ç¥ç»ç½‘ç»œæœ¬è´¨ä¸Šä¹Ÿæ˜¯æ•°å­¦è¡¨è¾¾å¼ï¼Œåªæ˜¯ç»“æ„æ›´è§„å¾‹ä¸€ç‚¹ã€‚

ç¥ç»ç½‘ç»œçš„è¾“å…¥æ˜¯æ•°æ®å’Œæƒé‡ï¼Œè¾“å‡ºæ˜¯é¢„æµ‹æˆ–æŸå¤±å‡½æ•°ï¼Œè€Œè¿™ä¸­é—´åªæ˜¯ç”±ä¸€å †æ•°å­¦æ“ä½œæ„æˆçš„è¡¨è¾¾å¼å›¾ã€‚å› æ­¤ï¼šåå‘ä¼ æ’­å…¶å®å’Œç¥ç»ç½‘ç»œæ— å…³ï¼Œå®ƒåªæ˜¯ç”¨æ¥å¤„ç†æ•°å­¦è¡¨è¾¾å¼çš„æ±‚å¯¼ã€‚

This is the most step-by-step spelled-out explanation of backpropagation and training of neural networks. It only assumes basic knowledge of Python and a vague recollection of calculus from high school.

Links:
- micrograd on github: https://github.com/karpathy/micrograd
- jupyter notebooks I built in this video: https://github.com/karpathy/nn-zero-t...
- my website: https://karpathy.ai
- my twitter:   / karpathy  
- "discussion forum": nvm, use youtube comments below for now :)
- (new) Neural Networks: Zero to Hero series Discord channel:   / discord   , for people who'd like to chat more and go beyond - youtube comments

Exercises:
you should now be able to complete the following google collab, good luck!:
- https://colab.research.google.com/dri...

```
Chapters:
00:00:00 intro
00:00:25 micrograd overview
00:08:08 derivative of a simple function with one input
00:14:12 derivative of a function with multiple inputs
00:19:09 starting the core Value object of micrograd and its visualization
00:32:10 manual backpropagation example #1: simple expression
00:51:10 preview of a single optimization step
00:52:52 manual backpropagation example #2: a neuron
01:09:02 implementing the backward function for each operation
01:17:32 implementing the backward function for a whole expression graph
01:22:28 fixing a backprop bug when one node is used multiple times
01:27:05 breaking up a tanh, exercising with more operations
01:39:31 doing the same thing but in PyTorch: comparison
01:43:55 building out a neural net library (multi-layer perceptron) in micrograd
01:51:04 creating a tiny dataset, writing the loss function
01:57:56 collecting all of the parameters of the neural net
02:01:12 doing gradient descent optimization manually, training the network
02:14:03 summary of what we learned, how to go towards modern neural nets
02:16:46 walkthrough of the full code of micrograd on github
02:21:10 real stuff: diving into PyTorch, finding their backward pass for tanh
02:24:39 conclusion
02:25:20 outtakes :)
```


å½“ç„¶å¯ä»¥ï¼Œä»¥ä¸‹æ˜¯ä½ æä¾›çš„å†…å®¹çš„ä¸­æ–‡ç¿»è¯‘ï¼š

---

è¿™æ˜¯å¯¹åå‘ä¼ æ’­å’Œç¥ç»ç½‘ç»œè®­ç»ƒ**æœ€é€æ­¥ã€æœ€è¯¦å°½çš„è®²è§£**ï¼Œåªéœ€è¦ä½ å…·å¤‡**åŸºç¡€çš„ Python çŸ¥è¯†å’Œå¯¹é«˜ä¸­å¾®ç§¯åˆ†çš„æ¨¡ç³Šè®°å¿†**ã€‚

ğŸ”— é“¾æ¥ï¼š

* micrograd GitHub ä»“åº“ï¼š[https://github.com/karpathy/micrograd](https://github.com/karpathy/micrograd)
* è§†é¢‘ä¸­ä½¿ç”¨çš„ Jupyter ç¬”è®°æœ¬ï¼š[https://github.com/karpathy/nn-zero-t...](https://github.com/karpathy/nn-zero-t...)
* æˆ‘çš„ä¸ªäººç½‘ç«™ï¼š[https://karpathy.ai](https://karpathy.ai)
* æˆ‘çš„ Twitterï¼š[@karpathy](https://twitter.com/karpathy)
* ã€Œè®¨è®ºåŒºã€ï¼šç®—äº†ï¼Œæš‚æ—¶è¯·ç›´æ¥ç”¨ä¸‹é¢çš„ YouTube è¯„è®ºåŒºå§ :)
* **ï¼ˆæ–°ï¼‰â€œNeural Networks: Zero to Heroâ€ç³»åˆ—çš„ Discord é¢‘é“**ï¼š`/discord`ï¼Œé€‚åˆæƒ³æ›´æ·±å…¥äº¤æµã€è¶…è¶Š YouTube è¯„è®ºåŒºçš„æœ‹å‹ã€‚

ğŸ§ª ç»ƒä¹ é¢˜ï¼š

ä½ ç°åœ¨åº”è¯¥èƒ½å¤Ÿå®Œæˆä»¥ä¸‹ Google Colab ä¸Šçš„å†…å®¹äº†ï¼ŒåŠ æ²¹ï¼
ğŸ‘‰ [https://colab.research.google.com/dri...](https://colab.research.google.com/dri...)

ğŸ“š ç« èŠ‚ç›®å½•ï¼š

* 00:00:00 å¼€åœºä»‹ç»
* 00:00:25 micrograd æ¦‚è§ˆ
* 00:08:08 å•è¾“å…¥å‡½æ•°çš„å¯¼æ•°
* 00:14:12 å¤šè¾“å…¥å‡½æ•°çš„å¯¼æ•°
* 00:19:09 åˆ›å»º micrograd çš„æ ¸å¿ƒ Value å¯¹è±¡å¹¶å®ç°å¯è§†åŒ–
* 00:32:10 æ‰‹åŠ¨åå‘ä¼ æ’­ä¾‹å­ #1ï¼šç®€å•è¡¨è¾¾å¼
* 00:51:10 é¢„è§ˆä¸€æ¬¡ä¼˜åŒ–æ­¥éª¤
* 00:52:52 æ‰‹åŠ¨åå‘ä¼ æ’­ä¾‹å­ #2ï¼šä¸€ä¸ªç¥ç»å…ƒ
* 01:09:02 ä¸ºæ¯ä¸ªæ“ä½œå®ç° `backward()` æ–¹æ³•
* 01:17:32 ä¸ºæ•´ä¸ªè¡¨è¾¾å¼å›¾å®ç°åå‘ä¼ æ’­
* 01:22:28 ä¿®å¤ä¸€ä¸ªåå‘ä¼ æ’­çš„ bugï¼šæŸèŠ‚ç‚¹è¢«å¤šæ¬¡ä½¿ç”¨çš„æƒ…å†µ
* 01:27:05 æ‹†è§£ tanh å‡½æ•°ï¼Œç»ƒä¹ æ›´å¤šæ“ä½œ
* 01:39:31 ç”¨ PyTorch åšåŒæ ·çš„äº‹æƒ…ï¼šæ¯”è¾ƒ
* 01:43:55 åœ¨ micrograd ä¸­æ„å»ºç¥ç»ç½‘ç»œåº“ï¼ˆå¤šå±‚æ„ŸçŸ¥æœºï¼‰
* 01:51:04 åˆ›å»ºä¸€ä¸ªå°æ•°æ®é›†ï¼Œç¼–å†™æŸå¤±å‡½æ•°
* 01:57:56 æ”¶é›†ç¥ç»ç½‘ç»œçš„æ‰€æœ‰å‚æ•°
* 02:01:12 æ‰‹åŠ¨å®ç°æ¢¯åº¦ä¸‹é™ï¼Œè®­ç»ƒç½‘ç»œ
* 02:14:03 æ€»ç»“æ‰€å­¦å†…å®¹ï¼Œå¹¶ä»‹ç»å¦‚ä½•èµ°å‘ç°ä»£ç¥ç»ç½‘ç»œ
* 02:16:46 å…¨é¢è®²è§£ micrograd çš„ä»£ç ï¼ˆGitHub ä¸Šï¼‰
* 02:21:10 å®æˆ˜å†…å®¹ï¼šæ·±å…¥ PyTorchï¼Œæ‰¾åˆ°å…¶ tanh çš„åå‘ä¼ æ’­å®ç°
* 02:24:39 æ€»ç»“
* 02:25:20 èŠ±çµ®é•œå¤´ :)

---

å¦‚æœä½ éœ€è¦æˆ‘æŠŠè¿™äº›å†…å®¹æ”¹å†™æˆç¬”è®°ã€æ€ç»´å¯¼å›¾æˆ–ä¸­æ–‡æ•™ç¨‹ææ–™ï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ï¼

micrograd

A tiny Autograd engine (with a bite! :)). Implements backpropagation (reverse-mode autodiff) over a dynamically built DAG and a small neural networks library on top of it with a PyTorch-like API. Both are tiny, with about 100 and 50 lines of code respectively. The DAG only operates over scalar values, so e.g. we chop up each neuron into all of its individual tiny adds and multiplies. However, this is enough to build up entire deep neural nets doing binary classification, as the demo notebook shows. Potentially useful for educational purposes.

è¿™æ˜¯ä¸€æ¬¾å°å·§çš„ Autograd å¼•æ“ï¼ˆå¸¦ç‚¹â€œå’¬åŠ²â€ï¼:))ï¼‰ã€‚å®ƒå®ç°äº†åå‘ä¼ æ’­ï¼ˆåå‘æ¨¡å¼è‡ªåŠ¨å¾®åˆ†ï¼‰ï¼Œé€šè¿‡åŠ¨æ€æ„å»ºçš„æœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰æ¥è¿›è¡Œï¼Œå¹¶åœ¨å…¶åŸºç¡€ä¸Šæä¾›äº†ä¸€ä¸ªç±»ä¼¼ PyTorch çš„ç¥ç»ç½‘ç»œåº“ã€‚ä¸¤ä¸ªéƒ¨åˆ†éƒ½éå¸¸ç®€æ´ï¼Œåˆ†åˆ«å¤§çº¦æœ‰ 100 è¡Œå’Œ 50 è¡Œä»£ç ã€‚è¯¥ DAG åªå¤„ç†æ ‡é‡å€¼ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å°†æ¯ä¸ªç¥ç»å…ƒæ‹†è§£ä¸ºæ‰€æœ‰å•ç‹¬çš„å°åŠ æ³•å’Œä¹˜æ³•æ“ä½œã€‚ç„¶è€Œï¼Œè¿™å·²ç»è¶³å¤Ÿç”¨æ¥æ„å»ºæ•´ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œï¼Œå¹¶è¿›è¡ŒäºŒåˆ†ç±»ä»»åŠ¡ï¼Œæ­£å¦‚æ¼”ç¤ºç¬”è®°æœ¬æ‰€å±•ç¤ºçš„é‚£æ ·ã€‚è¿™ä¸ªå·¥å…·å¯èƒ½å¯¹æ•™è‚²ç”¨é€”éå¸¸æœ‰å¸®åŠ©ã€‚

# Training a neural net

The notebook demo.ipynb provides a full demo of training an 2-layer neural network (MLP) binary classifier. This is achieved by initializing a neural net from micrograd.nn module, implementing a simple svm "max-margin" binary classification loss and using SGD for optimization. As shown in the notebook, using a 2-layer neural net with two 16-node hidden layers we achieve the following decision boundary on the moon dataset:

`demo.ipynb` æ¼”ç¤ºæ–‡æ¡£æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„ç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•è®­ç»ƒä¸€ä¸ª 2 å±‚ç¥ç»ç½‘ç»œï¼ˆMLPï¼‰è¿›è¡ŒäºŒåˆ†ç±»ã€‚è¿™é€šè¿‡ä» micrograd.nn æ¨¡å—åˆå§‹åŒ–ä¸€ä¸ªç¥ç»ç½‘ç»œã€å®ç°ä¸€ä¸ªç®€å•çš„æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰â€œæœ€å¤§è¾¹è·â€äºŒåˆ†ç±»æŸå¤±å‡½æ•°ï¼Œå¹¶ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰è¿›è¡Œä¼˜åŒ–æ¥å®ç°ã€‚æ­£å¦‚æ¼”ç¤ºæ–‡æ¡£æ‰€ç¤ºï¼Œä½¿ç”¨ä¸€ä¸ªåŒ…å«ä¸¤ä¸ª 16 èŠ‚ç‚¹éšè—å±‚çš„ 2 å±‚ç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬åœ¨â€œæœˆäº®æ•°æ®é›†â€ä¸Šè¾¾åˆ°äº†ä»¥ä¸‹å†³ç­–è¾¹ç•Œï¼š

# Tracing / visualization

For added convenience, the notebook trace_graph.ipynb produces graphviz visualizations. E.g. this one below is of a simple 2D neuron, arrived at by calling draw_dot on the code below, and it shows both the data (left number in each node) and the gradient (right number in each node).

**è·Ÿè¸ª / å¯è§†åŒ–**

ä¸ºäº†æ›´åŠ æ–¹ä¾¿ï¼Œ`trace_graph.ipynb` æ¼”ç¤ºæ–‡æ¡£æä¾›äº† graphviz å¯è§†åŒ–åŠŸèƒ½ã€‚ä¾‹å¦‚ï¼Œä¸‹é¢è¿™ä¸ªå›¾æ˜¯é€šè¿‡åœ¨ä¸‹é¢çš„ä»£ç ä¸­è°ƒç”¨ `draw_dot` å‡½æ•°ç”Ÿæˆçš„ï¼Œå®ƒå±•ç¤ºäº†ä¸€ä¸ªç®€å•çš„ 2D ç¥ç»å…ƒï¼Œå¹¶ä¸”æ˜¾ç¤ºäº†æ¯ä¸ªèŠ‚ç‚¹çš„**æ•°æ®**ï¼ˆæ¯ä¸ªèŠ‚ç‚¹å·¦ä¾§çš„æ•°å­—ï¼‰å’Œ**æ¢¯åº¦**ï¼ˆæ¯ä¸ªèŠ‚ç‚¹å³ä¾§çš„æ•°å­—ï¼‰ã€‚



# intro

hello my name is andre and i've been training deep neural networks for a bit more than a decade and in this lecture i'd like to show you
what neural network training looks like under the hood so in particular we are going to start with a blank jupiter
notebook and by the end of this lecture we will define and train in neural net and you'll get to see everything that
goes on under the hood and exactly sort of how that works on an intuitive level now specifically what i would like to do
is i would like to take you through building of micrograd now micrograd is

å½“ç„¶å¯ä»¥ï¼Œä¸‹é¢æ˜¯è¿™æ®µè‹±æ–‡çš„ä¸­æ–‡è§£é‡Šï¼š

---

ä½ å¥½ï¼Œæˆ‘å« Andreï¼ˆAndrej Karpathyï¼‰ï¼Œæˆ‘ä»äº‹æ·±åº¦ç¥ç»ç½‘ç»œè®­ç»ƒå·²ç»æœ‰åå¤šå¹´äº†ã€‚åœ¨è¿™èŠ‚è¯¾é‡Œï¼Œæˆ‘æƒ³å¸¦ä½ äº†è§£**ç¥ç»ç½‘ç»œè®­ç»ƒçš„åº•å±‚åŸç†**ï¼Œçœ‹çœ‹åœ¨èƒŒååˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆã€‚

å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†ä»ä¸€ä¸ª**ç©ºç™½çš„ Jupyter Notebook** å¼€å§‹ï¼Œä¸€æ­¥ä¸€æ­¥åœ°æ­å»ºï¼Œæœ€ç»ˆæˆ‘ä»¬ä¼š**å®šä¹‰å¹¶è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œ**ã€‚ä½ å°†èƒ½å¤Ÿç›´è§‚åœ°ç†è§£æ¯ä¸€æ­¥æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼ŒçœŸæ­£çœ‹åˆ°â€œå¼•æ“ç›–ä¸‹â€çš„è¿ä½œæ–¹å¼ã€‚

è¿™èŠ‚è¯¾æˆ‘ç‰¹åˆ«æƒ³åšçš„ä¸€ä»¶äº‹æ˜¯ï¼Œå¸¦ä½ ä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªåå« **micrograd** çš„å°é¡¹ç›®ã€‚

---

å¦‚æœä½ éœ€è¦æˆ‘ç»§ç»­ç¿»è¯‘ä¸‹ä¸€æ®µï¼Œæˆ–è€…å°†è¿™æ®µè¯æ”¹å†™æˆæ›´ç®€å•çš„å­¦ä¹ ç¬”è®°å½¢å¼ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼


# micrograd overview

this library that i released on github about two years ago but at the time i only uploaded the source code and you'd
have to go in by yourself and really figure out how it works so in this lecture i will take you
through it step by step and kind of comment on all the pieces of it so what is micrograd and why is it interesting
good um micrograd is basically an autograd engine autograd is short for automatic
gradient and really what it does is it implements backpropagation now backpropagation is this algorithm that
allows you to efficiently evaluate the gradient of some kind of a loss function with
respect to the weights of a neural network and what that allows us to do then is we can iteratively tune the
weights of that neural network to minimize the loss function and therefore improve the accuracy of the network so
back propagation would be at the mathematical core of any modern deep neural network library like say pytorch
or jaxx so the functionality of microgrant is i think best illustrated by an example so
if we just scroll down here you'll see that micrograph basically allows you to build out mathematical
expressions and um here what we are doing is we have an expression that we're building out where you have two inputs a and b
and you'll see that a and b are negative four and two but we are wrapping those
values into this value object that we are going to build out as part of micrograd so this value object will wrap the
numbers themselves and then we are going to build out a mathematical expression here where a and b are transformed into c d and
eventually e f and g and i'm showing some of the functions some of the functionality of micrograph
and the operations that it supports so you can add two value objects you can multiply them you can raise them to a
constant power you can offset by one negate squash at zero
square divide by constant divide by it etc and so we're building out an expression
graph with with these two inputs a and b and we're creating an output value of g
and micrograd will in the background build out this entire mathematical expression so it will for example know
that c is also a value c was a result of an addition operation and the
child nodes of c are a and b because the and will maintain pointers to a and b
value objects so we'll basically know exactly how all of this is laid out and then not only can we do what we call
the forward pass where we actually look at the value of g of course that's pretty straightforward we will access
that using the dot data attribute and so the output of the forward pass the value
of g is 24.7 it turns out but the big deal is that we can also take this g
value object and we can call that backward and this will basically uh initialize back propagation at the node g
and what backpropagation is going to do is it's going to start at g and it's going to go backwards through that
expression graph and it's going to recursively apply the chain rule from calculus and what that allows us to do then is
we're going to evaluate basically the derivative of g with respect to all the internal nodes
like e d and c but also with respect to the inputs a and b
and then we can actually query this derivative of g with respect to a for example that's a dot grad in this case
it happens to be 138 and the derivative of g with respect to b which also happens to be here 645
and this derivative we'll see soon is very important information because it's telling us how a and b are affecting g
through this mathematical expression so in particular a dot grad is 138 so if we slightly
nudge a and make it slightly larger 138 is telling us that g will grow and
the slope of that growth is going to be 138 and the slope of growth of b is going to be 645. so that's going to tell us about
how g will respond if a and b get tweaked a tiny amount in a positive direction
okay now you might be confused about what this expression is that we built out
here and this expression by the way is completely meaningless i just made it up i'm just flexing about the kinds of
operations that are supported by micrograd what we actually really care about are neural networks but it turns out that
neural networks are just mathematical expressions just like this one but actually slightly bit less crazy even
neural networks are just a mathematical expression they take the input data as an input and they take the weights of a
neural network as an input and it's a mathematical expression and the output are your predictions of your neural net
or the loss function we'll see this in a bit but basically neural networks just happen to be a certain class of
mathematical expressions but back propagation is actually significantly more general it doesn't
actually care about neural networks at all it only tells us about arbitrary mathematical expressions and then we
happen to use that machinery for training of neural networks now one more note i would like to make at this stage
is that as you see here micrograd is a scalar valued auto grant engine so it's working on the you know level of
individual scalars like negative four and two and we're taking neural nets and we're breaking them down all the way to
these atoms of individual scalars and all the little pluses and times and it's just excessive and so obviously you
would never be doing any of this in production it's really just put down for pedagogical reasons because it allows us
to not have to deal with these n-dimensional tensors that you would use in modern deep neural network library so
this is really done so that you understand and refactor out back propagation and chain rule and
understanding of neurologic training and then if you actually want to train bigger networks you have to be using
these tensors but none of the math changes this is done purely for efficiency we are basically taking scale
value all the scale values we're packaging them up into tensors which are just arrays of these scalars and then because
we have these large arrays we're making operations on those large arrays that allows us to take advantage of the
parallelism in a computer and all those operations can be done in parallel and then the whole thing runs faster but
really none of the math changes and that's done purely for efficiency so i don't think that it's pedagogically useful to be dealing with tensors from
scratch uh and i think and that's why i fundamentally wrote micrograd because you can understand how things work uh at
the fundamental level and then you can speed it up later okay so here's the fun part my claim is that micrograd is what
you need to train your networks and everything else is just efficiency so you'd think that micrograd would be a
very complex piece of code and that turns out to not be the case so if we just go to micrograd
and you'll see that there's only two files here in micrograd this is the actual engine it doesn't know anything
about neural nuts and this is the entire neural nets library on top of micrograd so engine and nn.pi
so the actual backpropagation autograd engine that gives you the power of neural
networks is literally 100 lines of code of like very simple
python which we'll understand by the end of this lecture and then nn.pi
this neural network library built on top of the autograd engine um is like a joke it's like
we have to define what is a neuron and then we have to define what is the layer of neurons and then we define what is a
multi-layer perceptron which is just a sequence of layers of neurons and so it's just a total joke
so basically there's a lot of power that comes from only 150 lines of code
and that's all you need to understand to understand neural network training and everything else is just efficiency and
of course there's a lot to efficiency but fundamentally that's all that's happening okay so now let's dive right

å½“ç„¶å¯ä»¥ï¼Œä»¥ä¸‹æ˜¯è¿™æ®µå†…å®¹çš„ä¸­æ–‡è§£é‡Šï¼ŒæŒ‰é€»è¾‘æ¸…æ™°åœ°ç¿»è¯‘å¹¶æ•´ç†å‡ºæ¥ï¼Œå¸®åŠ©ä½ æ›´å®¹æ˜“ç†è§£ï¼š

---

## ğŸ§  micrograd æ€»è§ˆï¼ˆMicrograd Overviewï¼‰

è¿™ä¸ªå« **micrograd** çš„åº“ï¼Œæ˜¯æˆ‘å¤§çº¦ä¸¤å¹´å‰å‘å¸ƒåœ¨ GitHub ä¸Šçš„ã€‚ä½†å½“æ—¶æˆ‘åªä¸Šä¼ äº†æºä»£ç ï¼Œæ²¡åšè®²è§£ã€‚ç”¨æˆ·å¾—è‡ªå·±çœ‹æºç ï¼Œè‡ªå·±æ‘¸ç´¢å®ƒæ˜¯æ€ä¹ˆè¿ä½œçš„ã€‚

æ‰€ä»¥åœ¨è¿™èŠ‚è¯¾ä¸­ï¼Œæˆ‘ä¼š**ä¸€æ­¥ä¸€æ­¥å¸¦ä½ èµ°å®Œæ•´ä¸ªé¡¹ç›®**ï¼Œè®²è§£æ¯ä¸ªéƒ¨åˆ†çš„åŸç†å’Œä»£ç ã€‚

---

### micrograd æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆå®ƒå¾ˆæœ‰è¶£ï¼Ÿ

**micrograd æ˜¯ä¸€ä¸ªè‡ªåŠ¨æ±‚å¯¼ï¼ˆautogradï¼‰å¼•æ“ã€‚**

* "autograd" æ˜¯ "automatic gradient"ï¼ˆè‡ªåŠ¨è®¡ç®—æ¢¯åº¦ï¼‰çš„ç¼©å†™ã€‚
* å®ƒçš„æ ¸å¿ƒåŠŸèƒ½æ˜¯**å®ç°åå‘ä¼ æ’­ï¼ˆbackpropagationï¼‰ç®—æ³•**ã€‚

---

### ğŸ’¡ ä»€ä¹ˆæ˜¯åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰ï¼Ÿ

åå‘ä¼ æ’­æ˜¯ä¸€ç§ç®—æ³•ï¼Œå®ƒå¯ä»¥**é«˜æ•ˆåœ°è®¡ç®—æŸå¤±å‡½æ•°å¯¹ç¥ç»ç½‘ç»œä¸­æƒé‡çš„æ¢¯åº¦**ã€‚æœ‰äº†è¿™äº›æ¢¯åº¦ï¼š

* æˆ‘ä»¬å°±å¯ä»¥é€šè¿‡æ¢¯åº¦ä¸‹é™æ¥**é€æ­¥ä¼˜åŒ–æƒé‡**ï¼›
* è¿›è€Œ**å‡å°‘æŸå¤±å‡½æ•°å€¼**ï¼›
* ä»è€Œ**æé«˜ç¥ç»ç½‘ç»œçš„å‡†ç¡®ç‡**ã€‚

åå‘ä¼ æ’­æ˜¯ç°ä»£æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆæ¯”å¦‚ PyTorchã€JAXï¼‰çš„**æ•°å­¦æ ¸å¿ƒ**ã€‚

---

### ç”¨ä¾‹å­æ¥ç†è§£ micrograd

micrograd å…è®¸æˆ‘ä»¬æ„å»ºæ•°å­¦è¡¨è¾¾å¼ï¼Œæ¯”å¦‚ä¸‹é¢çš„ä¾‹å­ï¼š

æˆ‘ä»¬å®šä¹‰äº†ä¸¤ä¸ªè¾“å…¥ `a = -4` å’Œ `b = 2`ï¼Œä½†æˆ‘ä»¬ä¸æ˜¯ç›´æ¥æ“ä½œæ•°å­—ï¼Œè€Œæ˜¯å°†å®ƒä»¬**å°è£…æˆä¸€ä¸ªå« `Value` çš„å¯¹è±¡**ï¼Œè¿™æ˜¯ micrograd çš„æ ¸å¿ƒã€‚

æˆ‘ä»¬åŸºäº `a` å’Œ `b` æ„é€ äº†ä¸€ä¸ªè®¡ç®—è¡¨è¾¾å¼å›¾ï¼Œæ¯”å¦‚ï¼š

```python
a = Value(-4.0)
b = Value(2.0)
c = a + b
d = a * b + b**3
e = c - d
f = e**2
g = f / 2.0
```

è¿™äº›æ“ä½œï¼ˆåŠ ã€å‡ã€ä¹˜ã€é™¤ã€å¹‚ã€å¹³æ–¹ç­‰ï¼‰éƒ½è¢«å°è£…åœ¨ `Value` å¯¹è±¡ä¸­ï¼ŒåŒæ—¶è‡ªåŠ¨æ„å»ºå‡ºä¸€å¼ è®¡ç®—å›¾ã€‚

æˆ‘ä»¬å¯ä»¥æ‰§è¡Œï¼š

```python
print(g.data)     # è¾“å‡ºæœ€ç»ˆå€¼ï¼ˆå‰å‘ä¼ æ’­ç»“æœï¼‰
g.backward()      # å¼€å§‹åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦
print(a.grad)     # æŸ¥çœ‹ a å¯¹ g çš„å¯¼æ•°
print(b.grad)     # æŸ¥çœ‹ b å¯¹ g çš„å¯¼æ•°
```

---

### ğŸ“ˆ ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦ï¼Ÿ

* åå‘ä¼ æ’­ä¼šä»è¾“å‡º `g` å¼€å§‹ï¼Œ**åå‘éå†æ•´ä¸ªè®¡ç®—å›¾**ï¼Œé€’å½’åº”ç”¨é“¾å¼æ³•åˆ™ï¼ˆæ¥è‡ªå¾®ç§¯åˆ†ï¼‰ã€‚
* æœ€ç»ˆä½ èƒ½çŸ¥é“ `g` å¯¹æ¯ä¸ªè¾“å…¥ï¼ˆå¦‚ aã€bï¼‰çš„å½±å“ç¨‹åº¦ï¼ˆå³æ¢¯åº¦ï¼‰ã€‚
* ä¾‹å¦‚ `a.grad = 138`ï¼Œæ„æ€æ˜¯å¦‚æœä½ è½»å¾®å¢åŠ  aï¼Œg ä¹Ÿä¼šä»¥æ–œç‡ 138 å¢åŠ ã€‚

---

### â“è¿™äº›è¡¨è¾¾å¼æ˜¯ç¥ç»ç½‘ç»œå—ï¼Ÿ

ä¸æ˜¯ï¼Œè¿™ä¸ªä¾‹å­åªæ˜¯ä¸€ä¸ªäººä¸ºæ„é€ çš„æ•°å­¦è¡¨è¾¾å¼ï¼Œ**ç”¨æ¥å±•ç¤º micrograd æ”¯æŒçš„æ“ä½œ**ï¼Œæ¯”å¦‚åŠ å‡ä¹˜é™¤ã€å¹‚è¿ç®—ç­‰ã€‚

ä½†å¾ˆé‡è¦çš„ä¸€ç‚¹æ˜¯ï¼š

> **ç¥ç»ç½‘ç»œæœ¬è´¨ä¸Šä¹Ÿæ˜¯æ•°å­¦è¡¨è¾¾å¼ï¼Œåªæ˜¯ç»“æ„æ›´è§„å¾‹ä¸€ç‚¹ã€‚**

ç¥ç»ç½‘ç»œçš„è¾“å…¥æ˜¯æ•°æ®å’Œæƒé‡ï¼Œè¾“å‡ºæ˜¯é¢„æµ‹æˆ–æŸå¤±å‡½æ•°ï¼Œè€Œè¿™ä¸­é—´åªæ˜¯ç”±ä¸€å †æ•°å­¦æ“ä½œæ„æˆçš„è¡¨è¾¾å¼å›¾ã€‚å› æ­¤ï¼š

> åå‘ä¼ æ’­å…¶å®**å’Œç¥ç»ç½‘ç»œæ— å…³**ï¼Œå®ƒåªæ˜¯ç”¨æ¥å¤„ç†æ•°å­¦è¡¨è¾¾å¼çš„æ±‚å¯¼ã€‚

---

### ğŸ§© micrograd æ˜¯æ ‡é‡çº§åˆ«çš„å¼•æ“ï¼ˆScalar-valuedï¼‰

micrograd æ˜¯ä¸º**æ•™å­¦ç›®çš„**è®¾è®¡çš„ï¼Œå®ƒå¤„ç†çš„æ˜¯**å•ä¸ªæ•°å­—ï¼ˆæ ‡é‡ï¼‰**ï¼Œä¸æ˜¯å¤šç»´æ•°ç»„ï¼ˆå¼ é‡ï¼‰ã€‚

* æ‰€ä»¥ä½ ä¸ä¼šçœ‹åˆ° PyTorch é‚£ç§ `Tensor` ç»“æ„ï¼›
* æ¯ä¸ªåŠ æ³•ã€ä¹˜æ³•éƒ½æ˜¯ä½œç”¨åœ¨å•ä¸ªå€¼ä¸Šçš„ï¼›
* è¿™æ ·åšçš„å¥½å¤„æ˜¯ä½ **æ›´å®¹æ˜“ç†è§£æ¯ä¸€ä¸ªç»†èŠ‚**ã€‚

ç”Ÿäº§ç¯å¢ƒä¸ä¼šè¿™ä¹ˆå†™ï¼Œè¿™æ˜¯**ä¸ºäº†å­¦ä¹ **ï¼Œä¸æ˜¯ä¸ºäº†æ•ˆç‡ã€‚

---

### ğŸš€ æ•ˆç‡æ¥è‡ªå“ªé‡Œï¼Ÿ

ç°ä»£æ·±åº¦å­¦ä¹ ä½¿ç”¨å¼ é‡ï¼ˆtensorï¼‰æ¥ï¼š

* å°†å¾ˆå¤šæ ‡é‡æ‰“åŒ…æˆæ•°ç»„ï¼›
* æ‰¹é‡å¤„ç†è¿™äº›æ•°ç»„ï¼›
* ç”¨å¹¶è¡Œè®¡ç®—å¤§å¤§åŠ é€Ÿè¿è¡Œã€‚

ä½†**æ•°å­¦åŸç†å®Œå…¨ä¸å˜**ã€‚æ‰€ä»¥ï¼š

> **micrograd æ˜¯â€œåŸç†æœ€å°é›†â€**ï¼Œè®©ä½ æŒæ¡ç¥ç»ç½‘ç»œè®­ç»ƒçš„æœ¬è´¨ã€‚ä¸€æ—¦ç†è§£ï¼Œä½ å¯ä»¥åˆ‡æ¢åˆ° PyTorch ç­‰æ¡†æ¶ï¼Œä»…ä»…æ˜¯æ¢äº†â€œè¿è¡Œæ•ˆç‡â€çš„å£³å­ã€‚

---

### ğŸ“ micrograd æœ‰å¤šå¤æ‚ï¼Ÿ

å®ƒå¾ˆç®€å•ï¼Œåªæœ‰ä¸¤ä¸ª Python æ–‡ä»¶ï¼š

1. `engine.py`ï¼šçœŸæ­£çš„è‡ªåŠ¨æ±‚å¯¼å¼•æ“ï¼Œ**ä¸åŒ…å«ä»»ä½•ç¥ç»ç½‘ç»œé€»è¾‘**ã€‚
2. `nn.py`ï¼šåœ¨ engine ä¸Šå»ºç«‹çš„ä¸€ä¸ª**è¿·ä½ ç¥ç»ç½‘ç»œåº“**ã€‚

æ•´ä¸ªæ ¸å¿ƒåå‘ä¼ æ’­é€»è¾‘å°±**ä¸åˆ° 100 è¡Œ Python ä»£ç **ï¼

è€Œç¥ç»ç½‘ç»œéƒ¨åˆ†ï¼š

* å®šä¹‰äº†ä¸€ä¸ª**ç¥ç»å…ƒï¼ˆneuronï¼‰**
* ä¸€å±‚ç¥ç»å…ƒç»„æˆä¸€ä¸ª**å±‚ï¼ˆlayerï¼‰**
* å¤šå±‚ç»„æˆä¸€ä¸ª**å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰**

åŠ èµ·æ¥æ€»å…±ä¹Ÿå°± **150 è¡Œ**ã€‚

---

### ğŸ¯ ç»“è®º

> **micrograd + nn.py å°±æ˜¯è®­ç»ƒç¥ç»ç½‘ç»œæ‰€éœ€çš„å…¨éƒ¨åŸç†ï¼Œå…¶ä»–éƒ½æ˜¯æ•ˆç‡ä¼˜åŒ–è€Œå·²ã€‚**

æ¥ä¸‹æ¥ï¼Œå°±è®©æˆ‘ä»¬æ·±å…¥ micrograd çš„æ¯ä¸€éƒ¨åˆ†å§ï¼

---

å¦‚æœä½ å¸Œæœ›æˆ‘å°†åé¢çš„è®²è§£ç»§ç»­ç¿»è¯‘ä¸‹å»ï¼Œæˆ–è€…æ•´ç†æˆä¸­æ–‡å­¦ä¹ ç¬”è®°ã€å›¾ç¤ºï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼


# derivative of a simple function with one input

in and implement micrograph step by step the first thing i'd like to do is i'd like to make sure that you have a very good understanding intuitively of what a
derivative is and exactly what information it gives you so let's start with some basic imports that i copy
paste in every jupiter notebook always and let's define a function a scalar
valued function f of x as follows so i just make this up randomly i just
want to scale a valid function that takes a single scalar x and returns a single scalar y
and we can call this function of course so we can pass in say 3.0 and get 20 back
now we can also plot this function to get a sense of its shape you can tell from the mathematical expression that this is probably a parabola it's a
quadratic and so if we just uh create a set of um
um scale values that we can feed in using for example a range from negative five to five in steps of 0.25
so this is so axis is just from negative 5 to 5 not including 5 in steps of 0.25
and we can actually call this function on this numpy array as well so we get a set of y's if we call f on axis
and these y's are basically also applying a function on every one of
these elements independently and we can plot this using matplotlib so plt.plot x's and y's and we get a nice
parabola so previously here we fed in 3.0 somewhere here and we received 20
back which is here the y coordinate so now i'd like to think through what is the derivative
of this function at any single input point x right so what is the derivative at different points x of this function now
if you remember back to your calculus class you've probably derived derivatives so we take this mathematical expression 3x squared minus 4x plus 5
and you would write out on a piece of paper and you would you know apply the product rule and all the other rules and derive the mathematical expression of
the great derivative of the original function and then you could plug in different texts and see what the derivative is
we're not going to actually do that because no one in neural networks actually writes out the expression for
the neural net it would be a massive expression um it would be you know thousands tens of thousands of terms no
one actually derives the derivative of course and so we're not going to take this kind of like a symbolic approach
instead what i'd like to do is i'd like to look at the definition of derivative and just make sure that we really understand what derivative is measuring
what it's telling you about the function and so if we just look up derivative
we see that okay so this is not a very good definition of derivative this is a definition of what it means to be differentiable
but if you remember from your calculus it is the limit as h goes to zero of f of x plus h minus f of x over h so
basically what it's saying is if you slightly bump up you're at some point x
that you're interested in or a and if you slightly bump up you know you slightly increase it by
small number h how does the function respond with what sensitivity does it respond what is the
slope at that point does the function go up or does it go down and by how much and that's the slope of that function
the the slope of that response at that point and so we can basically evaluate
the derivative here numerically by taking a very small h of course the definition would ask us to take h to
zero we're just going to pick a very small h 0.001 and let's say we're interested in point 3.0 so we can look at f of x of course
as 20 and now f of x plus h so if we slightly nudge x in a positive
direction how is the function going to respond and just looking at this do you expect do you expect f of x plus h to be
slightly greater than 20 or do you expect to be slightly lower than 20
and since this 3 is here and this is 20 if we slightly go positively the function will respond positively so
you'd expect this to be slightly greater than 20. and now by how much it's telling you the
sort of the the strength of that slope right the the size of the slope so f of x plus h minus
f of x this is how much the function responded in the positive direction and we have to
normalize by the run so we have the rise over run to get the slope so this of course is just a
numerical approximation of the slope because we have to make age very very small to converge to the exact amount
now if i'm doing too many zeros at some point i'm gonna get an incorrect answer
because we're using floating point arithmetic and the representations of all these numbers in computer memory is
finite and at some point we get into trouble so we can converse towards the right answer with this approach
but basically um at 3 the slope is 14. and you can see that by taking 3x
squared minus 4x plus 5 and differentiating it in our head so 3x squared would be
6 x minus 4 and then we plug in x equals 3 so that's 18 minus 4 is 14. so this is correct
so that's at 3. now how about the slope at say negative 3
would you expect would you expect for the slope now telling the exact value is really hard but what is the sign of that slope
so at negative three if we slightly go in the positive direction at x the function would
actually go down and so that tells you that the slope would be negative so we'll get a slight number below
below 20. and so if we take the slope we expect something negative negative 22. okay
and at some point here of course the slope would be zero now for this specific function i looked it up
previously and it's at point two over three so at roughly two over three
uh that's somewhere here um this derivative be zero so basically at that precise point
yeah at that precise point if we nudge in a positive direction the function doesn't respond this stays the same almost and
so that's why the slope is zero okay now let's look at a bit more complex case so we're going to start you know

å½“ç„¶å¯ä»¥ï¼Œä»¥ä¸‹æ˜¯è¿™ä¸€å¤§æ®µå†…å®¹çš„ä¸­æ–‡è§£é‡Šï¼Œæˆ‘ä¼šåˆ†æ®µæ•´ç†ï¼Œå¸®åŠ©ä½ é€æ­¥ç†è§£è®²è§£å†…å®¹ï¼š

---

## ğŸ“Œ **ç®€å•å‡½æ•°å¯¹ä¸€ä¸ªè¾“å…¥å˜é‡çš„å¯¼æ•°ï¼ˆderivative of a simple function with one inputï¼‰**

åœ¨æˆ‘ä»¬å¼€å§‹ä¸€æ­¥ä¸€æ­¥å®ç° micrograd ä¹‹å‰ï¼Œç¬¬ä¸€æ­¥è¦åšçš„äº‹æƒ…æ˜¯ï¼š

> **ç¡®ä¿ä½ ç›´è§‰ä¸ŠçœŸæ­£ç†è§£â€œå¯¼æ•°â€åˆ°åº•æ˜¯ä»€ä¹ˆæ„æ€ï¼Œä»¥åŠå®ƒåˆ°åº•å‘Šè¯‰æˆ‘ä»¬ä»€ä¹ˆä¿¡æ¯ã€‚**

---

### âœ… ç¬¬ä¸€æ­¥ï¼šå®šä¹‰ä¸€ä¸ªæ ‡é‡å‡½æ•°

æˆ‘ä»¬å…ˆå¼•å…¥ä¸€äº›å¸¸ç”¨çš„ Python åŒ…ï¼ˆå¦‚ numpy å’Œ matplotlibï¼‰ï¼Œç„¶åå®šä¹‰ä¸€ä¸ª**åªæ¥å—ä¸€ä¸ªæ ‡é‡è¾“å…¥å¹¶è¿”å›ä¸€ä¸ªæ ‡é‡è¾“å‡º**çš„å‡½æ•° `f(x)`ï¼Œä¾‹å¦‚ï¼š

```python
def f(x):
    return 3 * x ** 2 - 4 * x + 5
```

è¿™ä¸ªå‡½æ•°æ˜¯**éšä¾¿å†™çš„**ï¼Œç›®çš„æ˜¯ä¸ºäº†ä¸¾ä¾‹è¯´æ˜ã€‚

ä½ å¯ä»¥è°ƒç”¨å®ƒï¼Œæ¯”å¦‚ `f(3.0)` ä¼šè¿”å› `20`ã€‚

---

### ğŸ“Š ç¬¬äºŒæ­¥ï¼šå¯è§†åŒ–è¿™ä¸ªå‡½æ•°

é€šè¿‡ `matplotlib` ç”»å‡ºè¿™ä¸ªå‡½æ•°çš„å›¾åƒï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒæ˜¯ä¸€æ¡**æŠ›ç‰©çº¿**ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ª**äºŒæ¬¡å‡½æ•°**ã€‚

æ¯”å¦‚æˆ‘ä»¬ç”Ÿæˆä» -5 åˆ° 5ï¼ˆæ­¥é•¿ 0.25ï¼‰çš„è¾“å…¥æ•°ç»„ï¼Œç„¶åæŠŠæ¯ä¸ª x è¾“å…¥åˆ° `f(x)` é‡Œï¼Œå¯¹åº”å¾—åˆ°ä¸€ç»„ y å€¼ï¼Œç„¶åç”»å›¾ã€‚

ç»“æœå°±æ˜¯ä¸€ä¸ªæ ‡å‡†çš„æŠ›ç‰©çº¿æ›²çº¿ã€‚

---

### ğŸ“ ç¬¬ä¸‰æ­¥ï¼šä»€ä¹ˆæ˜¯â€œå¯¼æ•°â€ï¼Ÿ

æ¥ä¸‹æ¥æˆ‘ä»¬è¦**ä»ç›´è§‰ä¸Š**ç†è§£â€œå¯¼æ•°â€åˆ°åº•è¡¨ç¤ºä»€ä¹ˆï¼š

* åœ¨æŸä¸€ä¸ªç‚¹ `x` ä¸Šï¼Œå¯¼æ•° `f'(x)` è¡¨ç¤º **å‡½æ•°å¯¹è¿™ä¸ªç‚¹çš„ååº”ç¨‹åº¦ï¼ˆæ–œç‡ï¼‰**ã€‚
* ç”¨ç®€å•çš„å®šä¹‰æ¥è¯´ï¼Œå°±æ˜¯ï¼š

$$
f'(x) \approx \frac{f(x + h) - f(x)}{h}
$$

å…¶ä¸­ $h$ æ˜¯ä¸€ä¸ªå¾ˆå°çš„æ­£æ•°ï¼Œæ¯”å¦‚ 0.001ã€‚

è¿™ä¸ªå…¬å¼çš„æ„æ€æ˜¯ï¼š

> å¦‚æœä½ è½»å¾®åœ°å¢åŠ  `x`ï¼ˆåŠ ä¸€ç‚¹ç‚¹ $h$ï¼‰ï¼Œå‡½æ•° `f(x)` ä¼šå¦‚ä½•å˜åŒ–ï¼Ÿå˜åŒ–å¤šå°‘ï¼Ÿ

è¿™ä¸ªå˜åŒ–ç‡ï¼Œå°±æ˜¯å‡½æ•°çš„**æ–œç‡**ã€‚

---

### ğŸ§® ä¸¾ä¾‹ï¼šåœ¨ `x = 3` å¤„æ±‚å¯¼

* å·²çŸ¥ `f(3.0) = 20`
* æˆ‘ä»¬å–ä¸€ä¸ªå°çš„ $h = 0.001$
* ç®—ä¸€ä¸‹ `f(3.001)`ï¼Œä¼šæ¯” 20 ç¨å¾®å¤§ä¸€ç‚¹
* ç„¶åç”¨ä¸Šè¿°å¯¼æ•°å…¬å¼ä¼°ç®—ï¼š

```python
(f(3.001) - f(3.0)) / 0.001
```

ç»“æœå¤§çº¦æ˜¯ `14`ã€‚

æˆ‘ä»¬ä¹Ÿå¯ä»¥æ‰‹åŠ¨è®¡ç®—å¯¼æ•°ï¼š
åŸå‡½æ•°ï¼š $f(x) = 3x^2 - 4x + 5$
å¯¹å®ƒæ±‚å¯¼ï¼š$f'(x) = 6x - 4$
ä»£å…¥ `x = 3`ï¼š

$$
f'(3) = 6 \times 3 - 4 = 18 - 4 = 14
$$

éªŒè¯æ•°å€¼ç»“æœæ˜¯æ­£ç¡®çš„ã€‚

---

### ğŸ§® ä¸¾ä¾‹ï¼šåœ¨ `x = -3` å¤„æ±‚å¯¼

ä½ ä¸éœ€è¦ç®—å‡ºç²¾ç¡®æ•°å€¼ï¼Œåªè¦åˆ¤æ–­æ–¹å‘å³å¯ã€‚

* åœ¨ `x = -3` æ—¶ï¼Œå‡½æ•°å¤„äºå·¦è¾¹ã€‚
* å¦‚æœæˆ‘ä»¬ä» `-3` ç¨å¾®å¢åŠ ä¸€ç‚¹ï¼Œå‡½æ•°å€¼å…¶å®ä¼š**ä¸‹é™**ã€‚
* æ‰€ä»¥å¯¼æ•°åº”è¯¥æ˜¯**è´Ÿæ•°**ã€‚

å®é™…ç»“æœæ˜¯å¤§çº¦ `-22`ï¼Œè¯´æ˜å‡½æ•°åœ¨è¿™ä¸ªç‚¹æ˜¯å¿«é€Ÿä¸‹é™çš„ã€‚

---

### ğŸ“ ç‰¹æ®Šæƒ…å†µï¼šå¯¼æ•°ä¸ºé›¶

åœ¨æŸäº›ç‚¹ï¼Œå‡½æ•°çš„æ–œç‡æ˜¯é›¶â€”â€”ä¹Ÿå°±æ˜¯**å‡½æ•°åœ¨é‚£ä¸ªç‚¹ä¸å†ä¸Šå‡æˆ–ä¸‹é™**ï¼Œè€Œæ˜¯è¾¾åˆ°å³°å€¼æˆ–è°·å€¼ã€‚

å¯¹æˆ‘ä»¬è¿™ä¸ªå‡½æ•°æ¥è¯´ï¼Œè¿™ä¸ªä¸´ç•Œç‚¹åœ¨ï¼š

$$
x = \frac{2}{3}
$$

åœ¨è¿™ä¸ªç‚¹ï¼Œå¯¼æ•°ä¸º 0ï¼Œæ„å‘³ç€å‡½æ•°å›¾åƒåœ¨è¿™é‡Œâ€œå¹³å¦â€ã€‚

---

### âœ… å°ç»“ï¼š

è¿™ä¸€éƒ¨åˆ†çš„ç›®çš„æ˜¯å¸®åŠ©ä½ ï¼š

* **ç›´è§‚ç†è§£ä»€ä¹ˆæ˜¯å¯¼æ•°ï¼ˆslopeï¼‰**
* å­¦ä¼šç”¨**æ•°å€¼æ–¹å¼**ï¼ˆè€Œä¸æ˜¯ä»£æ•°ï¼‰è®¡ç®—å¯¼æ•°
* ç†è§£å¯¼æ•°åœ¨ç¥ç»ç½‘ç»œä¸­æ‰®æ¼”çš„è§’è‰²ï¼ˆå³è¡¡é‡è¾“å…¥å€¼å˜åŒ–å¯¹è¾“å‡ºç»“æœçš„å½±å“ï¼‰

è¿™ä¹Ÿæ˜¯åå‘ä¼ æ’­ï¼ˆbackpropagationï¼‰èƒŒåçš„æ ¸å¿ƒæ€æƒ³ã€‚

---

å¦‚æœä½ å¸Œæœ›æˆ‘ç»§ç»­ç¿»è¯‘åé¢è®²è§£â€œå¤šè¾“å…¥å‡½æ•°çš„å¯¼æ•°â€éƒ¨åˆ†ï¼Œæˆ–è€…éœ€è¦æ•´ç†æˆå­¦ä¹ ç¬”è®°ã€å›¾è§£å¯¼æ•°åŸç†ï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ï¼


# derivative of a function with multiple inputs

complexifying a bit so now we have a function here
with output variable d that is a function of three scalar inputs a b and c
so a b and c are some specific values three inputs into our expression graph and a single output d
and so if we just print d we get four and now what i have to do is i'd like to
again look at the derivatives of d with respect to a b and c and uh think through uh again just the
intuition of what this derivative is telling us so in order to evaluate this derivative we're going to get a bit hacky here
we're going to again have a very small value of h and then we're going to fix the inputs
at some values that we're interested in so these are the this is the point abc
at which we're going to be evaluating the the derivative of d with respect to all a b and c at that point
so there are the inputs and now we have d1 is that expression and then we're going to for example look
at the derivative of d with respect to a so we'll take a and we'll bump it by h and then we'll get d2 to be the exact
same function and now we're going to print um you know f1
d1 is d1 d2 is d2 and print slope
so the derivative or slope here will be um of course
d2 minus d1 divide h so d2 minus d1 is how much the function
increased uh when we bumped the uh the specific input that we're interested
in by a tiny amount and this is then normalized by h
to get the slope so um
yeah so this so if i just run this we're going to print
d1 which we know is four
now d2 will be bumped a will be bumped by h so let's just think through
a little bit uh what d2 will be uh printed out here
in particular d1 will be four will d2 be a number slightly greater
than four or slightly lower than four and that's going to tell us the sl the the sign of the derivative
so we're bumping a by h
b as minus three c is ten so you can just intuitively think through this derivative and what it's
doing a will be slightly more positive and but b is a negative number
so if a is slightly more positive because b is negative three
we're actually going to be adding less to d so you'd actually expect that the value
of the function will go down so let's just see this
yeah and so we went from 4 to 3.9996 and that tells you that the slope will
be negative and then uh will be a negative number because we went down
and then the exact number of slope will be exact amount of slope is negative 3.
and you can also convince yourself that negative 3 is the right answer mathematically and analytically because
if you have a times b plus c and you are you know you have calculus then differentiating a times b plus c with
respect to a gives you just b and indeed the value of b is negative 3 which is the derivative that we have so
you can tell that that's correct so now if we do this with b so if we bump b by a little bit in a
positive direction we'd get different slopes so what is the influence of b on the output d
so if we bump b by a tiny amount in a positive direction then because a is positive
we'll be adding more to d right so um and now what is the what is the
sensitivity what is the slope of that addition and it might not surprise you that this should be
2 and y is a 2 because d of d by db differentiating with respect to b
would be would give us a and the value of a is two so that's also working well
and then if c gets bumped a tiny amount in h by h then of course a times b is unaffected
and now c becomes slightly bit higher what does that do to the function it makes it slightly bit higher because
we're simply adding c and it makes it slightly bit higher by the exact same amount that we added to c
and so that tells you that the slope is one that will be the
the rate at which d will increase as we scale c
okay so we now have some intuitive sense of what this derivative is telling you about the function and we'd like to move to neural networks now as i mentioned

å½“ç„¶å¯ä»¥ï¼Œä¸‹é¢æ˜¯è¿™ä¸€æ®µå†…å®¹çš„ä¸­æ–‡è§£é‡Šï¼Œæ•´ç†æˆæ˜“æ‡‚çš„ç»“æ„åŒ–è¯´æ˜ï¼Œå¸®åŠ©ä½ æ¸…æ™°ç†è§£â€œ**å¤šè¾“å…¥å‡½æ•°çš„å¯¼æ•°**â€éƒ¨åˆ†ï¼š

---

## ğŸ“Œ å¤šè¾“å…¥å‡½æ•°çš„å¯¼æ•°ï¼ˆDerivative of a Function with Multiple Inputsï¼‰

---

### âœ… æƒ…å¢ƒè®¾å®š

æˆ‘ä»¬ç°åœ¨ç¨å¾®å¤æ‚ä¸€ç‚¹ï¼š

> å®šä¹‰ä¸€ä¸ªè¾“å‡ºä¸º `d` çš„å‡½æ•°ï¼Œå®ƒä¾èµ–äºä¸‰ä¸ªè¾“å…¥å˜é‡ï¼š`a`ã€`b`ã€`c`ã€‚
> ä¹Ÿå°±æ˜¯è¯´ï¼š

$$
d = f(a, b, c)
$$

* `a`ã€`b`ã€`c` æ˜¯ä¸‰ä¸ªå…·ä½“çš„æ ‡é‡å€¼ï¼ˆä¾‹å¦‚ `a = 2`ï¼Œ`b = -3`ï¼Œ`c = 10`ï¼‰
* è¾“å‡º `d` æ˜¯ä¸€ä¸ªæ ‡é‡å€¼ï¼ˆä¾‹å­ä¸­ `d = 4`ï¼‰

---

### ğŸ“ æƒ³æ³•ï¼šæˆ‘ä»¬æƒ³çŸ¥é“æ¯ä¸ªè¾“å…¥å¯¹ `d` çš„å½±å“æœ‰å¤šå¤§

ä¹Ÿå°±æ˜¯æˆ‘ä»¬è¦è®¡ç®—ï¼š

* $\frac{\partial d}{\partial a}$
* $\frac{\partial d}{\partial b}$
* $\frac{\partial d}{\partial c}$

ä¸ºäº†è·å¾—ç›´è§‰ä¸Šçš„ç†è§£ï¼Œæˆ‘ä»¬è¿˜æ˜¯åƒå‰é¢é‚£æ ·ï¼Œç”¨**æ•°å€¼æ–¹å¼é€¼è¿‘å¯¼æ•°**ï¼š

$$
\text{slope} = \frac{f(x + h) - f(x)}{h}
$$

å…¶ä¸­ $h$ æ˜¯ä¸€ä¸ªéå¸¸å°çš„æ­£æ•°ï¼Œæ¯”å¦‚ 0.001ã€‚

---

### ğŸ§® ä¸¾ä¾‹ï¼šä»¥ `a` ä¸ºä¾‹ï¼Œè®¡ç®— $\frac{\partial d}{\partial a}$

1. å…ˆå›ºå®š `a=2`ï¼Œ`b=-3`ï¼Œ`c=10`ï¼Œè®¡ç®—ä¸€æ¬¡ `d1 = f(a, b, c)`ï¼Œå€¼ä¸º `4`
2. ç„¶åå°† `a` å¢åŠ ä¸€ç‚¹ç‚¹ $h = 0.001$ï¼Œå˜ä¸º `a=2.001`ï¼Œå†è®¡ç®—ä¸€æ¬¡ `d2 = f(a+h, b, c)`
3. è®¡ç®—å¯¼æ•°è¿‘ä¼¼å€¼ï¼š

$$
\frac{d2 - d1}{h}
$$

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼š

* `a` å¢åŠ äº†ï¼Œä½† `b` æ˜¯è´Ÿæ•°ï¼Œæ‰€ä»¥ `a * b` å˜å¾—æ›´è´Ÿ
  â†’ æ‰€ä»¥æœ€ç»ˆçš„ `d` ä¼šå˜å°
  â†’ è¯´æ˜å¯¼æ•°æ˜¯è´Ÿçš„
  â†’ å®é™…æ•°å€¼æ˜¯ `-3`

æ•°å­¦éªŒè¯ï¼š

$$
d = a \cdot b + c \Rightarrow \frac{\partial d}{\partial a} = b = -3
$$

---

### ğŸ§® ç±»ä¼¼åœ°ï¼Œå¯¹ `b` æ±‚å¯¼ï¼š

* å¢åŠ  `b`ï¼Œ`a` æ˜¯æ­£çš„ï¼Œæ‰€ä»¥ `a * b` å˜å¤§ï¼Œ`d` å˜å¤§
  â†’ å¯¼æ•°ä¸ºæ­£
  â†’ å®é™…å¯¼æ•°æ˜¯ `a = 2`

$$
\frac{\partial d}{\partial b} = a = 2
$$

---

### ğŸ§® å¯¹ `c` æ±‚å¯¼ï¼š

* å¢åŠ  `c`ï¼Œå‡½æ•° `d = a * b + c` ä¸­ï¼Œ`c` æ˜¯ç›´æ¥ç›¸åŠ çš„é¡¹
* æ‰€ä»¥å‡½æ•°å¢åŠ çš„å¹…åº¦å’Œ `c` çš„å˜åŒ–å®Œå…¨ä¸€è‡´
  â†’ å¯¼æ•°ä¸º 1

$$
\frac{\partial d}{\partial c} = 1
$$

---

### âœ… å°ç»“

é€šè¿‡è¿™ä¸ªç®€å•çš„å¤šè¾“å…¥å‡½æ•°ä¾‹å­ï¼Œä½ åº”è¯¥èƒ½**ç›´è§‚ç†è§£å¯¼æ•°å‘Šè¯‰æˆ‘ä»¬ä»€ä¹ˆ**ï¼š

* å®ƒå‘Šè¯‰æˆ‘ä»¬ï¼š**å½“ä½ è½»å¾®è°ƒæ•´æŸä¸ªè¾“å…¥å˜é‡æ—¶ï¼Œè¾“å‡ºå€¼ä¼šå¦‚ä½•å˜åŒ–ï¼ˆæ–œç‡ï¼‰**
* å®ƒæ˜¯ç¥ç»ç½‘ç»œè®­ç»ƒï¼ˆé€šè¿‡åå‘ä¼ æ’­ç®—æ³•ï¼‰æœ€å…³é”®çš„ä¿¡æ¯æ¥æº

---

æ¥ä¸‹æ¥ï¼Œä½œè€…ä¼šå¼€å§‹çœŸæ­£è¿›å…¥ç¥ç»ç½‘ç»œçš„ç»“æ„å’Œåå‘ä¼ æ’­ç®—æ³•çš„å®ç°ã€‚

å¦‚æœä½ å¸Œæœ›æˆ‘ç»§ç»­ç¿»è¯‘â€œç¥ç»å…ƒçš„ä¾‹å­â€æˆ–â€œæ‰‹åŠ¨å®ç°åå‘ä¼ æ’­â€çš„éƒ¨åˆ†ï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯ä»¥ç»§ç»­ä¸ºä½ è®²è§£ï¼


# starting the core Value object of micrograd and its visualization

neural networks will be pretty massive expressions mathematical expressions so we need some data structures that maintain these expressions and that's
what we're going to start to build out now so we're going to build out this value object that i
showed you in the readme page of micrograd so let me copy paste a skeleton of the
first very simple value object so class value takes a single
scalar value that it wraps and keeps track of and that's it so
we can for example do value of 2.0 and then we can get we can look at its content and
python will internally use the wrapper function to uh return
uh this string oops like that so this is a value object with data
equals two that we're creating here now we'd like to do is like we'd like to be able to
have not just like two values but we'd like to do a bluffy right we'd like to add them
so currently you would get an error because python doesn't know how to add two value objects so we have to tell it
so here's addition so you have to basically use these
special double underscore methods in python to define these operators for these objects so if we call um
the uh if we use this plus operator python will internally call a dot add of
b that's what will happen internally and so b will be the other and
self will be a and so we see that what we're going to return is a new value object and it's
just it's going to be wrapping the plus of their data
but remember now because data is the actual like numbered python number so this operator here is just the typical
floating point plus addition now it's not an addition of value objects and will return a new value so now a
plus b should work and it should print value of negative one because that's two plus minus three
there we go okay let's now implement multiply just so we can recreate this expression
here so multiply i think it won't surprise you will be fairly similar
so instead of add we're going to be using mul and then here of course we want to do times
and so now we can create a c value object which will be 10.0 and now we should be able to do a times b well
let's just do a times b first um [Music] that's value of negative six now
and by the way i skipped over this a little bit suppose that i didn't have the wrapper function here then it's just that you'll get some kind
of an ugly expression so what wrapper is doing is it's providing us a way to print out like a nicer looking
expression in python uh so we don't just have something cryptic we actually are you know it's
value of negative six so this gives us a times and then this we should now be able to
add c to it because we've defined and told the python how to do mul and add and so this will call this will
basically be equivalent to a dot small of b
and then this new value object will be dot add of c and so let's see if that worked
yep so that worked well that gave us four which is what we expect from before and i believe we can just call them
manually as well there we go so yeah okay so now what we are missing is the
connective tissue of this expression as i mentioned we want to keep these expression graphs so we need to know and
keep pointers about what values produce what other values so here for example we are going to
introduce a new variable which we'll call children and by default it will be an empty tuple and then we're actually going to keep a
slightly different variable in the class which we'll call underscore prev which will be the set of children
this is how i done i did it in the original micrograd looking at my code here i can't remember exactly the reason
i believe it was efficiency but this underscore children will be a tuple for convenience but then when we actually
maintain it in the class it will be just this set yeah i believe for efficiency
um so now when we are creating a value like this with a constructor children will be
empty and prep will be the empty set but when we're creating a value through addition or multiplication we're going
to feed in the children of this value which in this case is self and other
so those are the children here so now we can do d dot prev
and we'll see that the children of the we now know are this value of negative 6
and value of 10 and this of course is the value resulting from a times b and the c value which is 10.
now the last piece of information we don't know so we know that the children of every single value but we don't know
what operation created this value so we need one more element here let's call it underscore pop
and by default this is the empty set for leaves and then we'll just maintain it here
and now the operation will be just a simple string and in the case of addition it's plus in the case of
multiplication is times so now we not just have d dot pref we also have a
d dot up and we know that d was produced by an addition of those two values and so now
we have the full mathematical expression uh and we're building out this data structure and we know exactly how each value came to be
by word expression and from what other values now because these expressions are about
to get quite a bit larger we'd like a way to nicely visualize these expressions that we're building out so
for that i'm going to copy paste a bunch of slightly scary code that's going to visualize this these expression graphs
for us so here's the code and i'll explain it in a bit but first let me just show you what this code does
basically what it does is it creates a new function drawdot that we can call on some root node
and then it's going to visualize it so if we call drawdot on d which is this final value here that is a
times b plus c it creates something like this so this is d
and you see that this is a times b creating an integrated value plus c gives us this output node d
so that's dried out of d and i'm not going to go through this in complete detail you can take a look at
graphless and its api uh graphis is a open source graph visualization software
and what we're doing here is we're building out this graph and graphis api and
you can basically see that trace is this helper function that enumerates all of the nodes and edges in the graph
so that just builds a set of all the nodes and edges and then we iterate for all the nodes and we create special node
objects for them in using dot node
and then we also create edges using dot dot edge and the only thing that's like slightly tricky here is you'll notice that i
basically add these fake nodes which are these operation nodes so for example this node here is just like a plus node
and i create these special op nodes here
and i connect them accordingly so these nodes of course are not actual
nodes in the original graph they're not actually a value object the only value objects here are the things
in squares those are actual value objects or representations thereof and these op nodes are just created in this
drawdot routine so that it looks nice let's also add labels to these graphs
just so we know what variables are where so let's create a special underscore label
um or let's just do label equals empty by default and save it in
each node and then here we're going to do label as a
label is the label a c
and then let's create a special um e equals a times b
and e dot label will be e it's kind of naughty and e will be e plus c
and a d dot label will be d okay so nothing really changes i just
added this new e function a new e variable and then here when we are
printing this i'm going to print the label here so this will be a percent s
bar and this will be end.label
and so now we have the label on the left here so it says a b creating e and then e plus c
creates d just like we have it here and finally let's make this expression just one layer deeper
so d will not be the final output node instead after d we are going to create a
new value object called f we're going to start running out of variables soon f will be negative
2.0 and its label will of course just be f and then l capital l will be the output
of our graph and l will be p times f okay so l will be negative eight is the
output so now we don't just draw a d we draw l
okay and somehow the label of l was undefined oops all that label has
to be explicitly sort of given to it there we go so l is the output
so let's quickly recap what we've done so far we are able to build out mathematical expressions using only plus and times so
far they are scalar valued along the way and we can do this forward pass
and build out a mathematical expression so we have multiple inputs here a b c and f
going into a mathematical expression that produces a single output l and this here is visualizing the forward
pass so the output of the forward pass is negative eight that's the value
now what we'd like to do next is we'd like to run back propagation and in back propagation we are going to
start here at the end and we're going to reverse and calculate the gradient along along
all these intermediate values and really what we're computing for every single value here
um we're going to compute the derivative of that node with respect to l
so the derivative of l with respect to l is just uh one
and then we're going to derive what is the derivative of l with respect to f with respect to d with respect to c with
respect to e with respect to b and with respect to a and in the neural network setting you'd
be very interested in the derivative of basically this loss function l with respect to the weights of a neural
network and here of course we have just these variables a b c and f but some of these will eventually
represent the weights of a neural net and so we'll need to know how those weights are impacting
the loss function so we'll be interested basically in the derivative of the output with respect to some of its leaf
nodes and those leaf nodes will be the weights of the neural net and the other leaf nodes of course will be the data itself but usually we will
not want or use the derivative of the loss function with respect to data because the data is fixed but the
weights will be iterated on using the gradient information so next we are going to create a variable inside
the value class that maintains the derivative of l with respect to that
value and we will call this variable grad so there's a data and there's a
self.grad and initially it will be zero and remember that zero is basically means no
effect so at initialization we're assuming that every value does not impact does not affect the out the
output right because if the gradient is zero that means that changing this variable is not changing the loss function
so by default we assume that the gradient is zero and then
now that we have grad and it's 0.0
we are going to be able to visualize it here after data so here grad is 0.4 f
and this will be in that graph and now we are going to be showing both the data and the grad
initialized at zero and we are just about getting ready to calculate the back propagation
and of course this grad again as i mentioned is representing the derivative of the output in this case l with respect to this value so
with respect to so this is the derivative of l with respect to f with respect to d and so on so let's now fill

è¿™æ®µå†…å®¹è®²è¿°äº†**æ„å»ºå¾®å‹åå‘ä¼ æ’­å¼•æ“ï¼ˆmicrogradï¼‰æ ¸å¿ƒæ•°æ®ç»“æ„**â€”â€”**`Value`å¯¹è±¡çš„å®ç°**ï¼Œå¹¶ä¸”é€šè¿‡ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•å®šä¹‰è¿™ä¸ªå¯¹è±¡ã€å¦‚ä½•è¿›è¡ŒåŠ æ³•å’Œä¹˜æ³•æ“ä½œï¼Œå¹¶ä¸”å¦‚ä½•å¯è§†åŒ–è¿™äº›æ•°å­¦è¡¨è¾¾å¼ã€‚ä»¥ä¸‹æ˜¯ç®€è¦çš„ä¸­æ–‡è§£é‡Šï¼š

---

### **1. å®šä¹‰ `Value` ç±»**

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªç±»æ¥è¡¨ç¤ºä¸€ä¸ª**æ•°å€¼å¯¹è±¡** (`Value`)ï¼Œè¯¥å¯¹è±¡å°è£…äº†ä¸€ä¸ªæ ‡é‡å€¼ã€‚è¿™ä¸ªç±»çš„ä¸»è¦ä»»åŠ¡æ˜¯ä¿å­˜æ•°å€¼å’Œæ‰§è¡ŒåŸºæœ¬çš„æ•°å­¦æ“ä½œï¼ˆå¦‚åŠ æ³•ã€ä¹˜æ³•ï¼‰ã€‚

#### ç¤ºä¾‹ï¼šåˆ›å»ºä¸€ä¸ªç®€å•çš„ `Value` å¯¹è±¡

```python
class Value:
    def __init__(self, data):
        self.data = data  # ä¿å­˜æ ‡é‡æ•°æ®
```

é€šè¿‡è¯¥ç±»ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªæ•°å€¼å¯¹è±¡ï¼š

```python
a = Value(2.0)  # åˆ›å»ºä¸€ä¸ªå€¼ä¸º 2.0 çš„ `Value` å¯¹è±¡
print(a)  # æ‰“å°è¾“å‡ºï¼švalue of 2.0
```

---

### **2. æ”¯æŒåŸºæœ¬æ•°å­¦è¿ç®—**

åœ¨é»˜è®¤æƒ…å†µä¸‹ï¼ŒPythonä¸æ”¯æŒç›´æ¥å¯¹ `Value` å¯¹è±¡è¿›è¡ŒåŠ æ³•æˆ–ä¹˜æ³•æ“ä½œï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦é€šè¿‡é‡è½½ç‰¹æ®Šæ–¹æ³•ï¼ˆå¦‚ `__add__` å’Œ `__mul__`ï¼‰æ¥æ”¯æŒè¿™äº›æ“ä½œã€‚

#### åŠ æ³•ï¼ˆ`+`ï¼‰ï¼š

```python
def __add__(self, other):
    return Value(self.data + other.data)
```

è¿™æ ·å°±å¯ä»¥ä½¿ç”¨ `+` è¿ç®—ç¬¦å¯¹ä¸¤ä¸ª `Value` å¯¹è±¡è¿›è¡ŒåŠ æ³•è¿ç®—ã€‚

#### ä¹˜æ³•ï¼ˆ`*`ï¼‰ï¼š

```python
def __mul__(self, other):
    return Value(self.data * other.data)
```

è¿™äº›è¿ç®—ç¬¦å°†è¿”å›æ–°çš„ `Value` å¯¹è±¡ï¼Œå°è£…äº†ç»“æœã€‚

---

### **3. ç»´æŠ¤è¡¨è¾¾å¼å›¾**

ä¸ºäº†è·Ÿè¸ªæ¯ä¸ªæ“ä½œçš„æ¥æºå’Œåˆ›å»ºè¿‡ç¨‹ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ `Value` ç±»ä¸­ç»´æŠ¤ä¸¤ä¸ªä¿¡æ¯ï¼š

* **`prev`**ï¼šæŒ‡å‘å¯¼è‡´å½“å‰å€¼çš„çˆ¶èŠ‚ç‚¹ï¼Œè¡¨ç¤ºè¿ç®—çš„è¾“å…¥ã€‚
* **`op`**ï¼šè¡¨ç¤ºåˆ›å»ºå½“å‰å€¼çš„è¿ç®—ç¬¦ï¼ˆå¦‚åŠ æ³•ã€ä¹˜æ³•ï¼‰ã€‚

æ¯æ¬¡è¿›è¡Œè¿ç®—ï¼ˆå¦‚åŠ æ³•æˆ–ä¹˜æ³•ï¼‰ï¼Œæˆ‘ä»¬ä¸ä»…ä»…è¿”å›è®¡ç®—ç»“æœï¼Œè¿˜éœ€è¦è®°å½•è¿ç®—çš„æ“ä½œç±»å‹å’Œæ“ä½œæ•°ï¼Œä»¥ä¾¿åœ¨åå‘ä¼ æ’­æ—¶ä½¿ç”¨ã€‚

#### ç¤ºä¾‹ï¼š

```python
class Value:
    def __init__(self, data, prev=None, op=''):
        self.data = data
        self.prev = prev if prev else []
        self.op = op
```

---

### **4. å¯è§†åŒ–æ•°å­¦è¡¨è¾¾å¼**

æˆ‘ä»¬ä½¿ç”¨ `Graphviz` æ¥å¯è§†åŒ–è¿™äº›æ•°å­¦è¡¨è¾¾å¼ã€‚åœ¨å®é™…çš„å›¾å½¢ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¯ä¸ªæ“ä½œï¼ˆå¦‚åŠ æ³•ã€ä¹˜æ³•ï¼‰çš„èŠ‚ç‚¹ï¼Œä»¥åŠå®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚

#### å¯è§†åŒ–è¿‡ç¨‹ï¼š

```python
def draw_dot(self):
    dot = graphviz.Digraph()
    dot.node(str(self), label=str(self.data))
    for child in self.prev:
        dot.edge(str(child), str(self))
    return dot
```

é€šè¿‡ `draw_dot` å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¡¨è¾¾å¼å›¾å¯è§†åŒ–ã€‚æ¯ä¸ªæ•°å€¼èŠ‚ç‚¹ä¼šæ˜¾ç¤ºå‡ºå®ƒçš„æ•°æ®å’Œç”±å“ªäº›æ“ä½œï¼ˆåŠ æ³•ã€ä¹˜æ³•ç­‰ï¼‰ç”Ÿæˆã€‚

---

### **5. æ‰©å±•åˆ°æ›´å¤æ‚çš„è¡¨è¾¾å¼**

éšç€ `Value` å¯¹è±¡å’Œè¿ç®—ç¬¦çš„å¢åŠ ï¼Œæ•°å­¦è¡¨è¾¾å¼ä¼šè¶Šæ¥è¶Šå¤æ‚ã€‚åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œå¤šä¸ª `Value` å¯¹è±¡é€šè¿‡åŠ æ³•ã€ä¹˜æ³•è¿æ¥æˆä¸€ä¸ªæ›´å¤§çš„è¡¨è¾¾å¼ã€‚ç„¶åï¼Œé€šè¿‡ `draw_dot` ç»˜åˆ¶å‡ºè¡¨è¾¾å¼å›¾ï¼Œå›¾ä¸­æ˜¾ç¤ºäº†æ¯ä¸ªèŠ‚ç‚¹çš„è®¡ç®—è¿‡ç¨‹å’Œæ“ä½œã€‚

---

### **6. å‡†å¤‡è¿›è¡Œåå‘ä¼ æ’­**

ä¸ºäº†è¿›è¡Œåå‘ä¼ æ’­ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸ªå€¼å¯¹è±¡å¢åŠ ä¸€ä¸ª **`grad`**ï¼ˆæ¢¯åº¦ï¼‰å±æ€§ï¼Œè¿™ä¸ªå±æ€§è¡¨ç¤ºæŸå¤±å‡½æ•°å…³äºè¯¥å€¼çš„å¯¼æ•°ã€‚åˆå§‹æ—¶ï¼Œ`grad` ä¸º 0ã€‚

åå‘ä¼ æ’­æ—¶ï¼Œæˆ‘ä»¬å°†ä»æœ€ç»ˆè¾“å‡ºèŠ‚ç‚¹ï¼ˆå¦‚ `l`ï¼‰å¼€å§‹ï¼Œæ²¿ç€è®¡ç®—å›¾åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¯ä¸ªä¸­é—´èŠ‚ç‚¹çš„æ¢¯åº¦ã€‚

ä¾‹å¦‚ï¼Œå¯¹äºæ¯ä¸ª `Value` å¯¹è±¡ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥è®¡ç®—æŸå¤±å‡½æ•°ï¼ˆ`l`ï¼‰å…³äºè¯¥èŠ‚ç‚¹çš„å¯¼æ•°ï¼Œå¹¶ç”¨æ¢¯åº¦æ›´æ–°æƒé‡ï¼ˆå¦‚ç¥ç»ç½‘ç»œä¸­çš„æƒé‡ï¼‰ã€‚

---

### **æ€»ç»“**

* æˆ‘ä»¬é€šè¿‡æ„å»ºä¸€ä¸ªç®€å•çš„ `Value` ç±»æ¥è¡¨ç¤ºæ¯ä¸ªæ•°å€¼èŠ‚ç‚¹ï¼Œè®°å½•å…¶æ•°æ®ã€çˆ¶èŠ‚ç‚¹å’Œæ“ä½œç¬¦ã€‚
* é€šè¿‡é‡è½½åŸºæœ¬è¿ç®—ç¬¦ï¼Œæ”¯æŒå¯¹æ•°å€¼å¯¹è±¡çš„åŠ æ³•ã€ä¹˜æ³•ç­‰æ“ä½œã€‚
* ä¸ºäº†å¯è§†åŒ–è¿™äº›æ•°å­¦è¡¨è¾¾å¼ï¼Œä½¿ç”¨ `Graphviz` ç”Ÿæˆè®¡ç®—å›¾ã€‚
* æœ€ç»ˆçš„ç›®æ ‡æ˜¯é€šè¿‡åå‘ä¼ æ’­è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹å¯¹æœ€ç»ˆè¾“å‡ºçš„å½±å“ï¼ˆå³æ¢¯åº¦ï¼‰ã€‚

åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•ï¼Œæ„å»ºå‡ºå®Œæ•´çš„ç¥ç»ç½‘ç»œè®­ç»ƒæ¡†æ¶ã€‚


pythoné™¤äº†__init__æ–¹æ³•ï¼Œè¿˜æœ‰å“ªäº›ç‰¹æ®Šæ–¹æ³•


åœ¨ Python ä¸­ï¼Œé™¤äº† `__init__` æ–¹æ³•ï¼Œè¿˜æœ‰è®¸å¤šå…¶ä»–ç‰¹æ®Šæ–¹æ³•ï¼ˆä¹Ÿå«é­”æ³•æ–¹æ³•æˆ–åŒä¸‹åˆ’çº¿æ–¹æ³•ï¼‰ã€‚è¿™äº›æ–¹æ³•é€šå¸¸ç”¨äºå®šä¹‰å¯¹è±¡çš„è¡Œä¸ºï¼Œå¯ä»¥è®©ä½ çš„å¯¹è±¡çœ‹èµ·æ¥åƒå†…å»ºç±»å‹ä¸€æ ·ï¼Œæˆ–è€…èƒ½å¤Ÿè¿›è¡Œç‰¹å®šçš„æ“ä½œã€‚

ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„ç‰¹æ®Šæ–¹æ³•ï¼š

1. **`__del__`**
   ç”¨äºå¯¹è±¡è¢«é”€æ¯æ—¶æ‰§è¡Œæ¸…ç†æ“ä½œï¼ˆæ¯”å¦‚é‡Šæ”¾èµ„æºï¼‰ã€‚

   ```python
   def __del__(self):
       print(f"Object {self} is being destroyed.")
   ```

2. **`__repr__`**
   è¿”å›å¯¹è±¡çš„â€œå®˜æ–¹â€å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œé€šå¸¸æ˜¯ç”¨äºè°ƒè¯•ã€‚
   ç”¨æ³•ï¼š`repr(obj)` æˆ– `print(obj)` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

   ```python
   def __repr__(self):
       return f"MyClass({self.value})"
   ```

3. **`__str__`**
   è¿”å›å¯¹è±¡çš„â€œéæ­£å¼â€å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œé€šå¸¸ç”¨äºæ‰“å°å¯¹è±¡æ—¶ã€‚
   ç”¨æ³•ï¼š`str(obj)` æˆ– `print(obj)` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

   ```python
   def __str__(self):
       return f"Value: {self.value}"
   ```

4. **`__len__`**
   è¿”å›å¯¹è±¡çš„é•¿åº¦ã€‚æ¯”å¦‚ï¼Œè°ƒç”¨ `len(obj)` æ—¶ä¼šè§¦å‘æ­¤æ–¹æ³•ã€‚

   ```python
   def __len__(self):
       return len(self.items)
   ```

5. **`__getitem__`**
   ç”¨äºè·å–å¯¹è±¡ä¸­çš„å…ƒç´ ï¼Œé€šå¸¸ç”¨äºå®ç°ç±»ä¼¼äºåˆ—è¡¨ã€å­—å…¸çš„ç´¢å¼•æ“ä½œã€‚
   ç”¨æ³•ï¼š`obj[key]` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

   ```python
   def __getitem__(self, index):
       return self.items[index]
   ```

6. **`__setitem__`**
   ç”¨äºè®¾ç½®å¯¹è±¡ä¸­çš„å…ƒç´ ã€‚
   ç”¨æ³•ï¼š`obj[key] = value` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

   ```python
   def __setitem__(self, index, value):
       self.items[index] = value
   ```

7. **`__delitem__`**
   ç”¨äºåˆ é™¤å¯¹è±¡ä¸­çš„å…ƒç´ ã€‚
   ç”¨æ³•ï¼š`del obj[key]` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

   ```python
   def __delitem__(self, index):
       del self.items[index]
   ```

8. **`__iter__`**
   ä½¿å¯¹è±¡å¯è¿­ä»£ï¼Œè¿”å›ä¸€ä¸ªè¿­ä»£å™¨ã€‚
   ç”¨æ³•ï¼š`for item in obj` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

   ```python
   def __iter__(self):
       return iter(self.items)
   ```

9. **`__next__`**
   ç”¨äºå®ç°è¿­ä»£å™¨åè®®ï¼Œè¿”å›ä¸‹ä¸€ä¸ªå€¼ã€‚
   ç”¨æ³•ï¼š`next(obj)` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

   ```python
   def __next__(self):
       if self.index < len(self.items):
           result = self.items[self.index]
           self.index += 1
           return result
       else:
           raise StopIteration
   ```

10. **`__contains__`**
    ç”¨äºæ£€æŸ¥æŸä¸ªå…ƒç´ æ˜¯å¦åœ¨å¯¹è±¡ä¸­ã€‚
    ç”¨æ³•ï¼š`item in obj` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

    ```python
    def __contains__(self, item):
        return item in self.items
    ```

11. **`__eq__`**
    ç”¨äºæ¯”è¾ƒä¸¤ä¸ªå¯¹è±¡æ˜¯å¦ç›¸ç­‰ã€‚
    ç”¨æ³•ï¼š`obj1 == obj2` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

    ```python
    def __eq__(self, other):
        return self.value == other.value
    ```

12. **`__ne__`**
    ç”¨äºæ¯”è¾ƒä¸¤ä¸ªå¯¹è±¡æ˜¯å¦ä¸ç›¸ç­‰ã€‚
    ç”¨æ³•ï¼š`obj1 != obj2` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

    ```python
    def __ne__(self, other):
        return self.value != other.value
    ```

13. **`__lt__`**
    ç”¨äºæ¯”è¾ƒä¸¤ä¸ªå¯¹è±¡çš„å¤§å°ï¼ˆå°äºï¼‰ã€‚
    ç”¨æ³•ï¼š`obj1 < obj2` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

    ```python
    def __lt__(self, other):
        return self.value < other.value
    ```

14. **`__le__`**
    ç”¨äºæ¯”è¾ƒä¸¤ä¸ªå¯¹è±¡çš„å¤§å°ï¼ˆå°äºæˆ–ç­‰äºï¼‰ã€‚
    ç”¨æ³•ï¼š`obj1 <= obj2` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

    ```python
    def __le__(self, other):
        return self.value <= other.value
    ```

15. **`__gt__`**
    ç”¨äºæ¯”è¾ƒä¸¤ä¸ªå¯¹è±¡çš„å¤§å°ï¼ˆå¤§äºï¼‰ã€‚
    ç”¨æ³•ï¼š`obj1 > obj2` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

    ```python
    def __gt__(self, other):
        return self.value > other.value
    ```

16. **`__ge__`**
    ç”¨äºæ¯”è¾ƒä¸¤ä¸ªå¯¹è±¡çš„å¤§å°ï¼ˆå¤§äºæˆ–ç­‰äºï¼‰ã€‚
    ç”¨æ³•ï¼š`obj1 >= obj2` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

    ```python
    def __ge__(self, other):
        return self.value >= other.value
    ```

17. **`__add__`**
    ç”¨äºå®šä¹‰åŠ æ³•æ“ä½œã€‚
    ç”¨æ³•ï¼š`obj1 + obj2` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

    ```python
    def __add__(self, other):
        return self.value + other.value
    ```

18. **`__sub__`**
    ç”¨äºå®šä¹‰å‡æ³•æ“ä½œã€‚
    ç”¨æ³•ï¼š`obj1 - obj2` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

    ```python
    def __sub__(self, other):
        return self.value - other.value
    ```

19. **`__mul__`**
    ç”¨äºå®šä¹‰ä¹˜æ³•æ“ä½œã€‚
    ç”¨æ³•ï¼š`obj1 * obj2` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

    ```python
    def __mul__(self, other):
        return self.value * other.value
    ```

20. **`__truediv__`**
    ç”¨äºå®šä¹‰é™¤æ³•æ“ä½œï¼ˆè¿”å›æµ®ç‚¹æ•°ç»“æœï¼‰ã€‚
    ç”¨æ³•ï¼š`obj1 / obj2` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

    ```python
    def __truediv__(self, other):
        return self.value / other.value
    ```

21. **`__floordiv__`**
    ç”¨äºå®šä¹‰æ•´é™¤æ“ä½œã€‚
    ç”¨æ³•ï¼š`obj1 // obj2` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

    ```python
    def __floordiv__(self, other):
        return self.value // other.value
    ```

22. **`__mod__`**
    ç”¨äºå®šä¹‰å–ä½™æ“ä½œã€‚
    ç”¨æ³•ï¼š`obj1 % obj2` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

    ```python
    def __mod__(self, other):
        return self.value % other.value
    ```

23. **`__pow__`**
    ç”¨äºå®šä¹‰å¹‚è¿ç®—ã€‚
    ç”¨æ³•ï¼š`obj1 ** obj2` ä¼šè°ƒç”¨æ­¤æ–¹æ³•ã€‚

    ```python
    def __pow__(self, other):
        return self.value ** other.value
    ```

è¿™äº›ç‰¹æ®Šæ–¹æ³•ä½¿å¾—ä½ å¯ä»¥è‡ªå®šä¹‰å¯¹è±¡çš„è¡Œä¸ºï¼Œåƒå†…å»ºç±»å‹ä¸€æ ·è¿›è¡Œæ“ä½œã€‚ä½ å¯ä»¥é€šè¿‡é‡å†™è¿™äº›æ–¹æ³•æ¥å®ç°è‡ªå®šä¹‰çš„è¿ç®—ã€æ¯”è¾ƒã€å“ˆå¸Œç­‰æ“ä½œã€‚


# manual backpropagation example #1: simple expression

in those gradients and actually do back propagation manually so let's start filling in these gradients and start all
the way at the end as i mentioned here first we are interested to fill in this gradient here so what is the derivative
of l with respect to l in other words if i change l by a tiny amount of h
how much does l change it changes by h so it's proportional and
therefore derivative will be one we can of course measure these or estimate these numerical gradients
numerically just like we've seen before so if i take this expression and i create a def lol function here
and put this here now the reason i'm creating a gating function hello here is because i don't want to pollute or mess
up the global scope here this is just kind of like a little staging area and as you know in python all of these will
be local variables to this function so i'm not changing any of the global scope here
so here l1 will be l and then copy pasting this expression
we're going to add a small amount h in for example a
right and this would be measuring the derivative of l with respect to a so here this will be l2
and then we want to print this derivative so print l2 minus l1 which is how much l changed
and then normalize it by h so this is the rise over run and we have to be careful because l is a
value node so we actually want its data um so that these are floats dividing by h
and this should print the derivative of l with respect to a because a is the one that we bumped a little bit by h
so what is the derivative of l with respect to a it's six
okay and obviously if we change l by h
then that would be here effectively
this looks really awkward but changing l by h you see the derivative here is 1. um
that's kind of like the base case of what we are doing here so basically we cannot come up here and
we can manually set l.grad to one this is our manual back propagation
l dot grad is one and let's redraw and we'll see that we filled in grad as
1 for l we're now going to continue the back propagation so let's here look at the derivatives of l with respect to d and f
let's do a d first so what we are interested in if i create a markdown on here is we'd like to know
basically we have that l is d times f and we'd like to know what is uh d
l by d d what is that and if you know your calculus uh l is d
times f so what is d l by d d it would be f and if you don't believe me we can also
just derive it because the proof would be fairly straightforward uh we go to the
definition of the derivative which is f of x plus h minus f of x divide h
as a limit limit of h goes to zero of this kind of expression so when we have l is d times f
then increasing d by h would give us the output of b plus h
times f that's basically f of x plus h right
minus d times f and then divide h and symbolically
expanding out here we would have basically d times f plus h times f minus
t times f divide h and then you see how the df minus df cancels so you're left with h times f
divide h which is f so in the limit as h goes to zero of
you know derivative definition we just get f in the case of
d times f so symmetrically dl by d
f will just be d so what we have is that f dot grad
we see now is just the value of d which is 4.
and we see that d dot grad is just uh the value of f
and so the value of f is negative two so we'll set those manually
let me erase this markdown node and then let's redraw what we have
okay and let's just make sure that these were correct so we seem to think that dl by
dd is negative two so let's double check um let me erase this plus h from before
and now we want the derivative with respect to f so let's just come here when i create f and let's do a plus h here and this
should print the derivative of l with respect to f so we expect to see four
yeah and this is four up to floating point funkiness and then dl by dd
should be f which is negative two grad is negative two
so if we again come here and we change d
d dot data plus equals h right here so we expect so we've added a little h
and then we see how l changed and we expect to print uh negative two
there we go so we've numerically verified what we're doing here is what kind of like an
inline gradient check gradient check is when we are deriving this like back propagation
and getting the derivative with respect to all the intermediate results and then numerical gradient is just you know
estimating it using small step size now we're getting to the crux of backpropagation so this will be the most
important node to understand because if you understand the gradient for this node you understand all of back
propagation and all of training of neural nets basically so we need to derive dl by bc
in other words the derivative of l with respect to c because we've computed all these other gradients already
now we're coming here and we're continuing the back propagation manually so we want dl by dc and then we'll also
derive dl by de now here's the problem how do we derive dl
by dc we actually know the derivative l with respect to d so we know how l assessed
it to d but how is l sensitive to c so if we wiggle c how does that impact l
through d so we know dl by dc
and we also here know how c impacts d and so just very intuitively if you know the impact that c is having on d and the
impact that d is having on l then you should be able to somehow put that information together to figure out
how c impacts l and indeed this is what we can actually do so in particular we know just
concentrating on d first let's look at how what is the derivative basically of d with respect to c so in other words
what is dd by dc so here we know that d is c times c plus
e that's what we know and now we're interested in dd by dc if you just know your calculus again and
you remember that differentiating c plus e with respect to c you know that that gives you
1.0 and we can also go back to the basics and derive this because again we can go
to our f of x plus h minus f of x divide by h that's the definition of a derivative as
h goes to zero and so here focusing on c and its effect on d
we can basically do the f of x plus h will be c is incremented by h plus e
that's the first evaluation of our function minus c plus e
and then divide h and so what is this uh just expanding this out this will be
c plus h plus e minus c minus e divide h and then you see here how c
minus c cancels e minus e cancels we're left with h over h which is 1.0
and so by symmetry also d d by d
e will be 1.0 as well so basically the derivative of a sum
expression is very simple and and this is the local derivative so i call this the local derivative because we have the
final output value all the way at the end of this graph and we're now like a small node here and this is a little plus node
and it the little plus node doesn't know anything about the rest of the graph that it's embedded in all it knows is
that it did a plus it took a c and an e added them and created d and this plus note also knows the local
influence of c on d or rather rather the derivative of d with respect to c and it
also knows the derivative of d with respect to e but that's not what we want that's just a local derivative what we actually
want is d l by d c and l could l is here just one step away but in a general case
this little plus note is could be embedded in like a massive graph so
again we know how l impacts d and now we know how c and e impact d how do we put
that information together to write dl by dc and the answer of course is the chain rule in calculus
and so um i pulled up a chain rule here from kapedia
and i'm going to go through this very briefly so chain rule wikipedia sometimes can be very
confusing and calculus can can be very confusing like this is the way i
learned chain rule and it was very confusing like what is happening it's just complicated so i like this expression
much better if a variable z depends on a variable y which itself depends on the variable x
then z depends on x as well obviously through the intermediate variable y in this case the chain rule is expressed
as if you want dz by dx then you take the dz by dy and you
multiply it by d y by dx so the chain rule fundamentally is telling you
how we chain these uh derivatives together
correctly so to differentiate through a function composition we have to apply a multiplication
of those derivatives so that's really what chain rule is telling us
and there's a nice little intuitive explanation here which i also think is kind of cute the chain rule says that
knowing the instantaneous rate of change of z with respect to y and y relative to x allows one to calculate the instantaneous rate of change of z
relative to x as a product of those two rates of change simply the product of those two
so here's a good one if a car travels twice as fast as bicycle and the bicycle is four times as
fast as walking man then the car travels two times four eight times as fast as demand
and so this makes it very clear that the correct thing to do sort of is to multiply
so cars twice as fast as bicycle and bicycle is four times as fast as man
so the car will be eight times as fast as the man and so we can take these
intermediate rates of change if you will and multiply them together and that justifies the
chain rule intuitively so have a look at chain rule about here really what it means for us is there's a very simple
recipe for deriving what we want which is dl by dc and what we have so far
is we know want and we know
what is the impact of d on l so we know d l by
d d the derivative of l with respect to d d we know that that's negative two and now because of this local
reasoning that we've done here we know dd by d c
so how does c impact d and in particular this is a plus node so the
local derivative is simply 1.0 it's very simple and so the chain rule tells us that dl by dc
going through this intermediate variable will just be simply d l by
d times
dd by dc that's chain rule so this is identical to what's happening
here except z is rl y is our d and x is rc
so we literally just have to multiply these and because
these local derivatives like dd by dc are just one we basically just copy over dl by dd
because this is just times one so what does it do so because dl by dd is negative two what is dl by dc
well it's the local gradient 1.0 times dl by dd which is negative two
so literally what a plus node does you can look at it that way is it literally just routes the gradient
because the plus nodes local derivatives are just one and so in the chain rule one times
dl by dd is um is uh is just dl by dd and so that
derivative just gets routed to both c and to e in this case
so basically um we have that that grad or let's start with c since that's the
one we looked at is negative two times one
negative two and in the same way by symmetry e that grad will be negative two that's the
claim so we can set those we can redraw
and you see how we just assign negative to negative two so this backpropagating signal which is carrying the information
of like what is the derivative of l with respect to all the intermediate nodes we can imagine it almost like flowing
backwards through the graph and a plus node will simply distribute the derivative to all the leaf nodes sorry
to all the children nodes of it so this is the claim and now let's verify it so let me remove the plus h
here from before and now instead what we're going to do is we're going to increment c so c dot
data will be credited by h and when i run this we expect to see negative 2
negative 2. and then of course for e so e dot data plus equals h and we
expect to see negative 2. simple
so those are the derivatives of these internal nodes and now we're going to recurse our way
backwards again and we're again going to apply the chain rule so here we go our second
application of chain rule and we will apply it all the way through the graph we just happen to only have one more node remaining
we have that d l by d e as we have just calculated is negative two so we know that
so we know the derivative of l with respect to e and now we want dl
by da right and the chain rule is telling us that that's just dl by de
negative 2 times the local gradient so what is the local gradient basically d e
by d a we have to look at that so i'm a little times node
inside a massive graph and i only know that i did a times b and i produced an e
so now what is d e by d a and d e by d b that's the only thing that i sort of
know about that's my local gradient so because we have that e's a times b we're
asking what is d e by d a and of course we just did that here we
had a times so i'm not going to rederive it but if you want to differentiate this
with respect to a you'll just get b right the value of b which in this case is negative 3.0
so basically we have that dl by da well let me just do it right here we
have that a dot grad and we are applying chain rule here is d l by d e which we see here is
negative two times what is d e by d a
it's the value of b which is negative 3.
that's it and then we have b grad is again dl by
de which is negative 2 just the same way times what is d e by d
um db is the value of a which is 2.2.0
as the value of a so these are our claimed derivatives
let's redraw and we see here that a dot grad turns out to be 6 because
that is negative 2 times negative 3 and b dot grad is negative 4
times sorry is negative 2 times 2 which is negative 4. so those are our claims let's delete
this and let's verify them we have
a here a dot data plus equals h so the claim is that
a dot grad is six let's verify six
and we have beta data plus equals h so nudging b by h
and looking at what happens we claim it's negative four and indeed it's negative four plus minus
again float oddness um and uh
that's it this that was the manual back propagation
uh all the way from here to all the leaf nodes and we've done it piece by piece and really all we've done is as you saw
we iterated through all the nodes one by one and locally applied the chain rule we always know what is the derivative of
l with respect to this little output and then we look at how this output was produced this output was produced
through some operation and we have the pointers to the children nodes of this operation
and so in this little operation we know what the local derivatives are and we just multiply them onto the derivative
always so we just go through and recursively multiply on the local derivatives and
that's what back propagation is is just a recursive application of chain rule backwards through the computation graph

è¿™æ®µå†…å®¹è®²è§£äº†å¦‚ä½•æ‰‹åŠ¨è¿›è¡Œåå‘ä¼ æ’­ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•è®¡ç®—ç¥ç»ç½‘ç»œä¸­çš„æ¢¯åº¦ï¼Œå¹¶é€šè¿‡é€’å½’åº”ç”¨é“¾å¼æ³•åˆ™ï¼ˆchain ruleï¼‰æ¥æ›´æ–°æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦ã€‚

### **æ¦‚è¿°**

* **åå‘ä¼ æ’­**ï¼šåå‘ä¼ æ’­çš„æ ¸å¿ƒä»»åŠ¡æ˜¯è®¡ç®—æŸå¤±å‡½æ•°ï¼ˆ`l`ï¼‰ç›¸å¯¹äºç½‘ç»œä¸­æ¯ä¸ªå‚æ•°ï¼ˆæˆ–èŠ‚ç‚¹ï¼‰çš„å¯¼æ•°ï¼ˆå³æ¢¯åº¦ï¼‰ï¼Œç„¶ååˆ©ç”¨è¿™äº›æ¢¯åº¦æ¥è°ƒæ•´ç½‘ç»œçš„æƒé‡ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æ‰‹åŠ¨è®¡ç®—æ¢¯åº¦ï¼Œç†è§£æ¢¯åº¦æ˜¯å¦‚ä½•ä»è¾“å‡ºå±‚å‘è¾“å…¥å±‚ä¼ æ’­çš„ã€‚

### **æ­¥éª¤è§£é‡Š**

#### 1. **è®¡ç®—æŸå¤±å¯¹è¾“å‡ºçš„æ¢¯åº¦**ï¼š

* æˆ‘ä»¬ä»æœ€ç»ˆè¾“å‡º `l` å¼€å§‹ï¼Œé¦–å…ˆè®¡ç®—æŸå¤±å¯¹ `l` è‡ªèº«çš„å¯¼æ•°ã€‚ç”±äº `l` æ˜¯æŸå¤±å‡½æ•°è‡ªèº«ï¼Œå› æ­¤å®ƒçš„å¯¼æ•°æ˜¯1ï¼Œè¡¨ç¤ºå¦‚æœ `l` å¢åŠ ä¸€ä¸ªå°é‡ `h`ï¼Œ`l` å˜åŒ–çš„æ¯”ä¾‹æ˜¯ 1ã€‚

* **æ¢¯åº¦èµ‹å€¼**ï¼šåœ¨ä»£ç ä¸­ï¼Œæˆ‘ä»¬æ‰‹åŠ¨å°† `l.grad` è®¾ç½®ä¸º1ï¼Œè¿™è¡¨ç¤ºè¾“å‡ºå±‚çš„æ¢¯åº¦ä¸º1ï¼Œä½œä¸ºåå‘ä¼ æ’­çš„èµ·å§‹ç‚¹ã€‚

#### 2. **è®¡ç®—æŸå¤±å¯¹ä¸­é—´èŠ‚ç‚¹çš„æ¢¯åº¦**ï¼š

* æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ ¹æ®é“¾å¼æ³•åˆ™ï¼ˆChain Ruleï¼‰è®¡ç®—å…¶ä»–èŠ‚ç‚¹çš„æ¢¯åº¦ã€‚

* **æŸå¤±å¯¹ `d` çš„æ¢¯åº¦ï¼ˆ`dl/dD`ï¼‰**ï¼šå¦‚æœ `l = d * f`ï¼Œé‚£ä¹ˆ `dl/dD = f`ã€‚è¿™æ„å‘³ç€ï¼Œå¦‚æœæˆ‘ä»¬æ”¹å˜ `d`ï¼ŒæŸå¤± `l` çš„å˜åŒ–æ˜¯é€šè¿‡ `f` çš„å€¼æ¥å†³å®šçš„ã€‚ä»£ç ä¸­é€šè¿‡è®¡ç®— `d.grad`ï¼Œæˆ‘ä»¬å¾—åˆ°äº† `f` çš„å€¼ã€‚

* **æŸå¤±å¯¹ `f` çš„æ¢¯åº¦ï¼ˆ`dl/dF`ï¼‰**ï¼šç”±äº `l = d * f`ï¼Œå› æ­¤ `dl/dF = d`ã€‚è¿™è¡¨ç¤º `f` å¯¹ `l` çš„å½±å“æ˜¯ç”± `d` æ¥å†³å®šçš„ã€‚

#### 3. **åå‘ä¼ æ’­åˆ°æ›´æ—©çš„èŠ‚ç‚¹**ï¼š

* æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬é€šè¿‡é“¾å¼æ³•åˆ™ç»§ç»­å‘å‰ä¼ æ’­ã€‚

* **æŸå¤±å¯¹ `c` å’Œ `e` çš„æ¢¯åº¦ï¼ˆ`dl/dC` å’Œ `dl/dE`ï¼‰**ï¼šæ ¹æ®å‰é¢çš„æ“ä½œï¼Œ`d = c + e`ï¼Œå› æ­¤ `dd/dc = 1` å’Œ `dd/de = 1`ã€‚æ‰€ä»¥ï¼Œ`dl/dc = dl/dd * dd/dc = -2 * 1 = -2`ï¼Œ`dl/de = dl/dd * dd/de = -2 * 1 = -2`ã€‚è¿™è¡¨ç¤º `c` å’Œ `e` å¯¹ `d` çš„å½±å“æ˜¯ä¸€æ ·çš„ï¼Œéƒ½ç­‰äº -2ã€‚

* **ç»§ç»­åº”ç”¨é“¾å¼æ³•åˆ™**ï¼š

  * ç”±äº `d = a * b`ï¼Œè®¡ç®— `dl/da` å’Œ `dl/db` æ—¶ï¼Œå¯ä»¥é€šè¿‡é“¾å¼æ³•åˆ™å°†æ¢¯åº¦ä¼ æ’­åˆ° `a` å’Œ `b`ã€‚
  * å¯¹äº `a`ï¼Œæœ‰ `dl/da = dl/de * de/da = -2 * (-3) = 6`ã€‚
  * å¯¹äº `b`ï¼Œæœ‰ `dl/db = dl/de * de/db = -2 * 2 = -4`ã€‚

#### 4. **éªŒè¯æ¢¯åº¦è®¡ç®—**ï¼š

* æœ€åï¼Œæˆ‘ä»¬é€šè¿‡å¢åŠ  `h` æ¥éªŒè¯æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦è®¡ç®—æ˜¯å¦æ­£ç¡®ã€‚å¯¹äº `a`ï¼ŒæœŸæœ›çš„æ¢¯åº¦æ˜¯ 6ï¼›å¯¹äº `b`ï¼ŒæœŸæœ›çš„æ¢¯åº¦æ˜¯ -4ã€‚é€šè¿‡ä»£ç çš„æ•°å€¼è®¡ç®—ï¼Œç¡®å®å¾—åˆ°äº†è¿™äº›ç»“æœã€‚

### **é“¾å¼æ³•åˆ™çš„åº”ç”¨**ï¼š

é“¾å¼æ³•åˆ™æ˜¯åå‘ä¼ æ’­çš„æ ¸å¿ƒã€‚é€šè¿‡é“¾å¼æ³•åˆ™ï¼Œæˆ‘ä»¬å¯ä»¥é€’å½’åœ°è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦ã€‚æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦ä¸ä»…å–å†³äºå®ƒçš„å±€éƒ¨å¯¼æ•°ï¼Œè¿˜è¦ä¹˜ä»¥ä¸Šæ¸¸èŠ‚ç‚¹çš„æ¢¯åº¦ã€‚åå‘ä¼ æ’­é€šè¿‡é€’å½’åœ°åº”ç”¨è¿™ä¸€æ³•åˆ™ï¼Œå°†æ¢¯åº¦ä»è¾“å‡ºå±‚ä¼ æ’­å›è¾“å…¥å±‚ã€‚

### **æ€»ç»“**ï¼š

1. **ä»è¾“å‡ºå±‚å¼€å§‹**ï¼Œæ‰‹åŠ¨è®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦ã€‚
2. **ä½¿ç”¨é“¾å¼æ³•åˆ™**ï¼Œå°†æ¢¯åº¦ä»è¾“å‡ºå±‚ä¼ é€’åˆ°æ¯ä¸ªä¸­é—´èŠ‚ç‚¹ã€‚
3. **æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦**ç”±å®ƒçš„å±€éƒ¨æ¢¯åº¦å’Œä¸Šæ¸¸èŠ‚ç‚¹çš„æ¢¯åº¦å†³å®šã€‚
4. æœ€ç»ˆï¼Œé€šè¿‡æ•°å€¼æ£€æŸ¥éªŒè¯è®¡ç®—ç»“æœã€‚

è¿™æ®µä»£ç å’Œè®²è§£å¸®åŠ©ç†è§£å¦‚ä½•æ‰‹åŠ¨å®ç°åå‘ä¼ æ’­ï¼Œå¹¶è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£ç¥ç»ç½‘ç»œä¸­æ¢¯åº¦æ˜¯å¦‚ä½•ä¼ æ’­çš„ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨æ¢¯åº¦æ›´æ–°å‚æ•°ã€‚


# preview of a single optimization step

let's see this power in action just very briefly what we're going to do is we're going to
nudge our inputs to try to make l go up so in particular what we're doing is we
want a.data we're going to change it and if we want l to go up that means we just have to go in the direction of the
gradient so a should increase in the direction of gradient by like some small step amount
this is the step size and we don't just want this for ba but also for b
also for c also for f those are
leaf nodes which we usually have control over and if we nudge in direction of the
gradient we expect a positive influence on l so we expect l to go up
positively so it should become less negative it should go up to say negative you know
six or something like that uh it's hard to tell exactly and we'd have to rewrite the forward pass so let
me just um do that here um
this would be the forward pass f would be unchanged this is effectively the forward pass and now if we print l.data
we expect because we nudged all the values all the inputs in the rational gradient we expected a less negative l
we expect it to go up so maybe it's negative six or so let's see what happens
okay negative seven and uh this is basically one step of an
optimization that we'll end up running and really does gradient just give us some power because we know how to
influence the final outcome and this will be extremely useful for training knowledge as well as you'll see

è¿™æ®µå†…å®¹è®²è§£äº†ä¸€ä¸ªä¼˜åŒ–æ­¥éª¤çš„é¢„è§ˆï¼Œå±•ç¤ºäº†å¦‚ä½•é€šè¿‡æ¢¯åº¦æ›´æ–°è¾“å…¥å€¼ï¼Œä»è€Œå½±å“æœ€ç»ˆçš„æŸå¤±å€¼ï¼ˆ`l`ï¼‰ã€‚è¿™æ˜¯ä¼˜åŒ–ç®—æ³•ï¼ˆå¦‚æ¢¯åº¦ä¸‹é™ï¼‰çš„ä¸€éƒ¨åˆ†ï¼Œå®ƒèƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬é€æ­¥è°ƒæ•´ç¥ç»ç½‘ç»œçš„å‚æ•°ï¼Œä½¿å¾—æŸå¤±å‡½æ•°å˜å°ï¼Œä»è€Œè®©æ¨¡å‹å˜å¾—æ›´å¥½ã€‚

### **æ ¸å¿ƒæ€æƒ³**

1. **æ¢¯åº¦çš„ä½œç”¨**ï¼š

   * æ¢¯åº¦è¡¨ç¤ºäº†æŸå¤±å‡½æ•°å¯¹æŸä¸ªå‚æ•°çš„æ•æ„Ÿåº¦æˆ–å˜åŒ–ç‡ã€‚å…·ä½“æ¥è¯´ï¼Œæ¢¯åº¦æŒ‡ç¤ºäº†å¦‚æœæˆ‘ä»¬æ”¹å˜æŸä¸ªå‚æ•°ï¼ŒæŸå¤±å‡½æ•°ä¼šæœå“ªä¸ªæ–¹å‘å˜åŒ–ï¼Œå˜åŒ–çš„é€Ÿç‡æœ‰å¤šå¤§ã€‚
   * æˆ‘ä»¬å¸Œæœ›é€šè¿‡è°ƒæ•´è¾“å…¥ï¼ˆæˆ–ç½‘ç»œä¸­çš„å‚æ•°ï¼‰ï¼Œä½¿å¾—æŸå¤±å‡½æ•°çš„å€¼ä¸‹é™ï¼ˆæ›´æ¥è¿‘æœ€å°å€¼ï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦æ²¿ç€æ¢¯åº¦çš„æ–¹å‘è°ƒæ•´è¾“å…¥å€¼ï¼Œæœç€ä½¿æŸå¤±å‡½æ•°å‡å°‘çš„æ–¹å‘â€œèµ°â€ã€‚

2. **ä¼˜åŒ–è¿‡ç¨‹**ï¼š

   * åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡â€œå¾®è°ƒâ€è¾“å…¥å€¼ `a`ã€`b`ã€`c` å’Œ `f` æ¥è®©æŸå¤±å‡½æ•° `l` å¢åŠ ï¼ˆå³å˜å¾—æ›´å°‘è´Ÿï¼‰ã€‚è°ƒæ•´çš„æ­¥éª¤æ˜¯æ²¿ç€æ¢¯åº¦çš„æ–¹å‘è¿›è¡Œçš„ï¼Œç§°ä¸º **æ¢¯åº¦ä¸Šå‡**ï¼Œå³å¦‚æœæˆ‘ä»¬æƒ³è®© `l` å¢åŠ ï¼Œæˆ‘ä»¬å°±åº”è¯¥æœç€æ¢¯åº¦çš„æ–¹å‘è°ƒæ•´è¾“å…¥ã€‚

   * å¯¹äºæ¯ä¸ªè¾“å…¥èŠ‚ç‚¹ï¼ˆ`a`ã€`b`ã€`c` å’Œ `f`ï¼‰ï¼Œæˆ‘ä»¬æ ¹æ®å®ƒä»¬çš„æ¢¯åº¦å€¼æ¥è°ƒæ•´å®ƒä»¬çš„å€¼ã€‚è°ƒæ•´åçš„ç›®æ ‡æ˜¯ä½¿æŸå¤± `l` å¢åŠ ï¼ˆå˜å¾—æ›´ä¸è´Ÿï¼‰ï¼Œè€Œä¸æ˜¯ä¸‹é™ã€‚

   * è¿™å°±æ˜¯ä¸€ä¸ªç®€å•çš„â€œä¼˜åŒ–æ­¥éª¤â€ï¼Œä¹Ÿå°±æ˜¯ä¸€æ¬¡ **æ¢¯åº¦ä¸Šå‡**ï¼Œä½¿å¾—æŸå¤±å€¼ä»æ›´è´Ÿçš„æ•°å€¼ï¼ˆå¦‚ -8ï¼‰å˜å¾—ç¨å¾®ä¸é‚£ä¹ˆè´Ÿï¼ˆå¦‚ -7ï¼‰ã€‚

3. **é¢„æµ‹çš„ç»“æœ**ï¼š

   * é€šè¿‡è¿™ä¸ªæ­¥éª¤ï¼Œæˆ‘ä»¬å¯ä»¥é¢„æœŸï¼Œç»è¿‡ä¸€å°æ­¥è°ƒæ•´åï¼ŒæŸå¤± `l` ä¼šå˜å¾—æ›´åŠ æ¥è¿‘äºç›®æ ‡å€¼ï¼ˆä¾‹å¦‚ -6ï¼‰ï¼Œå› ä¸ºæˆ‘ä»¬æ²¿ç€æ¢¯åº¦æ–¹å‘å¯¹ `a`ã€`b`ã€`c` å’Œ `f` è¿›è¡Œäº†è°ƒæ•´ã€‚
   * ç„¶è€Œï¼Œåœ¨å®é™…æ‰§è¡Œæ—¶ï¼Œç»è¿‡ä¸€æ¬¡ä¼˜åŒ–æ­¥éª¤åï¼ŒæŸå¤±å¹¶æœªå®Œå…¨è¾¾åˆ°é¢„æœŸçš„ç»“æœï¼Œè€Œæ˜¯ç•¥å¾®å‡å°ï¼ˆå˜ä¸º -7ï¼‰ï¼Œè¿™è¡¨æ˜ä¼˜åŒ–æ˜¯ä¸€ä¸ªé€æ­¥çš„è¿‡ç¨‹ï¼Œéœ€è¦å¤šä¸ªæ­¥éª¤æ‰èƒ½çœŸæ­£è¾¾åˆ°é¢„æœŸç›®æ ‡ã€‚

### **æ€»ç»“**

* é€šè¿‡å¯¹è¾“å…¥å€¼è¿›è¡Œå¾®å°çš„è°ƒæ•´ï¼Œå¹¶æ²¿ç€æ¢¯åº¦çš„æ–¹å‘è¿›è¡Œæ›´æ–°ï¼Œæˆ‘ä»¬èƒ½å¤Ÿå½±å“æœ€ç»ˆçš„æŸå¤±å‡½æ•°ã€‚è¿™ä¸ªè¿‡ç¨‹å±•ç¤ºäº†æ¢¯åº¦ä¸‹é™ï¼ˆæˆ–æ¢¯åº¦ä¸Šå‡ï¼‰ä¼˜åŒ–æ–¹æ³•çš„ä¸€ä¸ªæ­¥éª¤ã€‚è™½ç„¶ç»è¿‡ä¸€æ¬¡ä¼˜åŒ–åï¼ŒæŸå¤±å‡½æ•°å¹¶æ²¡æœ‰å®Œå…¨è¾¾åˆ°ç›®æ ‡å€¼ï¼Œä½†å®ƒçš„å€¼å·²ç»å˜å¾—ç¨å¾®æ›´â€œå¥½â€äº†ã€‚è¿™æ˜¯è®­ç»ƒç¥ç»ç½‘ç»œè¿‡ç¨‹ä¸­é€æ­¥ä¼˜åŒ–æ¨¡å‹çš„ä¸€ä¸ªå…¸å‹ç¤ºä¾‹ã€‚


# manual backpropagation example #2: a neuron

so now i would like to do one more uh example of manual backpropagation using
a bit more complex and uh useful example we are going to back propagate through a
neuron so we want to eventually build up neural networks and in the simplest case these
are multilateral perceptrons as they're called so this is a two layer neural net and it's got these hidden layers made up
of neurons and these neurons are fully connected to each other now biologically neurons are very complicated devices but we have very
simple mathematical models of them and so this is a very simple mathematical model of a neuron you have
some inputs axis and then you have these synapses that have weights on them so
the w's are weights and then the synapse interacts with the input to
this neuron multiplicatively so what flows to the cell body of this neuron is w times x
but there's multiple inputs so there's many w times x's flowing into the cell body
the cell body then has also like some bias so this is kind of like the inert innate sort of trigger happiness
of this neuron so this bias can make it a bit more trigger happy or a bit less trigger happy regardless of the input
but basically we're taking all the w times x of all the inputs adding the bias and
then we take it through an activation function and this activation function is usually some kind of a squashing function
like a sigmoid or 10h or something like that so as an example we're going to use the 10h in this
example numpy has a np.10h so
we can call it on a range and we can plot it this is the 10h function and you see
that the inputs as they come in get squashed on the y coordinate here so
um right at zero we're going to get exactly zero and then as you go more positive in
the input then you'll see that the function will only go up to one and then plateau out
and so if you pass in very positive inputs we're gonna cap it smoothly at one and on the negative side we're gonna
cap it smoothly to negative one so that's 10h and that's the squashing function or an
activation function and what comes out of this neuron is just the activation function applied to the dot product of
the weights and the inputs so let's write one out
um i'm going to copy paste because
i don't want to type too much but okay so here we have the inputs x1 x2 so this is a two-dimensional
neuron so two inputs are going to come in these are thought out as the weights of this neuron
weights w1 w2 and these weights again are the synaptic strengths for each
input and this is the bias of the neuron b
and now we want to do is according to this model we need to multiply x1 times
w1 and x2 times w2 and then we need to add bias on top of
it and it gets a little messy here but all we are trying to do is x1 w1 plus x2 w2
plus b and these are multiply here except i'm doing it in small steps so
that we actually have pointers to all these intermediate nodes so we have x1 w1 variable x times x2 w2 variable and
i'm also labeling them so n is now the cell body raw
raw activation without the activation function for now
and this should be enough to basically plot it so draw dot of n
gives us x1 times w1 x2 times w2 being added
then the bias gets added on top of this and this n is this sum
so we're now going to take it through an activation function and let's say we use the 10h
so that we produce the output so what we'd like to do here is we'd like to do the output and i'll call it o
is um n dot 10h okay but we haven't yet written the 10h
now the reason that we need to implement another 10h function here is that tanh is a
hyperbolic function and we've only so far implemented a plus and the times and you can't make a 10h out of just pluses
and times you also need exponentiation so 10h is this kind of a formula here
you can use either one of these and you see that there's exponentiation involved which we have not implemented yet for
our low value node here so we're not going to be able to produce 10h yet and we have to go back up and implement something like it
now one option here is we could actually implement um
exponentiation right and we could return the x of a value instead of a 10h of a value
because if we had x then we have everything else that we need so um because we know how to add and we know
how to um we know how to add and we know how to multiply so we'd be able to create 10h
if we knew how to x but for the purposes of this example i specifically wanted to
show you that we don't necessarily need to have the most atomic pieces
in um in this value object we can actually like create functions at arbitrary
points of abstraction they can be complicated functions but they can be also very very simple functions like a plus and it's totally up to us the only
thing that matters is that we know how to differentiate through any one function so we take some inputs and we
make an output the only thing that matters it can be arbitrarily complex function as long as you know how to
create the local derivative if you know the local derivative of how the inputs impact the output then that's all you
need so we're going to cluster up all of this expression and we're not going to break it down to its atomic
pieces we're just going to directly implement tanh so let's do that depth nh
and then out will be a value of and we need this expression here so
um let me actually copy paste
let's grab n which is a cell.theta and then this i believe is the tan h
math.x of two no n
n minus one over two n plus one maybe i can call this x
just so that it matches exactly okay and now this will be t
and uh children of this node there's just one child and i'm wrapping it in a tuple so this
is a tuple of one object just self and here the name of this operation will be 10h
and we're going to return that okay
so now valley should be implementing 10h and now we can scroll all the way down here
and we can actually do n.10 h and that's going to return the tanhd output of n
and now we should be able to draw it out of o not of n so let's see how that worked
there we go n went through 10 h to produce this output
so now tan h is a sort of our little micro grad supported node
here as an operation and as long as we know the derivative of
10h then we'll be able to back propagate through it now let's see this 10h in action currently it's not squashing too
much because the input to it is pretty low so if the bias was increased to say
eight then we'll see that what's flowing into the 10h now is
two and 10h is squashing it to 0.96 so we're already hitting the tail of this 10h and
it will sort of smoothly go up to 1 and then plateau out over there okay so now i'm going to do something slightly strange i'm going to change
this bias from 8 to this number 6.88 etc
and i'm going to do this for specific reasons because we're about to start back propagation
and i want to make sure that our numbers come out nice they're not like very crazy numbers they're nice numbers that
we can sort of understand in our head let me also add a pose label o is short for output here
so that's zero okay so 0.88 flows into 10 h comes out 0.7 so on
so now we're going to do back propagation and we're going to fill in all the gradients so what is the derivative o with respect
to all the inputs here and of course in the typical neural network setting what we really
care about the most is the derivative of these neurons on the weights specifically the w2 and w1 because those
are the weights that we're going to be changing part of the optimization and the other thing that we have to remember is here we have only a single
neuron but in the neural natives typically have many neurons and they're connected so this is only like a one small neuron
a piece of a much bigger puzzle and eventually there's a loss function that sort of measures the accuracy of the neural net and we're back propagating
with respect to that accuracy and trying to increase it so let's start off by propagation here
in the end what is the derivative of o with respect to o the base case sort of we know
always is that the gradient is just 1.0 so let me fill it in
and then let me split out the drawing function
here and then here cell
clear this output here okay so now when we draw o we'll see that oh
that grad is one so now we're going to back propagate through the tan h so to back propagate through 10h we need
to know the local derivative of 10h so if we have that
o is 10 h of n then what is d o by d n
now what you could do is you could come here and you could take this expression and you could do your calculus derivative taking
um and that would work but we can also just scroll down wikipedia here into a section that hopefully tells us
that derivative uh d by dx of 10 h of x is any of these i like this one 1 minus 10
h square of x so this is 1 minus 10 h of x squared
so basically what this is saying is that d o by d n is
1 minus 10 h of n squared
and we already have 10 h of n that's just o so it's one minus o squared
so o is the output here so the output is this number
data is this number and then
what this is saying is that do by dn is 1 minus this squared so
one minus of that data squared is 0.5 conveniently
so the local derivative of this 10 h operation here is 0.5
and so that would be d o by d n so we can fill in that in that grad
is 0.5 we'll just fill in
so this is exactly 0.5 one half so now we're going to continue the back propagation
this is 0.5 and this is a plus node so how is backprop going to what is that
going to do here and if you remember our previous example a plus is just a distributor of gradient
so this gradient will simply flow to both of these equally and that's because the local derivative of this operation
is one for every one of its nodes so 1 times 0.5 is 0.5
so therefore we know that this node here which we called this
its grad is just 0.5 and we know that b dot grad is also 0.5
so let's set those and let's draw so 0.5
continuing we have another plus 0.5 again we'll just distribute it so 0.5 will flow to both of these
so we can set theirs
x2w2 as well that grad is 0.5 and let's redraw pluses are my favorite
uh operations to back propagate through because it's very simple so now it's flowing into these
expressions is 0.5 and so really again keep in mind what the derivative is telling us at every point in time along
here this is saying that if we want the output of this neuron to increase
then the influence on these expressions is positive on the output both of them are
positive contribution to the output
so now back propagating to x2 and w2 first this is a times node so we know that the
local derivative is you know the other term so if we want to calculate x2.grad
then can you think through what it's going to be
so x2.grad will be w2.data times this x2w2
by grad right and w2.grad will be
x2 that data times x2w2.grad
right so that's the local piece of chain rule
let's set them and let's redraw so here we see that the gradient on our weight 2 is 0 because x2 data was 0
right but x2 will have the gradient 0.5 because data here was 1. and so what's interesting here right is
because the input x2 was 0 then because of the way the times works
of course this gradient will be zero and think about intuitively why that is derivative always tells us the influence
of this on the final output if i wiggle w2 how is the output changing
it's not changing because we're multiplying by zero so because it's not changing there's no derivative and zero is the correct
answer because we're squashing it at zero and let's do it here point five should
come here and flow through this times and so we'll have that x1.grad is
can you think through a little bit what what this should be
the local derivative of times with respect to x1 is going to be w1
so w1 is data times x1 w1 dot grad
and w1.grad will be x1.data times x1 w2 w1 with graph
let's see what those came out to be so this is 0.5 so this would be negative 1.5 and this would be 1.
and we've back propagated through this expression these are the actual final derivatives so if we want this neuron's
output to increase we know that what's necessary is that
w2 we have no gradient w2 doesn't actually matter to this neuron right now but this neuron this weight should uh go
up so if this weight goes up then this neuron's output would have gone up and
proportionally because the gradient is one okay so doing the back propagation manually is obviously ridiculous so we

è¿™æ®µä»£ç è®²è§£äº†ä¸€ä¸ªç®€å•çš„ç¥ç»å…ƒçš„æ‰‹åŠ¨åå‘ä¼ æ’­è¿‡ç¨‹ã€‚è¿™ä¸ªä¾‹å­å±•ç¤ºäº†å¦‚ä½•é€šè¿‡åå‘ä¼ æ’­è®¡ç®—ç¥ç»å…ƒçš„æ¢¯åº¦ï¼Œå¹¶ä¸”é€æ­¥æ›´æ–°æƒé‡ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†çš„è§£é‡Šï¼š

### 1. **ç¥ç»å…ƒæ¨¡å‹**ï¼š

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªéå¸¸ç®€åŒ–çš„ç¥ç»å…ƒæ¨¡å‹ã€‚ç¥ç»å…ƒæœ‰å¤šä¸ªè¾“å…¥ï¼Œæ¯ä¸ªè¾“å…¥éƒ½é€šè¿‡ä¸€ä¸ªåŠ æƒçš„ synapseï¼ˆçªè§¦ï¼‰ä¸ç¥ç»å…ƒè¿æ¥ã€‚æ•°å­¦ä¸Šï¼Œç¥ç»å…ƒçš„è¾“å…¥æ˜¯é€šè¿‡åŠ æƒå’ŒåŠ ä¸Šä¸€ä¸ªåç½®å€¼ï¼ˆbiasï¼‰å¾—åˆ°çš„ï¼Œä¹‹åä¼šé€šè¿‡ä¸€ä¸ªæ¿€æ´»å‡½æ•°ï¼ˆå¦‚ `tanh`ï¼‰å¾—åˆ°ç¥ç»å…ƒçš„è¾“å‡ºã€‚

* **è¾“å…¥**ï¼š`x1` å’Œ `x2`ã€‚
* **æƒé‡**ï¼š`w1` å’Œ `w2`ï¼Œè¡¨ç¤ºè¾“å…¥ `x1` å’Œ `x2` ä¸ç¥ç»å…ƒä¹‹é—´çš„è¿æ¥å¼ºåº¦ã€‚
* **åç½®**ï¼š`b`ï¼Œæ§åˆ¶ç¥ç»å…ƒçš„æ¿€æ´»é˜ˆå€¼ã€‚
* **åŠ æƒå’Œ**ï¼š`n = x1 * w1 + x2 * w2 + b`ï¼Œè¿™æ˜¯ç¥ç»å…ƒçš„â€œåŸå§‹æ¿€æ´»â€ã€‚
* **æ¿€æ´»å‡½æ•°**ï¼šé€šè¿‡ `tanh(n)` å¾—åˆ°æœ€ç»ˆè¾“å‡ºã€‚

### 2. **å®ç° `tanh` æ¿€æ´»å‡½æ•°**ï¼š

`tanh` æ˜¯ä¸€ç§å¸¸è§çš„æ¿€æ´»å‡½æ•°ï¼Œå…¶è¾“å‡ºèŒƒå›´åœ¨ `-1` åˆ° `1` ä¹‹é—´ã€‚å¯¹äºè¾“å…¥ `n`ï¼Œ`tanh(n)` ä¼šå¯¹å…¶è¿›è¡Œå¹³æ»‘çš„å‹ç¼©ï¼Œé¿å…è¿‡å¤§çš„è¾“å…¥å€¼å¯¼è‡´ä¸ç¨³å®šçš„è¾“å‡ºã€‚åœ¨å®ç°æ—¶ï¼Œ`tanh` çš„å…¬å¼æ˜¯ï¼š

$$
\tanh(n) = \frac{e^n - e^{-n}}{e^n + e^{-n}}
$$

ä¸ºäº†æ‰‹åŠ¨è®¡ç®—åå‘ä¼ æ’­ï¼Œä½œè€…å®ç°äº† `tanh` çš„å¯¼æ•°ï¼Œå³ï¼š

$$
\frac{d}{dn} \tanh(n) = 1 - \tanh^2(n)
$$

### 3. **åå‘ä¼ æ’­çš„å¼€å§‹**ï¼š

åœ¨ç¥ç»ç½‘ç»œä¸­ï¼Œåå‘ä¼ æ’­çš„ç›®æ ‡æ˜¯è®¡ç®—æŸå¤±å‡½æ•°ç›¸å¯¹äºæ¯ä¸ªå‚æ•°ï¼ˆæƒé‡å’Œåç½®ï¼‰çš„æ¢¯åº¦ï¼Œç„¶åæ ¹æ®è¿™äº›æ¢¯åº¦æ¥æ›´æ–°æƒé‡ï¼Œä½¿å¾—æŸå¤±æœ€å°åŒ–ã€‚

* **å¼€å§‹åå‘ä¼ æ’­**ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬çŸ¥é“è¾“å‡º `o = tanh(n)`ï¼Œå¹¶ä¸”æŸå¤±å‡½æ•°å¯¹äºè¾“å‡ºçš„æ¢¯åº¦æ˜¯ 1ï¼ˆå³ `âˆ‚L/âˆ‚o = 1`ï¼‰ã€‚
* **åå‘ä¼ æ’­é€šè¿‡ `tanh` æ¿€æ´»å‡½æ•°**ï¼šä¸ºäº†åå‘ä¼ æ’­ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®— `o` ç›¸å¯¹äº `n` çš„æ¢¯åº¦ã€‚ç”±äº `o = tanh(n)`ï¼Œæˆ‘ä»¬ç”¨ `tanh` çš„å¯¼æ•°æ¥è®¡ç®— `âˆ‚o/âˆ‚n = 1 - o^2`ï¼Œè¿™ä¸ªå€¼å°±æ˜¯ `0.5`ã€‚
* **é€šè¿‡åŠ æ³•èŠ‚ç‚¹ä¼ æ’­æ¢¯åº¦**ï¼šç„¶åï¼Œåå‘ä¼ æ’­çš„æ¢¯åº¦è¢«åˆ†é…åˆ°è¾“å…¥ `x1`, `x2` å’Œæƒé‡ `w1`, `w2` ä¸Šã€‚åŠ æ³•èŠ‚ç‚¹çš„å¯¼æ•°ä¸º 1ï¼Œæ‰€ä»¥æ¢¯åº¦ä¼šå‡åŒ€åœ°åˆ†å¸ƒåˆ°æ¯ä¸ªè¾“å…¥å’Œæƒé‡ä¸Šã€‚

### 4. **è®¡ç®—æ¢¯åº¦å¹¶æ›´æ–°æƒé‡**ï¼š

* **æƒé‡æ¢¯åº¦**ï¼š

  * å¯¹äº `w1` å’Œ `w2`ï¼Œå®ƒä»¬çš„æ¢¯åº¦æ˜¯ç”±è¾“å…¥ `x1` å’Œ `x2` çš„æ•°æ®ä¹˜ä»¥æ¢¯åº¦å€¼æ¥å¾—åˆ°çš„ã€‚ç”±äº `x2` çš„æ•°æ®æ˜¯ 0ï¼Œå› æ­¤ `w2` çš„æ¢¯åº¦æ˜¯ 0ï¼Œè€Œ `w1` çš„æ¢¯åº¦æ˜¯åŸºäº `x1` å’Œ `w1` çš„å€¼è®¡ç®—çš„ã€‚
* **è¾“å…¥æ¢¯åº¦**ï¼š

  * å¯¹äºè¾“å…¥ `x1` å’Œ `x2`ï¼Œå…¶æ¢¯åº¦æ˜¯ç”±ç›¸åº”çš„æƒé‡ä¹˜ä»¥æ¢¯åº¦ä¼ é€’ä¸‹å»çš„ã€‚

### 5. **åå‘ä¼ æ’­çš„ç»†èŠ‚**ï¼š

åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡é“¾å¼æ³•åˆ™å°†æ¢¯åº¦é€å±‚ä¼ é€’ï¼š

* **å¯¹äºåŠ æ³•èŠ‚ç‚¹**ï¼Œæ¢¯åº¦ä¼šè¢«å‡åŒ€åˆ†é…ç»™æ‰€æœ‰å­èŠ‚ç‚¹ã€‚
* **å¯¹äºä¹˜æ³•èŠ‚ç‚¹**ï¼Œæ¢¯åº¦ä¼šæŒ‰æƒé‡å’Œè¾“å…¥çš„å¤§å°è¿›è¡Œç¼©æ”¾ã€‚ä¾‹å¦‚ï¼Œ`w2` çš„æ¢¯åº¦ä¼šä¹˜ä»¥ `x2` çš„æ•°æ®ï¼Œè€Œ `x1` çš„æ¢¯åº¦ä¼šä¹˜ä»¥ `w1` çš„æ•°æ®ã€‚

### 6. **æ¢¯åº¦æ›´æ–°**ï¼š

é€šè¿‡è®¡ç®—æ¢¯åº¦å¹¶åº”ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œæ›´æ–°æƒé‡å’Œåç½®ï¼Œä½¿å¾—æŸå¤±å‡½æ•° `L` æœ€å°åŒ–ã€‚è¿™ä¸ªè¿‡ç¨‹ä¼šé€šè¿‡å¤šæ¬¡è¿­ä»£ï¼Œé€æ­¥ä¼˜åŒ–ç¥ç»ç½‘ç»œçš„å‚æ•°ã€‚

### 7. **æ€»ç»“**ï¼š

* è¿™ä¸ªä¾‹å­å±•ç¤ºäº†å¦‚ä½•æ‰‹åŠ¨æ‰§è¡Œåå‘ä¼ æ’­ï¼Œé€šè¿‡è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„å±€éƒ¨å¯¼æ•°ï¼Œç„¶åæ ¹æ®é“¾å¼æ³•åˆ™å°†æ¢¯åº¦ä¼ æ’­å›å»ã€‚
* æ¯ä¸€æ­¥è®¡ç®—æ¢¯åº¦æ—¶ï¼Œé¦–å…ˆéœ€è¦äº†è§£æ¯ä¸ªèŠ‚ç‚¹çš„æ“ä½œï¼ˆå¦‚åŠ æ³•æˆ–ä¹˜æ³•ï¼‰çš„å±€éƒ¨å¯¼æ•°ï¼Œç„¶åå°†è¿™äº›å±€éƒ¨å¯¼æ•°ä¸æ¢¯åº¦ç›¸ä¹˜ï¼Œæœ€ç»ˆå¾—åˆ°æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ã€‚
* é€šè¿‡æ‰‹åŠ¨åå‘ä¼ æ’­ï¼Œèƒ½å¤Ÿæ·±å…¥ç†è§£ç¥ç»ç½‘ç»œè®­ç»ƒçš„åŸºæœ¬åŸç†ï¼Œå°¤å…¶æ˜¯å¦‚ä½•é€šè¿‡æ¢¯åº¦ä¸‹é™æ¥æ›´æ–°ç½‘ç»œçš„æƒé‡ã€‚


# implementing the backward function for each operation

are now going to put an end to this suffering and we're going to see how we can implement uh the backward pass a bit
more automatically we're not going to be doing all of it manually out here it's now pretty obvious to us by example
how these pluses and times are back property ingredients so let's go up to the value
object and we're going to start codifying what we've seen in the examples below
so we're going to do this by storing a special cell dot backward
and underscore backward and this will be a function which is going to do that little piece of chain rule at each
little node that compute that took inputs and produced output uh we're going to store
how we are going to chain the the outputs gradient into the inputs gradients
so by default this will be a function that uh doesn't do anything
so um and you can also see that here in the value in micrograb
so with this backward function by default doesn't do anything
this is an empty function and that would be sort of the case for example for a leaf node for leaf node there's nothing to do
but now if when we're creating these out values these out values are an addition
of self and other and so we will want to sell set
outs backward to be the function that propagates the gradient
so let's define what should happen
and we're going to store it in a closure let's define what should happen when we call outs grad
for in addition our job is to take outs grad and propagate it into self's
grad and other grad so basically we want to sell self.grad to something
and we want to set others.grad to something okay
and the way we saw below how chain rule works we want to take the local derivative times
the sort of global derivative i should call it which is the derivative of the final output of the expression with respect to
out's data with respect to out so
the local derivative of self in an addition is 1.0 so it's just 1.0 times
outs grad that's the chain rule and others.grad will be 1.0 times
outgrad and what you basically what you're seeing here is that outscrad will simply be copied onto selfs grad
and others grad as we saw happens for an addition operation so we're going to later call this
function to propagate the gradient having done an addition let's now do multiplication we're going
to also define that backward and we're going to set its backward to
be backward and we want to chain outgrad into
self.grad and others.grad
and this will be a little piece of chain rule for multiplication so we'll have so what should this be
can you think through
so what is the local derivative here the local derivative was others.data
and then oops others.data and the times of that grad that's channel
and here we have self.data times of that grad that's what we've been doing
and finally here for 10 h left backward
and then we want to set out backwards to be just backward
and here we need to back propagate we have out that grad and we want to chain it into self.grad
and salt.grad will be the local derivative of this operation that we've done here which is 10h
and so we saw that the local the gradient is 1 minus the tan h of x squared which here is t
that's the local derivative because that's t is the output of this 10 h so 1 minus t squared is the local derivative
and then gradient um has to be multiplied because of the chain rule so outgrad is chained through the local
gradient into salt.grad and that should be basically it so we're
going to redefine our value node we're going to swing all the way down here
and we're going to redefine our expression make sure that all the grads are zero
okay but now we don't have to do this manually anymore we are going to basically be calling the
dot backward in the right order so first we want to call os
dot backwards
so o was the outcome of 10h right so calling all that those who's
backward will be this function this is what it will do
now we have to be careful because there's a times out.grad
and out.grad remember is initialized to zero
so here we see grad zero so as a base case we need to set both.grad to 1.0
to initialize this with 1
and then once this is 1 we can call oda backward and what that should do is it should
propagate this grad through 10h so the local derivative times
the global derivative which is initialized at one so this should
um a dope
so i thought about redoing it but i figured i should just leave the error in here because it's pretty funny why is
anti-object not callable uh it's because i screwed up we're trying to save these
functions so this is correct this here we don't want to call the function
because that returns none these functions return none we just want to store the function so let me redefine the value object
and then we're going to come back in redefine the expression draw a dot everything is great o dot grad is one
o dot grad is one and now now this should work of course
okay so all that backward should this grant should now be 0.5 if we redraw and if everything went correctly
0.5 yay okay so now we need to call ns.grad
and it's not awkward sorry ends backward so that seems to have worked
so instead backward routed the gradient to both of these so this is looking great
now we could of course called uh called b grad beat up backwards sorry
what's gonna happen well b doesn't have it backward b is backward
because b is a leaf node b's backward is by initialization the empty function
so nothing would happen but we can call call it on it but when we call
this one it's backward
then we expect this 0.5 to get further routed right so there we go 0.5.5
and then finally we want to call it here on x2 w2
and on x1 w1
do both of those and there we go so we get 0 0.5 negative 1.5 and 1
exactly as we did before but now we've done it through calling that backward um
sort of manually so we have the lamp one last piece to get rid of which is us calling

è¿™æ®µä»£ç çš„ç›®çš„æ˜¯å®ç°ä¸€ä¸ªæ›´åŠ è‡ªåŠ¨åŒ–çš„åå‘ä¼ æ’­è¿‡ç¨‹ã€‚ä¹‹å‰æˆ‘ä»¬æ‰‹åŠ¨ç¼–å†™äº†åå‘ä¼ æ’­ï¼Œä½†ç°åœ¨é€šè¿‡å®ç°æ¯ä¸ªæ“ä½œçš„ `backward` å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒç”¨ `backward()` æ–¹æ³•è‡ªåŠ¨ä¼ æ’­æ¢¯åº¦ã€‚å…·ä½“è¿‡ç¨‹å¦‚ä¸‹ï¼š

### 1. **å®šä¹‰ `backward` æ–¹æ³•**ï¼š

æˆ‘ä»¬è¦åœ¨æ¯ä¸ªæ“ä½œï¼ˆæ¯”å¦‚åŠ æ³•ã€ä¹˜æ³•ã€æ¿€æ´»å‡½æ•°ç­‰ï¼‰ä¸Šå®ç°ä¸€ä¸ª `backward` æ–¹æ³•ï¼Œä»¥ä¾¿åœ¨è®¡ç®—æ¢¯åº¦æ—¶è‡ªåŠ¨æ‰§è¡Œåå‘ä¼ æ’­ã€‚æ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰ä¸€ä¸ª `backward()` æ–¹æ³•æ¥è®¡ç®—æ¢¯åº¦å¹¶å°†å…¶ä¼ æ’­åˆ°å‰é¢çš„èŠ‚ç‚¹ã€‚

* **`backward` æ–¹æ³•**çš„ä½œç”¨æ˜¯ï¼šå°†è¾“å‡ºçš„æ¢¯åº¦ä¼ é€’åˆ°å½“å‰æ“ä½œçš„è¾“å…¥ï¼Œå¹¶æ ¹æ®é“¾å¼æ³•åˆ™è®¡ç®—æ¯ä¸ªè¾“å…¥çš„æ¢¯åº¦ã€‚

### 2. **è®¾ç½® `backward` å‡½æ•°çš„é»˜è®¤è¡Œä¸º**ï¼š

* **å¶èŠ‚ç‚¹ï¼ˆleaf nodeï¼‰**ï¼šå¶èŠ‚ç‚¹æ˜¯æœ€ç»ˆæ¨¡å‹çš„è¾“å…¥ï¼Œå®ƒä»¬æ²¡æœ‰çˆ¶èŠ‚ç‚¹ï¼Œæ‰€ä»¥å®ƒä»¬çš„ `backward()` å‡½æ•°é»˜è®¤ä»€ä¹ˆä¹Ÿä¸åšã€‚
* **æ“ä½œèŠ‚ç‚¹ï¼ˆå¦‚åŠ æ³•ã€ä¹˜æ³•ã€æ¿€æ´»å‡½æ•°ç­‰ï¼‰**ï¼šæˆ‘ä»¬ä¼šåœ¨æ¯ä¸ªæ“ä½œçš„èŠ‚ç‚¹ä¸­å®šä¹‰å…·ä½“çš„ `backward()` é€»è¾‘ï¼Œä»¥ä¾¿å°†æ¢¯åº¦ä¼ é€’åˆ°è¾“å…¥ã€‚

### 3. **åŠ æ³•èŠ‚ç‚¹ `+` çš„åå‘ä¼ æ’­**ï¼š

å¯¹äºåŠ æ³•æ“ä½œï¼š

* **å±€éƒ¨å¯¼æ•°ï¼ˆlocal derivativeï¼‰**ï¼šåŠ æ³•çš„å¯¼æ•°æ˜¯ 1ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¼šå°† `outs.grad`ï¼ˆè¾“å‡ºçš„æ¢¯åº¦ï¼‰ç›´æ¥ä¼ é€’ç»™è¾“å…¥ `self` å’Œ `other` çš„æ¢¯åº¦ã€‚
* **æ›´æ–°æ¢¯åº¦**ï¼šæˆ‘ä»¬å°† `outs.grad` ä¹˜ä»¥ 1.0ï¼Œåˆ†åˆ«åŠ åˆ° `self.grad` å’Œ `other.grad` ä¸­ã€‚

```python
def backward(self):
    self.grad = outs.grad
    other.grad = outs.grad
```

### 4. **ä¹˜æ³•èŠ‚ç‚¹ `*` çš„åå‘ä¼ æ’­**ï¼š

å¯¹äºä¹˜æ³•æ“ä½œï¼š

* **å±€éƒ¨å¯¼æ•°**ï¼šä¹˜æ³•çš„å±€éƒ¨å¯¼æ•°åˆ†åˆ«æ˜¯ `other.data` å’Œ `self.data`ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬å°† `outs.grad` ä¹˜ä»¥ `other.data` ä¼ é€’ç»™ `self.grad`ï¼Œå°† `outs.grad` ä¹˜ä»¥ `self.data` ä¼ é€’ç»™ `other.grad`ã€‚

```python
def backward(self):
    self.grad = outs.grad * other.data
    other.grad = outs.grad * self.data
```

### 5. **`tanh` æ¿€æ´»å‡½æ•°çš„åå‘ä¼ æ’­**ï¼š

å¯¹äº `tanh` æ¿€æ´»å‡½æ•°ï¼š

* **å±€éƒ¨å¯¼æ•°**ï¼š`tanh` å‡½æ•°çš„å¯¼æ•°æ˜¯ `1 - tanh(x)^2`ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬å°† `outs.grad` ä¹˜ä»¥ `1 - t^2`ï¼ˆå…¶ä¸­ `t` æ˜¯ `tanh(n)` çš„è¾“å‡ºï¼‰ä¼ é€’ç»™è¾“å…¥çš„æ¢¯åº¦ã€‚

```python
def backward(self):
    self.grad = outs.grad * (1 - outs.data ** 2)
```

### 6. **åå‘ä¼ æ’­çš„å®ç°**ï¼š

ç°åœ¨æˆ‘ä»¬å·²ç»å®šä¹‰äº†æ¯ä¸ªæ“ä½œçš„ `backward()` æ–¹æ³•ï¼Œæ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡è°ƒç”¨æ¯ä¸ªèŠ‚ç‚¹çš„ `backward()` æ–¹æ³•æ¥ä¼ é€’æ¢¯åº¦ã€‚

1. **åˆå§‹åŒ–**ï¼šæˆ‘ä»¬é¦–å…ˆåˆå§‹åŒ–è¾“å‡ºçš„ `grad` ä¸º 1ã€‚å› ä¸º `o` æ˜¯æœ€ç»ˆçš„è¾“å‡ºï¼Œæ‰€ä»¥å®ƒçš„æ¢¯åº¦ä» 1 å¼€å§‹ã€‚
2. **ä¼ æ’­æ¢¯åº¦**ï¼š

   * å½“æˆ‘ä»¬è°ƒç”¨ `o.backward()` æ—¶ï¼Œåå‘ä¼ æ’­ä¼šé€šè¿‡ `tanh` å‡½æ•°å°†æ¢¯åº¦ä¼ æ’­åˆ° `n`ã€‚
   * ç„¶åï¼Œæ¢¯åº¦ä¼šç»§ç»­é€šè¿‡åŠ æ³•èŠ‚ç‚¹ã€ä¹˜æ³•èŠ‚ç‚¹ç­‰æ“ä½œä¼ æ’­ï¼Œç›´åˆ°è¾¾åˆ°æ‰€æœ‰è¾“å…¥èŠ‚ç‚¹ï¼ˆå¦‚ `x1`ï¼Œ`x2`ï¼Œ`w1`ï¼Œ`w2`ï¼‰ã€‚

### 7. **è‡ªåŠ¨åŒ–åå‘ä¼ æ’­**ï¼š

é€šè¿‡å®ç°æ¯ä¸ªæ“ä½œèŠ‚ç‚¹çš„ `backward` æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥è‡ªåŠ¨è¿›è¡Œåå‘ä¼ æ’­ï¼Œä¸å†éœ€è¦æ‰‹åŠ¨é€æ­¥è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦ã€‚

### 8. **æ¢¯åº¦çš„æ›´æ–°**ï¼š

åœ¨åå‘ä¼ æ’­å®Œæˆåï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„ `grad` å±æ€§å°†ä¿å­˜ç›¸åº”çš„æ¢¯åº¦å€¼ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™äº›æ¢¯åº¦æ¥æ›´æ–°æ¨¡å‹çš„å‚æ•°ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡æ¢¯åº¦ä¸‹é™ï¼‰ã€‚

### 9. **å®é™…æ“ä½œ**ï¼š

é€šè¿‡è°ƒç”¨ `backward()` æ–¹æ³•ï¼Œæˆ‘ä»¬å®Œæˆäº†ä»è¾“å‡ºåˆ°è¾“å…¥çš„åå‘ä¼ æ’­ï¼Œæ¢¯åº¦è‡ªåŠ¨ä¼ é€’å¹¶è®¡ç®—äº†æ¯ä¸ªæƒé‡å’Œè¾“å…¥çš„æ¢¯åº¦ã€‚æœ€ç»ˆï¼Œæ‰€æœ‰çš„ `grad` éƒ½è®¡ç®—å®Œæ¯•ï¼Œç»“æœå’Œä¹‹å‰æ‰‹åŠ¨è®¡ç®—çš„æ¢¯åº¦ä¸€è‡´ï¼Œä½†è¿™æ¬¡æ˜¯è‡ªåŠ¨å®Œæˆçš„ã€‚

---

### æ€»ç»“ï¼š

é€šè¿‡ä¸ºæ¯ä¸ªæ“ä½œèŠ‚ç‚¹å®šä¹‰ä¸€ä¸ª `backward()` æ–¹æ³•ï¼Œæˆ‘ä»¬ä½¿å¾—åå‘ä¼ æ’­è¿‡ç¨‹å˜å¾—è‡ªåŠ¨åŒ–ã€‚åœ¨å®é™…çš„ç¥ç»ç½‘ç»œä¸­ï¼Œè¿™ç§è‡ªåŠ¨åŒ–çš„åå‘ä¼ æ’­å¤§å¤§å‡å°‘äº†æ‰‹åŠ¨è®¡ç®—å’Œä»£ç ç¼–å†™çš„å·¥ä½œé‡ï¼Œä½¿å¾—åå‘ä¼ æ’­å˜å¾—æ›´åŠ é«˜æ•ˆå’Œæ˜“äºç®¡ç†ã€‚


# implementing the backward function for a whole expression graph

underscore backward manually so let's think through what we are actually doing um
we've laid out a mathematical expression and now we're trying to go backwards through that expression
um so going backwards through the expression just means that we never want to call a dot backward for any node
before we've done a sort of um everything after it
so we have to do everything after it before we're ever going to call that backward on any one node we have to get all of its full dependencies everything
that it depends on has to propagate to it before we can continue back propagation so this ordering of
graphs can be achieved using something called topological sort so topological sort
is basically a laying out of a graph such that all the edges go only from left to right basically
so here we have a graph it's a directory a cyclic graph a dag and this is two different topological
orders of it i believe where basically you'll see that it's laying out of the notes such that all the edges go only
one way from left to right and implementing topological sort you can look in wikipedia and so on i'm not
going to go through it in detail but basically this is what builds a
topological graph we maintain a set of visited nodes and
then we are going through starting at some root node
which for us is o that's where we want to start the topological sort and starting at o we go through all of
its children and we need to lay them out from left to right and basically this starts at o
if it's not visited then it marks it as visited and then it iterates through all of its children
and calls build topological on them and then uh after it's gone through all
the children it adds itself so basically this node that we're going to call it on
like say o is only going to add itself to the topo list after all of the
children have been processed and that's how this function is guaranteeing that you're only going to be in the list
once all your children are in the list and that's the invariant that is being maintained so if we built upon o and
then inspect this list we're going to see that it ordered our
value objects and the last one is the value of 0.707 which is the
output so this is o and then this is n and then all the other nodes get laid
out before it so that builds the topological graph and really what we're doing now is we're
just calling dot underscore backward on all of the nodes in a topological order
so if we just reset the gradients they're all zero what did we do we started by
setting o dot grad to b1 that's the base case
then we built the topological order and then we went for node
in reversed of topo now
in in the reverse order because this list goes from you know we need to go through it in reversed order
so starting at o note that backward and this should be
it there we go those are the correct derivatives
finally we are going to hide this functionality so i'm going to copy this and we're going to hide it
inside the valley class because we don't want to have all that code lying around so instead of an underscore backward
we're now going to define an actual backward so that's backward without the underscore
and that's going to do all the stuff that we just arrived so let me just clean this up a little bit so
we're first going to build a topological graph
starting at self so build topo of self
will populate the topological order into the topo list which is a local variable
then we set self.grad to be one and then for each node in the reversed
list so starting at us and going to all the children underscore backward
and that should be it so save
come down here redefine [Music] okay all the grands are zero
and now what we can do is oh that backward without the underscore and
there we go and that's uh that's back propagation
place for one neuron now we shouldn't be too happy with ourselves actually because we have a bad

è¿™æ®µä»£ç å®ç°äº†å¯¹æ•´ä¸ªè¡¨è¾¾å¼å›¾ï¼ˆç”±å¤šä¸ªæ“ä½œèŠ‚ç‚¹æ„æˆï¼‰è¿›è¡Œåå‘ä¼ æ’­çš„åŠŸèƒ½ã€‚åå‘ä¼ æ’­è¿‡ç¨‹æ¶‰åŠåˆ°é€šè¿‡è®¡ç®—å›¾ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦å¹¶æ›´æ–°å®ƒä»¬ã€‚ä¸ºäº†é«˜æ•ˆä¸”å‡†ç¡®åœ°å®Œæˆè¿™ä¸€è¿‡ç¨‹ï¼Œæˆ‘ä»¬éœ€è¦æ ¹æ®ä¾èµ–å…³ç³»æŒ‰é¡ºåºå¤„ç†æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦ã€‚è¿™å°±æ˜¯æˆ‘ä»¬è¦å®ç°çš„â€œæ‹“æ‰‘æ’åºâ€ï¼ˆTopological Sortï¼‰å’Œè‡ªåŠ¨åå‘ä¼ æ’­çš„æ ¸å¿ƒã€‚

### 1. **æ‹“æ‰‘æ’åºï¼ˆTopological Sortï¼‰**ï¼š

åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¸èƒ½åœ¨æŸä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦è¢«æ­£ç¡®è®¡ç®—ä¹‹å‰å°±è®¿é—®å®ƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ‹“æ‰‘æ’åºçš„è¿‡ç¨‹æ¥ç¡®ä¿åå‘ä¼ æ’­çš„é¡ºåºæ­£ç¡®â€”â€”å³ä»è¾“å‡ºèŠ‚ç‚¹å¼€å§‹ï¼Œä¾æ¬¡å¤„ç†æ‰€æœ‰ä¾èµ–å…³ç³»æ­£ç¡®çš„èŠ‚ç‚¹ã€‚

* **æ‹“æ‰‘æ’åºçš„æ„ä¹‰**ï¼šç¡®ä¿æˆ‘ä»¬æ€»æ˜¯å…ˆå¤„ç†ä¸€ä¸ªèŠ‚ç‚¹æ‰€ä¾èµ–çš„èŠ‚ç‚¹ï¼Œå†å¤„ç†å®ƒæœ¬èº«ã€‚
* **å›¾çš„ç‰¹ç‚¹**ï¼šæ‹“æ‰‘æ’åºé€šå¸¸åº”ç”¨äºæœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰ï¼Œä¹Ÿå°±æ˜¯æ¯ä¸ªèŠ‚ç‚¹æœ‰ä¸€ä¸ªæ–¹å‘æ€§ï¼Œä¸ä¼šå½¢æˆå¾ªç¯ã€‚

### 2. **æ‹“æ‰‘æ’åºçš„å®ç°**ï¼š

* ä» **è¾“å‡ºèŠ‚ç‚¹** `o` å¼€å§‹ï¼Œé€æ­¥å‘å›¾ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ä¼ æ’­ï¼Œé€šè¿‡æ¯ä¸ªèŠ‚ç‚¹çš„æ‰€æœ‰ä¾èµ–ï¼ˆå­èŠ‚ç‚¹ï¼‰ï¼Œç›´åˆ°æ‰€æœ‰èŠ‚ç‚¹éƒ½å¤„ç†å®Œæ¯•ã€‚
* **`build_topo`**ï¼šè¿™æ˜¯ä¸€ä¸ªé€’å½’å‡½æ•°ï¼Œç”¨æ¥æ„å»ºæ‹“æ‰‘é¡ºåºã€‚å®ƒé¦–å…ˆæ ‡è®°å½“å‰èŠ‚ç‚¹ä¸ºå·²è®¿é—®ï¼Œç„¶åé€’å½’åœ°è®¿é—®å…¶æ‰€æœ‰å­èŠ‚ç‚¹ï¼Œå¹¶åœ¨æ‰€æœ‰å­èŠ‚ç‚¹éƒ½å¤„ç†å®Œåï¼Œå°†å½“å‰èŠ‚ç‚¹æ·»åŠ åˆ°æ‹“æ‰‘é¡ºåºä¸­ã€‚

### 3. **æ‰§è¡Œåå‘ä¼ æ’­**ï¼š

* **æ­¥éª¤ä¸€ï¼š** å…ˆåˆå§‹åŒ– `o.grad = 1`ï¼Œå› ä¸º `o` æ˜¯è¾“å‡ºèŠ‚ç‚¹ï¼Œæˆ‘ä»¬å‡è®¾å®ƒçš„æ¢¯åº¦ä¸º 1ï¼ˆè¿™æ˜¯åå‘ä¼ æ’­çš„èµ·ç‚¹ï¼‰ã€‚
* **æ­¥éª¤äºŒï¼š** æ„å»ºæ‹“æ‰‘é¡ºåºï¼Œå¹¶ä»æ‹“æ‰‘é¡ºåºçš„æœ€åä¸€ä¸ªèŠ‚ç‚¹ï¼ˆå³è¾“å‡ºèŠ‚ç‚¹ï¼‰å¼€å§‹ï¼Œåå‘è°ƒç”¨æ¯ä¸ªèŠ‚ç‚¹çš„ `backward()` å‡½æ•°ï¼Œè¿™æ ·æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦å°±ä¼šä¾èµ–äºå®ƒçš„å­èŠ‚ç‚¹çš„æ¢¯åº¦ã€‚

### 4. **åå‘ä¼ æ’­æ“ä½œ**ï¼š

* å¯¹äºæ¯ä¸ªèŠ‚ç‚¹ï¼Œæˆ‘ä»¬è°ƒç”¨å®ƒçš„ `backward()` æ–¹æ³•ï¼Œè¿™ä¸ªæ–¹æ³•ä¼šæ ¹æ®å½“å‰æ“ä½œçš„é“¾å¼æ³•åˆ™ï¼ˆchain ruleï¼‰æ¥è®¡ç®—è¯¥èŠ‚ç‚¹çš„æ¢¯åº¦ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™ä¾èµ–å®ƒçš„èŠ‚ç‚¹ã€‚
* **é“¾å¼æ³•åˆ™**ï¼šæ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦æ˜¯é€šè¿‡è¯¥èŠ‚ç‚¹çš„å±€éƒ¨å¯¼æ•°ï¼ˆä¾‹å¦‚ï¼ŒåŠ æ³•çš„å¯¼æ•°ä¸º 1ï¼Œä¹˜æ³•çš„å¯¼æ•°ä¸ºè¾“å…¥å€¼ï¼‰ä¸åç»­èŠ‚ç‚¹çš„æ¢¯åº¦çš„ä¹˜ç§¯æ¥è®¡ç®—çš„ã€‚

### 5. **å®ç°ä»£ç **ï¼š

ä»£ç å®ç°äº†ä»¥ä¸‹æ­¥éª¤ï¼š

1. **`build_topo`**ï¼šæ„å»ºæ‹“æ‰‘æ’åºï¼Œç¡®ä¿åå‘ä¼ æ’­çš„é¡ºåºæ­£ç¡®ã€‚
2. **`backward()`**ï¼šè¿™ä¸ªå‡½æ•°ä¼šæ ¹æ®æ‹“æ‰‘æ’åºé€ä¸ªèŠ‚ç‚¹åœ°è°ƒç”¨ `backward()`ï¼Œä»è¾“å‡ºèŠ‚ç‚¹å¼€å§‹ï¼Œé€æ­¥ä¼ æ’­æ¢¯åº¦åˆ°æ‰€æœ‰è¾“å…¥èŠ‚ç‚¹ã€‚

### 6. **éšè—åŠŸèƒ½**ï¼š

* ä¸ºäº†ä»£ç çš„æ•´æ´æ€§ï¼Œæˆ‘ä»¬å°†å®ç°ç»†èŠ‚éšè—åœ¨ä¸€ä¸ªå« `Value` çš„ç±»ä¸­ï¼Œè€Œä¸æ˜¯åœ¨å¤–éƒ¨ä»£ç ä¸­æš´éœ²è¿™äº›å¤æ‚çš„è¿‡ç¨‹ã€‚è¿™æ ·ï¼Œç”¨æˆ·åªéœ€è¦ç®€å•åœ°è°ƒç”¨ `backward()` æ–¹æ³•ï¼Œè€Œä¸éœ€è¦å…³å¿ƒå†…éƒ¨çš„æ‹“æ‰‘æ’åºå’Œæ¢¯åº¦ä¼ æ’­è¿‡ç¨‹ã€‚

### æ€»ç»“ï¼š

* **æ‹“æ‰‘æ’åº**ï¼šé€šè¿‡æ‹“æ‰‘æ’åºç¡®ä¿åå‘ä¼ æ’­çš„é¡ºåºæ­£ç¡®ï¼Œä¿è¯æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦åœ¨å…¶ä¾èµ–çš„èŠ‚ç‚¹çš„æ¢¯åº¦è®¡ç®—åæ›´æ–°ã€‚
* **åå‘ä¼ æ’­**ï¼šé€šè¿‡ `backward()` æ–¹æ³•è‡ªåŠ¨è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦ï¼Œå¹¶å°†å®ƒä»¬ä¼ æ’­åˆ°å‰é¢ï¼ˆä¾èµ–çš„èŠ‚ç‚¹ï¼‰ã€‚
* **è‡ªåŠ¨åŒ–**ï¼šé€šè¿‡è‡ªåŠ¨åŒ–çš„ `backward()` è°ƒç”¨ï¼Œæ¶ˆé™¤äº†æ‰‹åŠ¨ç¼–å†™åå‘ä¼ æ’­çš„ç¹çå·¥ä½œï¼Œç®€åŒ–äº†æ¢¯åº¦è®¡ç®—çš„è¿‡ç¨‹ã€‚

è¿™æ ·ï¼Œæˆ‘ä»¬å°±èƒ½å¤Ÿé«˜æ•ˆä¸”æ­£ç¡®åœ°è®¡ç®—æ•´ä¸ªç¥ç»ç½‘ç»œï¼ˆæˆ–è®¡ç®—å›¾ï¼‰çš„æ¢¯åº¦ï¼Œå¹¶ä¸ºå‚æ•°ä¼˜åŒ–ï¼ˆå¦‚æ¢¯åº¦ä¸‹é™ï¼‰æä¾›æ”¯æŒã€‚


# fixing a backprop bug when one node is used multiple times

bug um and we have not surfaced the bug because of some specific conditions that we are we have to think about right now
so here's the simplest case that shows the bug say i create a single node a
and then i create a b that is a plus a and then i called backward
so what's going to happen is a is 3 and then a b is a plus a so there's two
arrows on top of each other here then we can see that b is of course the
forward pass works b is just a plus a which is six but the gradient here is not actually
correct that we calculate it automatically and that's because
um of course uh just doing calculus in your head the
derivative of b with respect to a should be uh two
one plus one it's not one intuitively what's happening here right so b is the result of a plus a and then
we call backward on it so let's go up and see what that does
um b is a result of addition so out as b and then when we called backward what
happened is self.grad was set to one and then other that grad was set to one
but because we're doing a plus a self and other are actually the exact same object
so we are overriding the gradient we are setting it to one and then we are setting it again to one and that's why
it stays at one so that's a problem there's another way to see this in a
little bit more complicated expression
so here we have a and b and then uh d will be the multiplication
of the two and e will be the addition of the two and then we multiply e times d to get f and
then we called fda backward and these gradients if you check will be incorrect
so fundamentally what's happening here again is basically we're going to see an issue
anytime we use a variable more than once until now in these expressions above every variable is used exactly once so
we didn't see the issue but here if a variable is used more than once what's going to happen during backward pass we're backpropagating from
f to e to d so far so good but now equals it backward and it deposits its
gradients to a and b but then we come back to d and call backward and it overwrites
those gradients at a and b so that's obviously a problem
and the solution here if you look at the multivariate case of the chain rule
and its generalization there the solution there is basically that we have to accumulate these gradients these
gradients add and so instead of setting those gradients
we can simply do plus equals we need to accumulate those gradients plus equals plus equals
plus equals plus equals and this will be okay remember because
we are initializing them at zero so they start at zero and then any
contribution that flows backwards will simply add
so now if we redefine this one because the plus equals this now works
because a.grad started at zero and we called beta backward we deposit one and
then we deposit one again and now this is two which is correct and here this will also work and we'll
get correct gradients because when we call eta backward we will deposit the gradients from this branch and then we get to back into
detail backward it will deposit its own gradients and then those gradients simply add on top of each other and so
we just accumulate those gradients and that fixes the issue okay now before we move on let me actually do a bit of
cleanup here and delete some of these some of this intermediate work so
we're not gonna need any of this now that we've derived all of it um we are going to keep this because i want
to come back to it delete the 10h delete our morning example
delete the step delete this keep the code that draws
and then delete this example and leave behind only the definition of value

è¿™ä¸ªæ®µè½æè¿°äº†åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­é‡åˆ°çš„ä¸€ä¸ªå¸¸è§çš„bugï¼Œç‰¹åˆ«æ˜¯å½“åŒä¸€ä¸ªèŠ‚ç‚¹è¢«å¤šæ¬¡ä½¿ç”¨æ—¶ï¼Œæ¢¯åº¦è®¡ç®—ä¼šå‡ºé”™ã€‚å…·ä½“æ¥è¯´ï¼Œå½“æŸä¸ªèŠ‚ç‚¹çš„è®¡ç®—ç»“æœè¢«å¤šä¸ªèŠ‚ç‚¹ä½¿ç”¨ï¼ˆä¾‹å¦‚åŠ æ³•æ“ä½œï¼‰æ—¶ï¼Œåå‘ä¼ æ’­æ—¶æ¢¯åº¦ä¼šè¢«é”™è¯¯åœ°è¦†ç›–ï¼Œå¯¼è‡´æœ€ç»ˆçš„æ¢¯åº¦ä¸æ­£ç¡®ã€‚è¿™ä¸ªé—®é¢˜çš„è§£å†³æ–¹æ¡ˆæ˜¯ç´¯åŠ æ¢¯åº¦ï¼Œè€Œä¸æ˜¯è¦†ç›–å®ƒã€‚

### 1. **é—®é¢˜çš„èƒŒæ™¯**ï¼š

* å‡è®¾æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªèŠ‚ç‚¹ `a`ï¼Œç„¶ååˆ›å»ºäº†å¦ä¸€ä¸ªèŠ‚ç‚¹ `b = a + a`ï¼Œå³ `b` æ˜¯ `a` çš„ä¸¤å€ã€‚
* æŒ‰ç†è¯´ï¼Œ`b` å¯¹ `a` çš„å¯¼æ•°åº”è¯¥æ˜¯ 2ï¼ˆå› ä¸º `b` = `a + a`ï¼Œå³å¯¼æ•°ä¸º 2ï¼‰ï¼Œä½†æ˜¯åå‘ä¼ æ’­æ—¶ï¼Œç”±äº `a` è¢«åŠ äº†ä¸¤æ¬¡ï¼ˆè€Œä¸”æ˜¯åŒä¸€ä¸ªå¯¹è±¡ï¼‰ï¼Œå®ƒçš„æ¢¯åº¦ä¼šè¢«è®¾ç½®ä¸º 1 åå†è¢«è¦†ç›–ï¼Œå¯¼è‡´æœ€ç»ˆçš„æ¢¯åº¦ä¸º 1ï¼Œè€Œä¸æ˜¯æ­£ç¡®çš„ 2ã€‚

### 2. **bugçš„åŸå› **ï¼š

* åœ¨è®¡ç®— `b = a + a` æ—¶ï¼Œ`a` çš„æ¢¯åº¦ä¼šè¢«è®¡ç®—ä¸¤æ¬¡ï¼Œä½†ç”±äº `a` å’Œ `a` æ˜¯åŒä¸€ä¸ªå¯¹è±¡ï¼ˆåŠ æ³•æ“ä½œæ²¡æœ‰ç”Ÿæˆæ–°çš„å¯¹è±¡ï¼‰ï¼Œæ‰€ä»¥åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œ`a` çš„æ¢¯åº¦ä¼šè¢«è¦†ç›–ã€‚
* åœ¨åå‘ä¼ æ’­æ—¶ï¼Œç¬¬ä¸€ä¸ªè°ƒç”¨ `b.backward()` ä¼šç»™ `a` å’Œ `b` çš„æ¢¯åº¦åˆ†åˆ«è®¾ç½®ä¸º 1ï¼Œä½†æ˜¯æ¥ä¸‹æ¥çš„æ“ä½œå†æ¬¡ä¿®æ”¹äº† `a` å’Œ `b` çš„æ¢¯åº¦ï¼Œè€Œä¸æ˜¯å°†å®ƒä»¬ç´¯åŠ ï¼Œè¿™å°±å¯¼è‡´äº†é”™è¯¯çš„ç»“æœã€‚

### 3. **æ›´å¤æ‚çš„ä¾‹å­**ï¼š

* åœ¨ä¸€ä¸ªæ›´å¤æ‚çš„ä¾‹å­ä¸­ï¼Œæ¶‰åŠåˆ°å¤šä¸ªèŠ‚ç‚¹çš„æ“ä½œï¼Œå¦‚ä¹˜æ³•å’ŒåŠ æ³•ï¼Œé—®é¢˜ä¼šæ›´åŠ æ˜æ˜¾ã€‚
* å¦‚æœæŸä¸ªèŠ‚ç‚¹ï¼ˆå¦‚ `a` æˆ– `b`ï¼‰è¢«å¤šæ¬¡ä½¿ç”¨ï¼ˆä¾‹å¦‚åŒæ—¶å‡ºç°åœ¨ä¹˜æ³•å’ŒåŠ æ³•çš„è®¡ç®—ä¸­ï¼‰ï¼Œåœ¨åå‘ä¼ æ’­æ—¶ï¼Œæ¢¯åº¦ä¼šè¢«é”™è¯¯åœ°è¦†ç›–ï¼Œä»è€Œå¯¼è‡´è®¡ç®—é”™è¯¯ã€‚

### 4. **è§£å†³æ–¹æ¡ˆ**ï¼š

* **ç´¯åŠ æ¢¯åº¦**ï¼šè§£å†³è¿™ä¸ªé—®é¢˜çš„å…³é”®æ˜¯æ¢¯åº¦çš„â€œç´¯åŠ â€ï¼Œå³åœ¨åå‘ä¼ æ’­æ—¶ï¼Œå½“å¤šä¸ªè·¯å¾„å¯¹åŒä¸€ä¸ªèŠ‚ç‚¹äº§ç”Ÿå½±å“æ—¶ï¼Œæˆ‘ä»¬ä¸ç›´æ¥è¦†ç›–è¯¥èŠ‚ç‚¹çš„æ¢¯åº¦ï¼Œè€Œæ˜¯å°†æ–°çš„æ¢¯åº¦åŠ åˆ°ç°æœ‰çš„æ¢¯åº¦ä¸Šã€‚

  * ä½¿ç”¨ `+=` ä»£æ›¿ `=`ï¼Œä»¥ä¾¿åœ¨è®¡ç®—æ¢¯åº¦æ—¶ç´¯åŠ è€Œä¸æ˜¯è¦†ç›–ã€‚
  * è¿™æ ·ï¼Œåœ¨æ¯æ¬¡è°ƒç”¨ `backward()` æ—¶ï¼Œæ¢¯åº¦ä¼šè¢«ç´¯åŠ èµ·æ¥ï¼Œç¡®ä¿æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦æ­£ç¡®åæ˜ äº†å®ƒåœ¨å¤šæ¡è·¯å¾„ä¸­çš„è´¡çŒ®ã€‚

### 5. **ä»£ç å®ç°**ï¼š

* é€šè¿‡ä½¿ç”¨ `+=` æ“ä½œç¬¦ï¼Œæˆ‘ä»¬é¿å…äº†è¦†ç›–æ¢¯åº¦çš„é—®é¢˜ã€‚å½“æˆ‘ä»¬è°ƒç”¨ `b.backward()` æ—¶ï¼Œ`a.grad` ä¼šå…ˆè®¾ç½®ä¸º 0ï¼Œç„¶ååŠ ä¸Šæ¯æ¬¡åå‘ä¼ æ’­çš„è´¡çŒ®ï¼Œæœ€ç»ˆå¾—åˆ°æ­£ç¡®çš„æ¢¯åº¦ï¼ˆä¾‹å¦‚ `a.grad = 2`ï¼‰ã€‚
* è¿™æ ·æ— è®ºæœ‰å¤šå°‘æ¬¡ç›¸åŒèŠ‚ç‚¹çš„ä½¿ç”¨ï¼Œæ¢¯åº¦éƒ½ä¼šè¢«æ­£ç¡®ç´¯åŠ ï¼Œè€Œä¸ä¼šè¢«è¦†ç›–ã€‚

### 6. **æ¸…ç†ä»£ç **ï¼š

* æœ€åï¼Œä»£ç åšäº†ä¸€äº›æ¸…ç†ï¼Œåˆ é™¤äº†å¤šä½™çš„ä¸­é—´è®¡ç®—æ­¥éª¤å’Œä¸å†éœ€è¦çš„ç¤ºä¾‹ï¼Œåªä¿ç•™äº†å…³é”®çš„è®¡ç®—å’Œå®šä¹‰éƒ¨åˆ†ï¼Œä»¥ä¿æŒä»£ç çš„ç®€æ´å’Œå¯ç»´æŠ¤æ€§ã€‚

### æ€»ç»“ï¼š

* **é—®é¢˜**ï¼šåå‘ä¼ æ’­æ—¶ï¼Œå½“åŒä¸€ä¸ªèŠ‚ç‚¹è¢«å¤šæ¬¡ä½¿ç”¨ï¼Œæ¢¯åº¦ä¼šè¢«è¦†ç›–ï¼Œå¯¼è‡´ç»“æœé”™è¯¯ã€‚
* **è§£å†³æ–¹æ³•**ï¼šé€šè¿‡ä½¿ç”¨ `+=` æ“ä½œç¬¦æ¥ç´¯åŠ æ¢¯åº¦ï¼Œè€Œä¸æ˜¯ç›´æ¥è¦†ç›–ï¼Œä»è€Œé¿å…æ¢¯åº¦ä¸¢å¤±çš„é—®é¢˜ï¼Œç¡®ä¿æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦åæ˜ äº†æ‰€æœ‰è·¯å¾„çš„å½±å“ã€‚
* **æ ¸å¿ƒæ€æƒ³**ï¼šåœ¨è®¡ç®—å›¾ä¸­ï¼Œå¤šæ¬¡ä½¿ç”¨ç›¸åŒèŠ‚ç‚¹æ—¶è¦ç´¯åŠ æ¢¯åº¦ï¼Œè€Œä¸æ˜¯è¦†ç›–å®ƒä»¬ã€‚


# breaking up a tanh, exercising with more operations

and now let's come back to this non-linearity here that we implemented the tanh now i told you that we could
have broken down 10h into its explicit atoms in terms of other expressions if
we had the x function so if you remember tan h is defined like this and we chose to develop tan h as a single function
and we can do that because we know its derivative and we can back propagate through it but we can also break down tan h into
and express it as a function of x and i would like to do that now because i want to prove to you that you get all the
same results and all those ingredients but also because it forces us to implement a few more expressions it
forces us to do exponentiation addition subtraction division and things like that and i think it's a good exercise to
go through a few more of these okay so let's scroll up to the definition of value
and here one thing that we currently can't do is we can do like a value of say 2.0
but we can't do you know here for example we want to add constant one and we can't do something like this
and we can't do it because it says object has no attribute data that's because a plus one comes right here to
add and then other is the integer one and then here python is trying to access
one.data and that's not a thing and that's because basically one is not a value object and we only have addition
for value objects so as a matter of convenience so that we can create expressions like this and make them make
sense we can simply do something like this basically
we let other alone if other is an instance of value but if it's not an instance of value we're going to assume
that it's a number like an integer float and we're going to simply wrap it in in value and then other will just become
value of other and then other will have a data attribute and this should work so if i just say this predefined value then
this should work there we go okay now let's do the exact same thing for multiply because we can't
do something like this again for the exact same reason so we just have to go to mole and if other is
not a value then let's wrap it in value let's redefine value and now this works
now here's a kind of unfortunate and not obvious part a times two works we saw that but two times a is that gonna work
you'd expect it to right but actually it will not and the reason it won't is because python doesn't know
like when when you do a times two basically um so a times two python will
go and it will basically do something like a dot mul of two that's basically what it will
call but to it 2 times a is the same as 2 dot mol of a
and it doesn't 2 can't multiply value and so it's really confused about that
so instead what happens is in python the way this works is you are free to define something called the r mold
and our mole is kind of like a fallback so if python can't do 2 times a it will check if um
if by any chance a knows how to multiply two and that will be called into our mole
so because python can't do two times a it will check is there an our mole in value and because there is it will now
call that and what we'll do here is we will swap the order of the operands so basically
two times a will redirect to armel and our mole will basically call a times two and that's how that will work
so redefining now with armor two times a becomes four okay now looking at the
other elements that we still need we need to know how to exponentiate and how to divide so let's first the explanation to the exponentiation part we're going
to introduce a single function x here and x is going to mirror 10h in the
sense that it's a simple single function that transforms a single scalar value and outputs a single scalar value
so we pop out the python number we use math.x to exponentiate it create a new value object
everything that we've seen before the tricky part of course is how do you propagate through e to the x
and so here you can potentially pause the video and think about what should go here
okay so basically we need to know what is the local derivative of e to the x so
d by d x of e to the x is famously just e to the x and we've already just calculated e to the x and it's inside
out that data so we can do up that data times and out that grad that's the chain rule
so we're just chaining on to the current running grad and this is what the expression looks like it looks a little confusing but
this is what it is and that's the exponentiation so redefining we should now be able to
call a.x and hopefully the backward pass works as well okay and the last thing we'd like
to do of course is we'd like to be able to divide now i actually will implement something slightly more powerful than division
because division is just a special case of something a bit more powerful so in particular just by rearranging
if we have some kind of a b equals value of 4.0 here we'd like to basically be able to do a divide b and we'd like
this to be able to give us 0.5 now division actually can be reshuffled
as follows if we have a divide b that's actually the same as a multiplying one over b
and that's the same as a multiplying b to the power of negative one and so what i'd like to do instead is i
basically like to implement the operation of x to the k for some constant uh k so it's an integer or a
float um and we would like to be able to differentiate this and then as a special case uh negative one will be division
and so i'm doing that just because uh it's more general and um yeah you might as well do it that way so basically what
i'm saying is we can redefine uh division which we will put here somewhere
yeah we can put it here somewhere what i'm saying is that we can redefine division so self-divide other
can actually be rewritten as self times other to the power of negative one and now
a value raised to the power of negative one we have now defined that so here's
so we need to implement the pow function where am i going to put the power function maybe here somewhere
this is the skeleton for it so this function will be called when we try to raise a value to some power and
other will be that power now i'd like to make sure that other is only an int or a float usually other is
some kind of a different value object but here other will be forced to be an end or a float otherwise the math
won't work for for or try to achieve in the specific case that would be a different derivative expression if we wanted other
to be a value so here we create the output value which is just uh you know this data raised to
the power of other and other here could be for example negative one that's what we are hoping to achieve
and then uh this is the backwards stub and this is the fun part which is what is the uh chain rule expression here for
back for um back propagating through the power function where the power is to the power
of some kind of a constant so this is the exercise and maybe pause the video here and see if you can figure it out yourself as to what we should put
here
okay so you can actually go here and look at derivative rules as an example and we
see lots of derivatives that you can hopefully know from calculus in particular what we're looking for is the power rule
because that's telling us that if we're trying to take d by dx of x to the n which is what we're doing here
then that is just n times x to the n minus 1 right okay
so that's telling us about the local derivative of this power operation
so all we want here basically n is now other and self.data is x
and so this now becomes other which is n times
self.data which is now a python in torah float it's not a valley object we're accessing
the data attribute raised to the power of other minus one or n
minus one i can put brackets around this but this doesn't matter because
power takes precedence over multiply and python so that would have been okay and that's the local derivative only but
now we have to chain it and we change just simply by multiplying by output grad that's chain rule
and this should technically work and we're going to find out soon but now
if we do this this should now work and we get 0.5 so the forward pass works
but does the backward pass work and i realize that we actually also have to know how to subtract so
right now a minus b will not work to make it work we need one more
piece of code here and basically this is the
subtraction and the way we're going to implement subtraction is we're going to implement it by addition of a negation
and then to implement negation we're gonna multiply by negative one so just again using the stuff we've already built and just um expressing it in terms
of what we have and a minus b is now working okay so now let's scroll again to this expression here for this neuron
and let's just compute the backward pass here once we've defined o and let's draw it
so here's the gradients for all these leaf nodes for this two-dimensional neuron that has a 10h that we've seen
before so now what i'd like to do is i'd like to break up this 10h into this expression here
so let me copy paste this here and now instead of we'll preserve the label
and we will change how we define o so in particular we're going to implement this formula here
so we need e to the 2x minus 1 over e to the x plus 1. so e to the 2x we need to take 2 times n and we
need to exponentiate it that's e to the two x and then because we're using it twice let's create an intermediate
variable e and then define o as e plus one over
e minus one over e plus one e minus one over e plus one
and that should be it and then we should be able to draw that of o so now before i run this what do we
expect to see number one we're expecting to see a much longer graph here because we've broken up 10h
into a bunch of other operations but those operations are mathematically equivalent and so what we're expecting
to see is number one the same result here so the forward pass works and number two because of that
mathematical equivalence we expect to see the same backward pass and the same gradients on these leaf nodes so these
gradients should be identical so let's run this so number one let's verify that instead
of a single 10h node we have now x and we have plus we have times negative one
uh this is the division and we end up with the same forward pass here and then the gradients we have to be
careful because they're in slightly different order potentially the gradients for w2x2 should be 0 and 0.5
w2 and x2 are 0 and 0.5 and w1 x1 are 1 and negative 1.5
1 and negative 1.5 so that means that both our forward passes and backward passes were correct
because this turned out to be equivalent to 10h before and so the reason i wanted to go through
this exercise is number one we got to practice a few more operations and uh writing more backwards passes and number
two i wanted to illustrate the point that the um the level at which you implement your
operations is totally up to you you can implement backward passes for tiny expressions like a single individual
plus or a single times or you can implement them for say 10h
which is a kind of a potentially you can see it as a composite operation because it's made up of all these more atomic
operations but really all of this is kind of like a fake concept all that matters is we have some kind of inputs
and some kind of an output and this output is a function of the inputs in some way and as long as you can do forward pass and the backward pass of
that little operation it doesn't matter what that operation is and how composite it is
if you can write the local gradients you can chain the gradient and you can continue back propagation so the design
of what those functions are is completely up to you so now i would like to show you how you

# doing the same thing but in PyTorch: comparison

can do the exact same thing by using a modern deep neural network library like for example pytorch which i've roughly
modeled micrograd by and so pytorch is something you would use in production and i'll show you how you can
do the exact same thing but in pytorch api so i'm just going to copy paste it in and walk you through it a little bit
this is what it looks like so we're going to import pi torch and then we need to define these
value objects like we have here now micrograd is a scalar valued
engine so we only have scalar values like 2.0 but in pi torch everything is
based around tensors and like i mentioned tensors are just n-dimensional arrays of scalars
so that's why things get a little bit more complicated here i just need a scalar value to tensor a tensor with
just a single element but by default when you work with pytorch you would use um
more complicated tensors like this so if i import pytorch
then i can create tensors like this and this tensor for example is a two by three array
of scalar scalars in a single compact representation so we
can check its shape we see that it's a two by three array and so on so this is usually what you would work
with um in the actual libraries so here i'm creating a tensor that has only a single element
2.0 and then i'm casting it to be double
because python is by default using double precision for its floating point numbers so i'd like everything to be
identical by default the data type of these tensors will be float32 so it's
only using a single precision float so i'm casting it to double so that we have float64 just like in
python so i'm casting to double and then we get something similar to value of two the
next thing i have to do is because these are leaf nodes by default pytorch assumes that they do not require gradients so i need to explicitly say
that all of these nodes require gradients okay so this is going to construct scalar valued one element tensors
make sure that fighters knows that they require gradients now by default these are set to false by the way because of
efficiency reasons because usually you would not want gradients for leaf nodes like the inputs to the network and this
is just trying to be efficient in the most common cases so once we've defined all of our values
in python we can perform arithmetic just like we can here in microgradlend so this will just work and then there's a
torch.10h also and when we get back is a tensor again and we can
just like in micrograd it's got a data attribute and it's got grant attributes so these tensor objects just like in
micrograd have a dot data and a dot grad and the only difference here is that we need
to call it that item because otherwise um pi torch
that item basically takes a single tensor of one element and it just returns that element stripping out
the tensor so let me just run this and hopefully we are going to get this is going to print
the forward pass which is 0.707 and this will be the gradients which
hopefully are 0.5 0 negative 1.5 and 1. so if we just run this
there we go 0.7 so the forward pass agrees and then point five zero negative one point five
and one so pi torch agrees with us and just to show you here basically o
here's a tensor with a single element and it's a double and we can call that item on it to just
get the single number out so that's what item does and o is a tensor object like i mentioned and it's
got a backward function just like we've implemented and then all of these also have a dot graph so like x2 for example in the grad
and it's a tensor and we can pop out the individual number with that actin
so basically torches torch can do what we did in micrograph is a special case when your
tensors are all single element tensors but the big deal with pytorch is that everything is significantly more
efficient because we are working with these tensor objects and we can do lots of operations in parallel on all of
these tensors but otherwise what we've built very much agrees with the api of pytorch

è¿™æ®µå†…å®¹å±•ç¤ºäº†å¦‚ä½•ç”¨ PyTorch æ¥å®ç°ç±»ä¼¼äºå¾®å‹ç¥ç»ç½‘ç»œæ¡†æ¶ **micrograd** çš„åŠŸèƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨è®¡ç®—å›¾å’Œåå‘ä¼ æ’­æ–¹é¢ã€‚ä½ å¯ä»¥å°†å®ƒç†è§£ä¸ºä¸€ä¸ªå¯¹æ¯”ï¼Œå±•ç¤ºäº†åœ¨ PyTorch ä¸­å¦‚ä½•åˆ©ç”¨å…¶å¼ é‡ï¼ˆtensorï¼‰æœºåˆ¶è¿›è¡Œç›¸åŒçš„è®¡ç®—ã€‚

### ä¸»è¦å†…å®¹ï¼š

1. **ä½¿ç”¨ PyTorch çš„å¼ é‡**ï¼š

   * åœ¨ `micrograd` ä¸­ï¼Œæˆ‘ä»¬åªå¤„ç†æ ‡é‡ï¼ˆå¦‚ `2.0`ï¼‰ä½œä¸º `Value` å¯¹è±¡ï¼Œè€Œåœ¨ PyTorch ä¸­ï¼Œæ“ä½œçš„æ˜¯ `å¼ é‡`ï¼ˆtensorï¼‰ï¼Œå¼ é‡æ˜¯ä¸€ä¸ªå¤šç»´æ•°ç»„ï¼Œå¯ä»¥åŒ…å«æ ‡é‡ã€å‘é‡ã€çŸ©é˜µç­‰ã€‚
   * ä¾‹å¦‚ï¼šåˆ›å»ºä¸€ä¸ªåŒ…å«å•ä¸€å…ƒç´ çš„å¼ é‡ `tensor(2.0)`ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ `tensor` æ¥è¡¨ç¤ºä¸€ä¸ªåŒ…å«å¤šä¸ªå…ƒç´ çš„å¤šç»´æ•°ç»„ï¼ˆå¦‚ `2x3` çš„çŸ©é˜µï¼‰ã€‚

2. **æ•°æ®ç±»å‹å’Œç²¾åº¦**ï¼š

   * é»˜è®¤æƒ…å†µä¸‹ï¼ŒPyTorch ä½¿ç”¨ `float32` ç²¾åº¦ï¼Œä½†ä¸ºäº†ä¸ `micrograd` ä¿æŒä¸€è‡´ï¼ˆé€šå¸¸ä½¿ç”¨ `float64`ï¼‰ï¼Œæˆ‘ä»¬å°†æ•°æ®ç±»å‹å¼ºåˆ¶è½¬æ¢ä¸º `double`ï¼ˆå³ `float64`ï¼‰ã€‚

3. **æ ‡è®°è®¡ç®—å›¾ä¸­çš„å¶å­èŠ‚ç‚¹**ï¼š

   * åœ¨ PyTorch ä¸­ï¼Œè®¡ç®—å›¾çš„èŠ‚ç‚¹ï¼ˆå¦‚è¾“å…¥å€¼ï¼‰é»˜è®¤æ˜¯ **ä¸éœ€è¦æ¢¯åº¦** çš„ã€‚å› æ­¤ï¼Œå¿…é¡»æ˜¾å¼åœ°å‘Šè¯‰ PyTorch å“ªäº›å¼ é‡éœ€è¦è®¡ç®—æ¢¯åº¦ï¼ˆå³éœ€è¦å‚ä¸åå‘ä¼ æ’­ï¼‰ã€‚æˆ‘ä»¬é€šè¿‡è®¾ç½® `requires_grad=True` æ¥æ ‡è®°è¿™äº›å¼ é‡ã€‚

4. **æ‰§è¡Œæ•°å­¦è¿ç®—**ï¼š

   * ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥åƒåœ¨ `micrograd` ä¸­ä¸€æ ·ï¼Œåœ¨è¿™äº›å¼ é‡ä¸Šæ‰§è¡ŒåŠ æ³•ã€ä¹˜æ³•ç­‰è¿ç®—ã€‚PyTorch ä¼šè‡ªåŠ¨å¤„ç†è®¡ç®—å›¾å’Œåå‘ä¼ æ’­ã€‚

5. **åå‘ä¼ æ’­**ï¼š

   * PyTorch çš„ `Tensor` å¯¹è±¡å…·æœ‰ `.backward()` æ–¹æ³•ï¼Œå®ƒä¼šè‡ªåŠ¨ä¸ºè®¡ç®—å›¾ä¸­çš„æ‰€æœ‰éœ€è¦æ¢¯åº¦çš„èŠ‚ç‚¹è®¡ç®—åå‘ä¼ æ’­ï¼ˆæ¢¯åº¦ï¼‰ã€‚é€šè¿‡ `.grad` å±æ€§ï¼Œå¯ä»¥è®¿é—®è¿™äº›æ¢¯åº¦ã€‚

6. **å¦‚ä½•ä½¿ç”¨ PyTorch å¼ é‡**ï¼š

   * PyTorch ä¸­çš„ `Tensor` å¯¹è±¡åŒ…å« `.data` å’Œ `.grad` å±æ€§ï¼Œç±»ä¼¼äº `micrograd` ä¸­çš„ `Value` å¯¹è±¡ã€‚
   * å¦‚æœæˆ‘ä»¬æƒ³è¦è·å–å¼ é‡çš„æ•°å€¼ï¼Œå¯ä»¥ä½¿ç”¨ `.item()` æ–¹æ³•ã€‚å› ä¸º PyTorch é»˜è®¤è¿”å›çš„æ˜¯ä¸€ä¸ªå¼ é‡å¯¹è±¡ï¼Œå³ä½¿å®ƒåªæœ‰ä¸€ä¸ªå…ƒç´ ï¼Œæˆ‘ä»¬éœ€è¦ `.item()` æå–è¯¥å€¼ã€‚

7. **æ•ˆç‡**ï¼š

   * PyTorch çš„ä¼˜åŠ¿åœ¨äºå®ƒèƒ½å¤Ÿé«˜æ•ˆåœ°å¤„ç†å¤§è§„æ¨¡å¼ é‡è®¡ç®—ï¼Œå¯ä»¥é€šè¿‡å¹¶è¡ŒåŒ–è®¡ç®—æ¥æé«˜æ•ˆç‡ï¼Œè€Œ `micrograd` æ˜¯ä¸ºå­¦ä¹ å’Œå®éªŒè€Œè®¾è®¡çš„æ›´ç®€æ´çš„æ¡†æ¶ï¼Œé€šå¸¸å¤„ç†çš„æ˜¯å•ä¸ªæ ‡é‡ã€‚

### ä»£ç ç¤ºä¾‹ï¼š

```python
import torch

# åˆ›å»ºä¸€ä¸ªæ ‡é‡å¼ é‡
x = torch.tensor(2.0, dtype=torch.float64, requires_grad=True)

# å¯¹å¼ é‡è¿›è¡Œæ“ä½œ
y = torch.tanh(x)

# æ‰§è¡Œåå‘ä¼ æ’­
y.backward()

# æ‰“å°ç»“æœ
print("Forward pass result:", y.item())  # æ‰“å° tanh(x) çš„å€¼
print("Gradients:", x.grad.item())  # æ‰“å° x çš„æ¢¯åº¦
```

### æ€»ç»“ï¼š

è¿™æ®µä»£ç å±•ç¤ºäº†å¦‚ä½•åœ¨ PyTorch ä¸­è¿›è¡Œæ ‡é‡å¼ é‡çš„åˆ›å»ºã€å‰å‘è®¡ç®—ï¼ˆå¦‚ `tanh` å‡½æ•°ï¼‰ä»¥åŠåå‘ä¼ æ’­ï¼ˆè®¡ç®—æ¢¯åº¦ï¼‰ã€‚ä¸ `micrograd` çš„æ ¸å¿ƒæ€æƒ³ä¸€è‡´ï¼ŒPyTorch é€šè¿‡è®¡ç®—å›¾å’Œè‡ªåŠ¨å¾®åˆ†æ”¯æŒæ›´åŠ å¤æ‚å’Œé«˜æ•ˆçš„ç¥ç»ç½‘ç»œè®­ç»ƒï¼Œä½†å…¶åº•å±‚ç»“æ„å’Œ API æ˜¯ä¸ºå¤§è§„æ¨¡çš„å¼ é‡æ“ä½œè€Œä¼˜åŒ–çš„ï¼Œèƒ½å¤Ÿè¿›è¡Œå¹¶è¡Œè®¡ç®—ã€‚


# building out a neural net library (multi-layer perceptron) in micrograd

okay so now that we have some machinery to build out pretty complicated mathematical expressions we can also start building out neural nets and as i
mentioned neural nets are just a specific class of mathematical expressions so we're going to start building out a
neural net piece by piece and eventually we'll build out a two-layer multi-layer layer perceptron as it's called and i'll
show you exactly what that means let's start with a single individual neuron we've implemented one here but
here i'm going to implement one that also subscribes to the pytorch api in how it designs its neural network
modules so just like we saw that we can like match the api of pytorch on the auto grad side we're going to try
to do that on the neural network modules so here's class neuron and just for the sake of efficiency i'm
going to copy paste some sections that are relatively straightforward so the constructor will take
number of inputs to this neuron which is how many inputs come to a neuron so this
one for example has three inputs and then it's going to create a weight there is some random number between
negative one and one for every one of those inputs and a bias that controls the overall
trigger happiness of this neuron and then we're going to implement a def underscore underscore call
of self and x some input x and really what we don't do here is w times x plus b
where w times x here is a dot product specifically now if you haven't seen
call let me just return 0.0 here for now the way this works now is we can have an x
which is say like 2.0 3.0 then we can initialize a neuron that is two-dimensional
because these are two numbers and then we can feed those two numbers into that neuron to get an output
and so when you use this notation n of x python will use call
so currently call just return 0.0
now we'd like to actually do the forward pass of this neuron instead so we're going to do here first is we
need to basically multiply all of the elements of w with all of the elements of x pairwise we need to multiply them
so the first thing we're going to do is we're going to zip up celta w and x and in python zip takes two iterators
and it creates a new iterator that iterates over the tuples of the corresponding entries
so for example just to show you we can print this list and still return 0.0 here
sorry so we see that these w's are paired up
with the x's w with x
and now what we want to do is
for w i x i in we want to multiply w times
w wi times x i and then we want to sum all of that together to come up with an activation
and add also subnet b on top so that's the raw activation and then of course we need to pass that through a
non-linearity so what we're going to be returning is act.10h and here's out
so now we see that we are getting some outputs and we get a different output from a neuron each time because we are
initializing different weights and by and biases and then to be a bit more efficient here actually sum by the way takes a second
optional parameter which is the start and by default the start is zero so
these elements of this sum will be added on top of zero to begin with but actually we can just start with cell dot
b and then we just have an expression like this
and then the generator expression here must be parenthesized in python there we go
yep so now we can forward a single neuron next up we're going to define a layer of neurons so here we have a
schematic for a mlb so we see that these mlps each layer
this is one layer has actually a number of neurons and they're not connected to each other but all of them are fully connected to the input
so what is a layer of neurons it's just it's just a set of neurons evaluated independently
so in the interest of time i'm going to do something fairly straightforward here
it's um literally a layer is just a list of neurons
and then how many neurons do we have we take that as an input argument here how many neurons do you want in your layer
number of outputs in this layer and so we just initialize completely independent neurons with this given
dimensionality and when we call on it we just independently evaluate them so now instead of a neuron
we can make a layer of neurons they are two-dimensional neurons and let's have three of them and now we see that we have three
independent evaluations of three different neurons right okay finally let's complete this picture
and define an entire multi-layer perceptron or mlp and as we can see here in an mlp these
layers just feed into each other sequentially so let's come here and i'm just going to copy the code here in interest of time
so an mlp is very similar we're taking the number of inputs as before but now instead of taking a
single n out which is number of neurons in a single layer we're going to take a list of an outs and this list defines
the sizes of all the layers that we want in our mlp so here we just put them all together and then iterate over consecutive pairs
of these sizes and create layer objects for them and then in the call function we are just calling them sequentially so that's
an mlp really and let's actually re-implement this picture so we want three input neurons
and then two layers of four and an output unit so we want
a three-dimensional input say this is an example input we want three inputs into
two layers of four and one output and this of course is an mlp
and there we go that's a forward pass of an mlp to make this a little bit nicer you see how we have just a single element but
it's wrapped in a list because layer always returns lists circle for convenience
return outs at zero if len out is exactly a single element else return fullest
and this will allow us to just get a single value out at the last layer that only has a single neuron
and finally we should be able to draw dot of n of x and as you might imagine
these expressions are now getting relatively involved so this is an entire mlp that we're
defining now
all the way until a single output okay and so obviously you would never
differentiate on pen and paper these expressions but with micrograd we will be able to back propagate all the way
through this and back propagate into these weights of all these neurons so
let's see how that works okay so let's create ourselves a very simple example data set here

è¿™æ®µå†…å®¹å±•ç¤ºäº†å¦‚ä½•ç”¨ **micrograd** æ„å»ºä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œåº“ï¼Œæœ€ç»ˆå®ç°ä¸€ä¸ª **å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰**ã€‚å®ƒåˆ†æ­¥éª¤è§£é‡Šäº†å¦‚ä½•æ„å»ºç¥ç»å…ƒã€ç¥ç»å±‚ä»¥åŠæœ€ç»ˆçš„å¤šå±‚æ„ŸçŸ¥æœºï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•æ‰§è¡Œå‰å‘ä¼ æ’­ï¼ˆForward Passï¼‰å’Œåå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰æ“ä½œã€‚

### ä¸»è¦æ­¥éª¤ï¼š

1. **æ„å»ºç¥ç»å…ƒï¼ˆNeuronï¼‰**ï¼š

   * æ¯ä¸ªç¥ç»å…ƒéƒ½æœ‰å¤šä¸ªè¾“å…¥ï¼Œé’ˆå¯¹æ¯ä¸ªè¾“å…¥éƒ½æœ‰ä¸€ä¸ª **æƒé‡**ï¼ˆweightï¼‰ï¼Œä»¥åŠä¸€ä¸ª **åç½®**ï¼ˆbiasï¼‰ã€‚
   * ç¥ç»å…ƒé€šè¿‡è®¡ç®—è¾“å…¥ä¸æƒé‡çš„åŠ æƒå’Œï¼Œå†åŠ ä¸Šåç½®æ¥å¾—åˆ° **æ¿€æ´»å€¼**ã€‚ç„¶åï¼Œè¯¥æ¿€æ´»å€¼é€šè¿‡ä¸€ä¸ªéçº¿æ€§å‡½æ•°ï¼ˆå¦‚ `tanh`ï¼‰æ¥è¿›è¡Œæ¿€æ´»ã€‚
   * å®ç°çš„ç¥ç»å…ƒç±»ï¼ˆ`Neuron`ï¼‰åŒ…æ‹¬ï¼š

     * æƒé‡å’Œåç½®çš„åˆå§‹åŒ–ï¼šæƒé‡æ˜¯éšæœºç”Ÿæˆçš„ï¼Œåç½®åˆå§‹åŒ–ä¸º 0ã€‚
     * `__call__` æ–¹æ³•ï¼šé€šè¿‡è¯¥æ–¹æ³•å¯ä»¥è¿›è¡Œå‰å‘ä¼ æ’­è®¡ç®—ï¼Œè®¡ç®—æ–¹å¼æ˜¯å¯¹æƒé‡å’Œè¾“å…¥è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå†åŠ ä¸Šåç½®ï¼Œæœ€åé€šè¿‡æ¿€æ´»å‡½æ•°è¾“å‡ºç»“æœã€‚

2. **æ„å»ºç¥ç»å±‚ï¼ˆLayerï¼‰**ï¼š

   * ç¥ç»å±‚åŒ…å«å¤šä¸ªç¥ç»å…ƒï¼Œæ¯ä¸ªç¥ç»å…ƒçš„è¾“å‡ºéƒ½ä¸è¾“å…¥è¿æ¥ï¼ˆå®Œå…¨è¿æ¥å±‚ï¼‰ã€‚æ¯ä¸ªç¥ç»å…ƒçš„è®¡ç®—æ˜¯ç‹¬ç«‹çš„ã€‚
   * å®ç°æ—¶ï¼Œç¥ç»å±‚å®é™…ä¸Šæ˜¯å¤šä¸ªç¥ç»å…ƒçš„é›†åˆï¼Œæ„æˆä¸€ä¸ª **ç¥ç»å…ƒåˆ—è¡¨**ã€‚å½“æˆ‘ä»¬è°ƒç”¨å±‚æ—¶ï¼Œå®é™…ä¸Šå°±æ˜¯å¯¹æ¯ä¸ªç¥ç»å…ƒè¿›è¡Œç‹¬ç«‹çš„è®¡ç®—ï¼Œè¾“å‡ºä¸€ä¸ªç¥ç»å…ƒçš„ç»“æœã€‚

3. **æ„å»ºå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰**ï¼š

   * MLP æ˜¯ç”±å¤šä¸ªç¥ç»å±‚æŒ‰é¡ºåºç»„æˆçš„ç¥ç»ç½‘ç»œã€‚æ¯ä¸€å±‚çš„è¾“å‡ºæ˜¯ä¸‹ä¸€å±‚çš„è¾“å…¥ã€‚
   * æ„å»ºæ—¶ï¼š

     * é€šè¿‡è¾“å…¥å±‚çš„å¤§å°å’Œæ¯å±‚çš„ç¥ç»å…ƒæ•°ï¼ŒæŒ‰é¡ºåºåˆ›å»ºå¤šä¸ªç¥ç»å±‚ã€‚
     * åœ¨ `__call__` æ–¹æ³•ä¸­ï¼Œä¾æ¬¡è°ƒç”¨æ¯ä¸€å±‚çš„å‰å‘ä¼ æ’­ï¼Œæœ€ç»ˆè¾“å‡ºæœ€åä¸€å±‚çš„ç»“æœã€‚
   * ä¸ºäº†æ–¹ä¾¿å¤„ç†ï¼Œå½“åªæœ‰ä¸€ä¸ªè¾“å‡ºç¥ç»å…ƒæ—¶ï¼Œç›´æ¥è¿”å›å•ä¸ªè¾“å‡ºè€Œä¸æ˜¯åˆ—è¡¨ã€‚

4. **å‰å‘ä¼ æ’­ï¼ˆForward Passï¼‰**ï¼š

   * å¯¹äºæ¯ä¸€å±‚ï¼Œç¥ç»å…ƒä¾æ¬¡è®¡ç®—è¾“å…¥ä¸æƒé‡çš„åŠ æƒå’Œï¼Œå†åŠ ä¸Šåç½®ï¼Œæœ€åé€šè¿‡éçº¿æ€§æ¿€æ´»å‡½æ•°è¾“å‡ºã€‚
   * æœ€ç»ˆé€šè¿‡æ‰€æœ‰å±‚çš„å‰å‘ä¼ æ’­å¾—åˆ°ç¥ç»ç½‘ç»œçš„è¾“å‡ºã€‚

5. **åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰**ï¼š

   * è™½ç„¶æ²¡æœ‰åœ¨è¿™æ®µä»£ç ä¸­ç›´æ¥å±•ç¤ºï¼Œä½†é€šè¿‡æ„å»ºçš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œ**micrograd** å¯ä»¥è‡ªåŠ¨å¤„ç†åå‘ä¼ æ’­ã€‚å³æ ¹æ®æŸå¤±å‡½æ•°çš„æ¢¯åº¦ï¼Œå°†è¯¯å·®é€å±‚åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¯ä¸ªæƒé‡å’Œåç½®çš„æ¢¯åº¦ã€‚

### æ ¸å¿ƒä»£ç ç¤ºä¾‹ï¼š

```python
class Neuron:
    def __init__(self, n_inputs):
        # åˆå§‹åŒ–æƒé‡å’Œåç½®
        self.weights = [random.uniform(-1, 1) for _ in range(n_inputs)]
        self.bias = 0.0

    def __call__(self, x):
        # è®¡ç®—åŠ æƒå’Œï¼Œæ¿€æ´»å‡½æ•°åº”ç”¨
        activation = sum(w * xi for w, xi in zip(self.weights, x)) + self.bias
        return math.tanh(activation)

class Layer:
    def __init__(self, n_inputs, n_neurons):
        # åˆå§‹åŒ–å¤šä¸ªç¥ç»å…ƒ
        self.neurons = [Neuron(n_inputs) for _ in range(n_neurons)]

    def __call__(self, x):
        # å¯¹æ¯ä¸ªç¥ç»å…ƒè¿›è¡Œå‰å‘ä¼ æ’­
        return [neuron(x) for neuron in self.neurons]

class MLP:
    def __init__(self, n_inputs, layer_sizes):
        # åˆå§‹åŒ–å¤šå±‚æ„ŸçŸ¥æœº
        self.layers = []
        prev_size = n_inputs
        for size in layer_sizes:
            self.layers.append(Layer(prev_size, size))
            prev_size = size

    def __call__(self, x):
        # ä¾æ¬¡é€šè¿‡æ¯ä¸€å±‚
        for layer in self.layers:
            x = layer(x)
        return x
```

### å…³é”®ç‚¹ï¼š

* **`Neuron` ç±»**ï¼šæ¯ä¸ªç¥ç»å…ƒéƒ½æœ‰å¤šä¸ªè¾“å…¥ã€æƒé‡å’Œåç½®ï¼Œè®¡ç®— `w*x + b` åï¼Œåº”ç”¨æ¿€æ´»å‡½æ•°ï¼ˆä¾‹å¦‚ `tanh`ï¼‰ã€‚
* **`Layer` ç±»**ï¼šæ¯ä¸€å±‚åŒ…å«å¤šä¸ªç¥ç»å…ƒï¼Œå‰å‘ä¼ æ’­æ—¶è®¡ç®—æ‰€æœ‰ç¥ç»å…ƒçš„è¾“å‡ºã€‚
* **`MLP` ç±»**ï¼šå°†å¤šä¸ªç¥ç»å±‚æŒ‰é¡ºåºè¿æ¥ï¼Œæ„å»ºä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºæ¨¡å‹ã€‚

### åç»­æ­¥éª¤ï¼š

* é€šè¿‡è¿™ä¸ªç¥ç»ç½‘ç»œçš„æ¡†æ¶ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ `micrograd` ä¸­å®ç°å¯¹ç¥ç»ç½‘ç»œçš„åå‘ä¼ æ’­ã€‚
* å¯ä»¥é€šè¿‡åˆ›å»ºä¸€ä¸ªç®€å•çš„æ•°æ®é›†å¹¶è¿›è¡Œè®­ç»ƒæ¥æµ‹è¯•æ•´ä¸ªç¥ç»ç½‘ç»œçš„æ•ˆæœã€‚

è¿™æ®µä»£ç å±•ç¤ºäº†å¦‚ä½•ä»åŸºæœ¬çš„ç¥ç»å…ƒå¼€å§‹ï¼Œé€æ­¥æ„å»ºèµ·ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œï¼Œå¹¶åˆ©ç”¨å¾®å‹çš„è‡ªåŠ¨æ±‚å¯¼åº“ `micrograd` æ¥å®ç°æ¢¯åº¦è®¡ç®—ï¼Œæœ€ç»ˆå®ç°ç¥ç»ç½‘ç»œçš„è®­ç»ƒã€‚


# creating a tiny dataset, writing the loss function

so this data set has four examples and so we have four possible inputs into the neural net
and we have four desired targets so we'd like the neural net to assign
or output 1.0 when it's fed this example negative one when it's fed these examples and one when it's fed this
example so it's a very simple binary classifier neural net basically that we would like here
now let's think what the neural net currently thinks about these four examples we can just get their predictions
um basically we can just call n of x for x in axis and then we can
print so these are the outputs of the neural net on those four examples
so the first one is 0.91 but we'd like it to be one so we should push this one
higher this one we want to be higher this one says 0.88 and we want this to
be negative one this is 0.8 we want it to be negative one and this one is 0.8 we want it to be one
so how do we make the neural net and how do we tune the weights to better predict the desired targets
and the trick used in deep learning to achieve this is to calculate a single number that somehow
measures the total performance of your neural net and we call this single number the loss
so the loss first is is a single number that we're going to define that basically measures how
well the neural net is performing right now we have the intuitive sense that it's not performing very well because we're not very much close to this
so the loss will be high and we'll want to minimize the loss so in particular in this case what we're
going to do is we're going to implement the mean squared error loss so this is doing is we're going to
basically iterate um for y ground truth
and y output in zip of um wise and white red so we're going to
pair up the ground truths with the predictions and this zip iterates over tuples of
them and for each y ground truth and y output we're going
to subtract them and square them
so let's first see what these losses are these are individual loss components and so basically for each
one of the four we are taking the prediction and the ground truth we are subtracting them and
squaring them so because this one is so close to its target 0.91
is almost one subtracting them gives a very small number
so here we would get like a negative point one and then squaring it just makes sure
that regardless of whether we are more negative or more positive we always get a positive
number instead of squaring we should we could also take for example the absolute value we need to discard the sign
and so you see that the expression is ranged so that you only get zero exactly when y out is equal to y ground truth
when those two are equal so your prediction is exactly the target you are going to get zero and if your prediction is not the target
you are going to get some other number so here for example we are way off and so that's why the loss is quite high
and the more off we are the greater the loss will be so we don't want high loss we want low
loss and so the final loss here will be just the sum
of all of these numbers so you see that this should be zero roughly plus zero roughly
but plus seven so loss should be about seven
here and now we want to minimize the loss we want the loss to be low
because if loss is low then every one of the predictions is equal to its target
so the loss the lowest it can be is zero and the greater it is the worse off the
neural net is predicting so now of course if we do lost that backward
something magical happened when i hit enter and the magical thing of course that happened is that we can look at
end.layers.neuron and that layers at say like the the first layer that neurons at zero
because remember that mlp has the layers which is a list and each layer has a neurons which is a
list and that gives us an individual neuron and then it's got some weights and so we can for example look at the
weights at zero um
oops it's not called weights it's called w and that's a value but now this value
also has a groud because of the backward pass and so we see that because this gradient
here on this particular weight of this particular neuron of this particular layer is negative we see that its influence on the loss is
also negative so slightly increasing this particular weight of this neuron of this layer would make the loss go down
and we actually have this information for every single one of our neurons and all their parameters actually it's worth looking at also the draw dot loss by the
way so previously we looked at the draw dot of a single neural neuron forward pass and that was already a large expression
but what is this expression we actually forwarded every one of those four examples and
then we have the loss on top of them with the mean squared error and so this is a really massive graph
because this graph that we've built up now oh my gosh this graph that we've built
up now which is kind of excessive it's excessive because it has four forward passes of a neural net for every one of
the examples and then it has the loss on top and it ends with the value of the loss which was 7.12
and this loss will now back propagate through all the four forward passes all the way through just every single
intermediate value of the neural net all the way back to of course the parameters of the weights which are the
input so these weight parameters here are inputs to this neural net
and these numbers here these scalars are inputs to the neural net so if we went around here
we'll probably find some of these examples this 1.0 potentially maybe this 1.0 or you know
some of the others and you'll see that they all have gradients as well the thing is these gradients on the
input data are not that useful to us and that's because the input data seems
to be not changeable it's it's a given to the problem and so it's a fixed input we're not going to be changing it or
messing with it even though we do have gradients for it but some of these gradients here
will be for the neural network parameters the ws and the bs and those we of course we want to change
okay so now we're going to want some convenience code to gather up all of the parameters of the neural net so that we

è¿™æ®µä»£ç è®²è§£äº†å¦‚ä½•åœ¨ç¥ç»ç½‘ç»œä¸­æ„å»ºå’Œä½¿ç”¨æŸå¤±å‡½æ•°ï¼Œå¹¶ä¸”å±•ç¤ºäº†å¦‚ä½•é€šè¿‡åå‘ä¼ æ’­æ¥è°ƒæ•´ç¥ç»ç½‘ç»œçš„æƒé‡ã€‚ä»¥ä¸‹æ˜¯å¯¹è¿™éƒ¨åˆ†å†…å®¹çš„è¯¦ç»†è§£é‡Šï¼š

### 1. **åˆ›å»ºæ•°æ®é›†å’Œç›®æ ‡å€¼**

æˆ‘ä»¬é¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ªç®€å•çš„æ•°æ®é›†ï¼ŒåŒ…æ‹¬å››ä¸ªè¾“å…¥æ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬å¯¹åº”ä¸€ä¸ªç›®æ ‡è¾“å‡ºã€‚ç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªç®€å•çš„äºŒåˆ†ç±»ç¥ç»ç½‘ç»œï¼Œä½¿å…¶èƒ½å¤Ÿè¾“å‡ºæ¥è¿‘ç›®æ ‡å€¼ã€‚

```python
# å››ä¸ªè¾“å…¥æ ·æœ¬ä¸ç›®æ ‡
inputs = [
    [-1, -1],
    [1, -1],
    [1, 1],
    [-1, 1]
]

# å¯¹åº”çš„ç›®æ ‡å€¼
targets = [1.0, -1.0, -1.0, 1.0]
```

### 2. **å‰å‘ä¼ æ’­**

å¯¹äºæ¯ä¸€ä¸ªè¾“å…¥ï¼Œæˆ‘ä»¬å°†å…¶è¾“å…¥åˆ°ç¥ç»ç½‘ç»œä¸­ï¼Œå¹¶è·å–é¢„æµ‹å€¼ã€‚å½“å‰ç½‘ç»œçš„é¢„æµ‹ç»“æœä¸ç›®æ ‡å€¼ä¹‹é—´å­˜åœ¨ä¸€å®šçš„å·®è·ï¼Œè¡¨æ˜ç¥ç»ç½‘ç»œçš„è¡¨ç°ä¸ä½³ã€‚

```python
# è¾“å‡ºé¢„æµ‹å€¼
predictions = [n(x) for x in inputs]
```

### 3. **è®¡ç®—æŸå¤±**

ä¸ºäº†è¡¡é‡ç¥ç»ç½‘ç»œçš„æ€§èƒ½ï¼Œæˆ‘ä»¬ä½¿ç”¨ **å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰æŸå¤±å‡½æ•°**ï¼Œè¿™æ˜¯æœºå™¨å­¦ä¹ ä¸­å¸¸ç”¨çš„æŸå¤±å‡½æ•°ã€‚å®ƒé€šè¿‡è®¡ç®—é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚æ¥è¯„ä¼°æ¨¡å‹çš„æ•ˆæœã€‚å…·ä½“è¿‡ç¨‹æ˜¯è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹è¯¯å·®ï¼Œå¹¶å°†å…¶å¹³æ–¹åæ±‚å’Œï¼Œæœ€ç»ˆè®¡ç®—å‡ºæ‰€æœ‰æ ·æœ¬çš„å¹³å‡è¯¯å·®ã€‚

```python
# è®¡ç®—å‡æ–¹è¯¯å·®æŸå¤±
loss = sum((y_true - y_pred) ** 2 for y_true, y_pred in zip(targets, predictions))
```

å¯¹äºæ¯ä¸ªé¢„æµ‹å€¼ï¼Œæˆ‘ä»¬è®¡ç®—å®ƒä¸çœŸå®ç›®æ ‡ä¹‹é—´çš„è¯¯å·®ï¼Œå¹¶é€šè¿‡å¹³æ–¹ç¡®ä¿è¯¯å·®æ˜¯æ­£å€¼ã€‚æœ€ç»ˆï¼Œé€šè¿‡æ±‚å’Œå¾—åˆ°æ€»æŸå¤±ã€‚æŸå¤±è¶Šå°ï¼Œè¡¨ç¤ºæ¨¡å‹çš„é¢„æµ‹æ•ˆæœè¶Šå¥½ã€‚

### 4. **åå‘ä¼ æ’­å’Œæ¢¯åº¦**

æŸå¤±å€¼æ˜¯è¡¡é‡æ¨¡å‹æ€§èƒ½çš„å…³é”®ï¼Œå®ƒç”¨äºæŒ‡å¯¼æˆ‘ä»¬å¦‚ä½•è°ƒæ•´ç½‘ç»œçš„å‚æ•°ï¼ˆå¦‚æƒé‡å’Œåç½®ï¼‰ã€‚é€šè¿‡ **åå‘ä¼ æ’­**ï¼Œæˆ‘ä»¬è®¡ç®—æŸå¤±ç›¸å¯¹äºå„ä¸ªå‚æ•°çš„æ¢¯åº¦ï¼Œå¹¶æ ¹æ®è¿™äº›æ¢¯åº¦è°ƒæ•´å‚æ•°ã€‚å…·ä½“æ¥è¯´ï¼š

* æ¯ä¸ªç¥ç»å…ƒçš„æƒé‡å’Œåç½®éƒ½ä¼šæœ‰ä¸€ä¸ªæ¢¯åº¦ï¼Œè¡¨ç¤ºè¯¥æƒé‡æˆ–åç½®å¯¹æ€»æŸå¤±çš„å½±å“ã€‚
* åå‘ä¼ æ’­è¿‡ç¨‹ä¼šéå†æ•´ä¸ªè®¡ç®—å›¾ï¼Œä»æŸå¤±å¼€å§‹ï¼Œé€æ­¥å›ä¼ ï¼Œè®¡ç®—æ¯ä¸ªç¥ç»å…ƒçš„æ¢¯åº¦ã€‚

ä¾‹å¦‚ï¼Œå¯¹äºç¥ç»ç½‘ç»œçš„ç¬¬ä¸€ä¸ªå±‚çš„æŸä¸ªç¥ç»å…ƒï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒçš„æƒé‡æ¢¯åº¦æ˜¯è´Ÿå€¼ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦å¢å¤§è¯¥æƒé‡æ‰èƒ½ä½¿æŸå¤±å‡å°‘ã€‚

```python
# æŸ¥çœ‹æŸä¸ªç¥ç»å…ƒçš„æƒé‡å’Œæ¢¯åº¦
layer_0_neuron_0_weight_grad = n.layers[0].neurons[0].weights[0].grad
```

### 5. **å›¾å½¢è¡¨ç¤ºå’Œåå‘ä¼ æ’­**

æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«æ‰€æœ‰è®¡ç®—æ­¥éª¤çš„è®¡ç®—å›¾ã€‚è¿™ä¸ªå›¾éå¸¸åºå¤§ï¼Œå› ä¸ºå®ƒåŒ…å«äº†æ¯ä¸ªè¾“å…¥æ ·æœ¬çš„å‰å‘ä¼ æ’­ï¼Œå¹¶ä¸”åœ¨æœ€åè®¡ç®—å‡ºæ€»çš„æŸå¤±å€¼ã€‚åå‘ä¼ æ’­ä¼šæ²¿ç€è¿™ä¸ªå›¾è¿›è¡Œï¼Œé€æ­¥è®¡ç®—æ¢¯åº¦ã€‚

```python
# ç»˜åˆ¶è®¡ç®—å›¾
draw(loss)
```

åå‘ä¼ æ’­ä¸ä»…ä¼šå½±å“ç½‘ç»œçš„å‚æ•°ï¼Œè¿˜ä¼šå½±å“è¾“å…¥æ•°æ®çš„æ¢¯åº¦ï¼Œå°½ç®¡é€šå¸¸æƒ…å†µä¸‹æˆ‘ä»¬ä¸ä¼šè°ƒæ•´è¾“å…¥æ•°æ®çš„å€¼ï¼ˆå®ƒæ˜¯å›ºå®šçš„ï¼‰ã€‚

### 6. **è°ƒæ•´ç½‘ç»œå‚æ•°**

æœ€ç»ˆï¼Œæˆ‘ä»¬å¸Œæœ›é€šè¿‡è°ƒæ•´ç¥ç»ç½‘ç»œçš„å‚æ•°ï¼ˆæƒé‡å’Œåç½®ï¼‰æ¥æœ€å°åŒ–æŸå¤±ï¼Œä»è€Œæé«˜é¢„æµ‹å‡†ç¡®æ€§ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦æå–ç½‘ç»œä¸­çš„æ‰€æœ‰å‚æ•°ï¼Œå¹¶è®¡ç®—æ¢¯åº¦ã€‚

```python
# æ”¶é›†ç¥ç»ç½‘ç»œçš„æ‰€æœ‰å‚æ•°ï¼ˆæƒé‡å’Œåç½®ï¼‰
parameters = gather_parameters(n)
```

### æ€»ç»“

* **æŸå¤±å‡½æ•°**ï¼šæˆ‘ä»¬ä½¿ç”¨ **å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰** æ¥è¯„ä¼°ç¥ç»ç½‘ç»œçš„é¢„æµ‹è¯¯å·®ï¼ŒæŸå¤±è¶Šä½ï¼Œè¡¨ç¤ºç½‘ç»œæ€§èƒ½è¶Šå¥½ã€‚
* **åå‘ä¼ æ’­**ï¼šé€šè¿‡åå‘ä¼ æ’­è®¡ç®—æŸå¤±ç›¸å¯¹äºå„ä¸ªç½‘ç»œå‚æ•°çš„æ¢¯åº¦ï¼Œä»è€Œèƒ½å¤Ÿæ›´æ–°æƒé‡å’Œåç½®ï¼Œæœ€ç»ˆè®­ç»ƒå‡ºä¸€ä¸ªæ€§èƒ½æ›´å¥½çš„ç¥ç»ç½‘ç»œã€‚
* **è®¡ç®—å›¾**ï¼šæ¯ä¸ªæ ·æœ¬çš„å‰å‘ä¼ æ’­è¿‡ç¨‹ä¼šæ„å»ºä¸€ä¸ªè®¡ç®—å›¾ï¼Œå¹¶é€šè¿‡åå‘ä¼ æ’­ä¼˜åŒ–ç¥ç»ç½‘ç»œçš„å‚æ•°ã€‚

é€šè¿‡è¿™ä¸€è¿‡ç¨‹ï¼Œç¥ç»ç½‘ç»œä¸æ–­è°ƒæ•´è‡ªèº«çš„å‚æ•°ï¼Œä»¥ä½¿æŸå¤±æœ€å°åŒ–ï¼Œæœ€ç»ˆæé«˜é¢„æµ‹å‡†ç¡®ç‡ã€‚è¿™æ˜¯ç¥ç»ç½‘ç»œè®­ç»ƒä¸­çš„æ ¸å¿ƒæ€æƒ³ã€‚


# collecting all of the parameters of the neural net

can operate on all of them simultaneously and every one of them we will nudge a tiny amount
based on the gradient information so let's collect the parameters of the neural net all in one array
so let's create a parameters of self that just returns celta w which is a list
concatenated with a list of self.b so this will just return a list
list plus list just you know gives you a list so that's parameters of neuron and i'm
calling it this way because also pi torch has a parameters on every single and in module
and uh it does exactly what we're doing here it just returns the parameter tensors for us as the
parameter scalars now layer is also a module so it will have parameters
itself and basically what we want to do here is something like this like
params is here and then for neuron in salt out neurons
we want to get neuron.parameters and we want to params.extend
right so these are the parameters of this neuron and then we want to put them on top of params so params dot extend
of peace and then we want to return brands so this is way too much code so actually
there's a way to simplify this which is return
p for neuron in self neurons
for p in neuron dot parameters
so it's a single list comprehension in python you can sort of nest them like this and you can um
then create uh the desired array so this is these are identical
we can take this out and then let's do the same here
def parameters self and return a parameter for layer in self dot layers
for p in layer dot parameters
and that should be good now let me pop out this so
we don't re-initialize our network because we need to re-initialize our
okay so unfortunately we will have to probably re-initialize the network because we just add functionality
because this class of course we i want to get all the and that parameters but that's not going to work because this is
the old class okay so unfortunately we do have to reinitialize the network which will
change some of the numbers but let me do that so that we pick up the new api we can now do in the
parameters and these are all the weights and biases inside the entire neural net
so in total this mlp has 41 parameters
and now we'll be able to change them if we recalculate the loss here we see

è¿™ä¸€éƒ¨åˆ†è®²çš„æ˜¯ï¼š**å¦‚ä½•æ”¶é›†æ•´ä¸ªç¥ç»ç½‘ç»œä¸­çš„æ‰€æœ‰å‚æ•°ï¼ˆæƒé‡å’Œåç½®ï¼‰**ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥ç»Ÿä¸€åœ°æ“ä½œå®ƒä»¬ï¼Œæ¯”å¦‚æ›´æ–°å‚æ•°è¿›è¡Œè®­ç»ƒã€‚

---

## ğŸŒŸ èƒŒæ™¯çŸ¥è¯†

åœ¨è®­ç»ƒç¥ç»ç½‘ç»œæ—¶ï¼Œæˆ‘ä»¬éœ€è¦ï¼š

1. **è·å–æ‰€æœ‰å‚æ•°ï¼ˆæƒé‡ `w` å’Œåç½® `b`ï¼‰**
2. **å¯¹æ¯ä¸ªå‚æ•°åšå¾®è°ƒï¼ˆæ ¹æ®åå‘ä¼ æ’­å¾—åˆ°çš„æ¢¯åº¦ï¼‰**

---

## ğŸ”§ ç›®æ ‡

ç¼–å†™ `parameters()` æ–¹æ³•ï¼š

* å¯ä»¥ä» **ç¥ç»å…ƒ**ï¼ˆ`Neuron`ï¼‰ã€**å±‚**ï¼ˆ`Layer`ï¼‰ã€**å¤šå±‚æ„ŸçŸ¥æœº MLP** ä¸­é€’å½’è·å–æ‰€æœ‰å‚æ•°ã€‚
* æœ€ç»ˆæ”¶é›†ä¸ºä¸€ä¸ªå‚æ•°åˆ—è¡¨ï¼Œæ–¹ä¾¿åç»­æ“ä½œï¼ˆå¦‚æ¢¯åº¦ä¸‹é™ï¼‰ã€‚

---

## ğŸ§  æ­¥éª¤è§£é‡Š

### 1. `Neuron` ç±»ä¸­çš„ `parameters()`

```python
def parameters(self):
    return self.w + [self.b]
```

* `self.w` æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«è¯¥ç¥ç»å…ƒçš„æ‰€æœ‰æƒé‡å‚æ•°ã€‚
* `self.b` æ˜¯åç½®ï¼Œæ˜¯ä¸€ä¸ªå•ç‹¬çš„ `Value` å¯¹è±¡ã€‚
* è¿™é‡Œé€šè¿‡ `self.w + [self.b]` æŠŠæ‰€æœ‰å‚æ•°æ”¾åœ¨ä¸€ä¸ªåˆ—è¡¨ä¸­è¿”å›ã€‚

---

### 2. `Layer` ç±»ä¸­çš„ `parameters()`

```python
def parameters(self):
    return [p for neuron in self.neurons for p in neuron.parameters()]
```

* æ¯ä¸ª `Layer` åŒ…å«å¤šä¸ª `Neuron`ã€‚
* å¯¹æ¯ä¸ª `Neuron` è°ƒç”¨å®ƒçš„ `parameters()` æ–¹æ³•ï¼ŒæŠŠæ‰€æœ‰ç¥ç»å…ƒçš„å‚æ•°å±•å¼€æˆä¸€ä¸ªå¤§çš„åˆ—è¡¨ã€‚
* ä½¿ç”¨äº† **åˆ—è¡¨æ¨å¯¼å¼åµŒå¥—å†™æ³•**ï¼Œç®€æ´é«˜æ•ˆã€‚

ç­‰ä»·äºæ›´å†—é•¿çš„å†™æ³•ï¼ˆä½†ä½œç”¨ç›¸åŒï¼‰ï¼š

```python
params = []
for neuron in self.neurons:
    params.extend(neuron.parameters())
return params
```

---

### 3. `MLP` ç±»ä¸­çš„ `parameters()`

```python
def parameters(self):
    return [p for layer in self.layers for p in layer.parameters()]
```

* `MLP` åŒ…å«å¤šä¸ª `Layer`ã€‚
* å¯¹æ¯å±‚è°ƒç”¨ `parameters()`ï¼Œå†å±•å¼€æ‰€æœ‰å‚æ•°ã€‚
* æœ€ç»ˆå¾—åˆ°çš„æ˜¯æ•´ä¸ªç½‘ç»œçš„æ‰€æœ‰æƒé‡å’Œåç½®ã€‚

---

## ğŸ§ª é‡æ–°åˆå§‹åŒ–æ¨¡å‹çš„åŸå› 

> åœ¨æœ€åï¼Œä½œè€…æåˆ°ï¼š

```text
æˆ‘ä»¬å¿…é¡»é‡æ–°åˆå§‹åŒ–ç¥ç»ç½‘ç»œï¼Œå› ä¸ºä¹‹å‰å®ä¾‹åŒ–çš„æ˜¯æ—§ç±»ï¼Œè¿˜æ²¡æœ‰æ–°åŠ çš„ parameters æ–¹æ³•ã€‚
```

è§£é‡Šï¼š

* ä¹‹å‰åˆ›å»ºçš„ `MLP` å®ä¾‹æ²¡æœ‰ `parameters()` æ–¹æ³•ã€‚
* åŠ å®Œè¿™ä¸ªæ–¹æ³•ä¹‹åï¼Œå¿…é¡»é‡æ–°åˆå§‹åŒ–æ¨¡å‹å¯¹è±¡ï¼ˆç”¨æ–°å®šä¹‰çš„ç±»ç»“æ„ï¼‰ï¼Œå¦åˆ™è°ƒç”¨ä¼šå¤±è´¥ã€‚

---

## âœ… æœ€ç»ˆæ•ˆæœ

```python
n = MLP(...)
params = n.parameters()  # æ‰€æœ‰çš„ w å’Œ b
len(params)  # e.g. 41 ä¸ªå‚æ•°
```

æˆ‘ä»¬å¯ä»¥ç»Ÿä¸€æ“ä½œè¿™äº›å‚æ•°ï¼Œæ¯”å¦‚ï¼š

```python
for p in n.parameters():
    p.data -= learning_rate * p.grad  # æ¢¯åº¦ä¸‹é™æ›´æ–°å‚æ•°
```

---

## ğŸ§¾ æ€»ç»“

| ç±»åˆ«       | æ–¹æ³•å            | è¿”å›å†…å®¹               |
| -------- | -------------- | ------------------ |
| `Neuron` | `parameters()` | `[w1, w2, ..., b]` |
| `Layer`  | `parameters()` | æ‰€æœ‰ç¥ç»å…ƒçš„ `[w, b]`    |
| `MLP`    | `parameters()` | æ‰€æœ‰å±‚çš„å‚æ•°åˆå¹¶åœ¨ä¸€èµ·        |

---

è¿™ä¸ºä¹‹åçš„è®­ç»ƒï¼ˆæ¯”å¦‚æ‰§è¡Œ SGD ä¼˜åŒ–å™¨ï¼‰æ‰“å¥½äº†åŸºç¡€ã€‚ä¸‹ä¸€æ­¥å°±æ˜¯å¼€å§‹è¿­ä»£æ›´æ–°è¿™äº›å‚æ•°ä»¥é™ä½æŸå¤±ã€‚éœ€è¦è®²è¿™ä¸ªè®­ç»ƒå¾ªç¯çš„è¯ä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ã€‚


# doing gradient descent optimization manually, training the network

that unfortunately we have slightly different predictions and slightly different laws
but that's okay okay so we see that this neurons gradient is slightly negative we can
also look at its data right now which is 0.85 so this is the current
value of this neuron and this is its gradient on the loss so what we want to do now is we want to
iterate for every p in n dot parameters so for all the 41 parameters in this neural net
we actually want to change p data slightly according to the gradient information
okay so dot dot to do here but this will be basically a tiny update
in this gradient descent scheme in gradient descent we are thinking of the
gradient as a vector pointing in the direction of increased
loss and so in gradient descent we are modifying
p data by a small step size in the direction of the gradient so the step size as an
example could be like a very small number like 0.01 is the step size times p dot grad
right but we have to think through some of the signs here so uh
in particular working with this specific example here we see that if we just left it like this
then this neuron's value would be currently increased by a tiny amount of the gradient
the grain is negative so this value of this neuron would go slightly down it would become like 0.8 you know four or
something like that but if this neuron's value goes lower
that would actually increase the loss that's because
the derivative of this neuron is negative so increasing this makes the loss go down so
increasing it is what we want to do instead of decreasing it so basically what we're missing here is we're
actually missing a negative sign and again this other interpretation and that's because we want to minimize
the loss we don't want to maximize the loss we want to decrease it and the other interpretation as i mentioned is you can think of the
gradient vector so basically just the vector of all the gradients as pointing in the direction of
increasing the loss but then we want to decrease it so we actually want to go in the opposite direction
and so you can convince yourself that this sort of plug does the right thing here with the negative because we want to minimize the loss
so if we nudge all the parameters by tiny amount
then we'll see that this data will have changed a little bit so now this neuron
is a tiny amount greater value so 0.854 went to 0.857
and that's a good thing because slightly increasing this neuron uh
data makes the loss go down according to the gradient and so the correct thing has happened sign wise
and so now what we would expect of course is that because we've changed all these parameters we expect that the loss
should have gone down a bit so we want to re-evaluate the loss let me basically
this is just a data definition that hasn't changed but the forward pass here of the network we can recalculate
and actually let me do it outside here so that we can compare the two loss values so here if i recalculate the loss
we'd expect the new loss now to be slightly lower than this number so hopefully what we're getting now is a
tiny bit lower than 4.84 4.36 okay and remember the way we've arranged
this is that low loss means that our predictions are matching the targets so our predictions now are probably
slightly closer to the targets and now all we have to do is we
have to iterate this process so again um we've done the forward pass and this is the loss
now we can lost that backward let me take these out and we can do a step size
and now we should have a slightly lower loss 4.36 goes to 3.9
and okay so we've done the forward pass here's the backward pass nudge
and now the loss is 3.66 3.47
and you get the idea we just continue doing this and this is uh gradient descent we're just iteratively doing
forward pass backward pass update forward pass backward pass update and the neural net is improving its
predictions so here if we look at why pred now
like red we see that um this value should be getting closer to
one so this value should be getting more positive these should be getting more negative and this one should be also getting more positive so if we just
iterate this a few more times actually we may be able to afford go to
go a bit faster let's try a slightly higher learning rate
oops okay there we go so now we're at 0.31 if you go too fast by the way if you try
to make it too big of a step you may actually overstep
it's overconfidence because again remember we don't actually know exactly about the loss function the loss function has all kinds of structure and
we only know about the very local dependence of all these parameters on the loss but if we step too far
we may step into you know a part of the loss that is completely different and that can destabilize training and
make your loss actually blow up even so the loss is now 0.04 so actually the
predictions should be really quite close let's take a look so you see how this is almost one
almost negative one almost one we can continue going uh so
yep backward update oops there we go so we went way too fast
and um we actually overstepped so we got two uh too eager where are we
now oops okay seven e negative nine so this is very very low loss
and the predictions are basically perfect so somehow we
basically we were doing way too big updates and we briefly exploded but then somehow we ended up getting into a really good spot so usually this
learning rate and the tuning of it is a subtle art you want to set your learning rate if it's too low you're going to
take way too long to converge but if it's too high the whole thing gets unstable and you might actually even
explode the loss depending on your loss function so finding the step size to be just
right it's it's a pretty subtle art sometimes when you're using sort of vanilla gradient descent
but we happen to get into a good spot we can look at n-dot parameters
so this is the setting of weights and biases that makes our network
predict the desired targets very very close and
basically we've successfully trained neural net okay let's make this a tiny bit more respectable and implement an actual
training loop and what that looks like so this is the data definition that stays this is the forward pass
um so for uh k in range you know we're going to
take a bunch of steps first you do the forward pass
we validate the loss let's re-initialize the neural net from scratch
and here's the data and we first do before pass then we do
the backward pass
and then we do an update that's gradient descent
and then we should be able to iterate this and we should be able to print the current step the current loss um let's just print the
sort of number of the loss and that should be it
and then the learning rate 0.01 is a little too small 0.1 we saw is like a little bit dangerously too high let's go
somewhere in between and we'll optimize this for not 10 steps but let's go for say 20
steps let me erase all of this junk
and uh let's run the optimization and you see how we've actually converged
slower in a more controlled manner and got to a loss that is very low
so i expect white bread to be quite good there we go
um and that's it okay so this is kind of embarrassing but
we actually have a really terrible bug in here and it's a subtle bug and it's a
very common bug and i can't believe i've done it for the 20th time in my life
especially on camera and i could have reshot the whole thing but i think it's pretty funny and you know you get to
appreciate a bit what um working with neural nets maybe is like sometimes
we are guilty of come bug i've actually tweeted
the most common neural net mistakes a long time ago now uh and
i'm not really gonna explain any of these except for we are guilty of number three you forgot to
zero grad before that backward what is that
basically what's happening and it's a subtle bug and i'm not sure if you saw it is that all of these
weights here have a dot data and a dot grad and that grad starts at zero
and then we do backward and we fill in the gradients and then we do an update on the data but
we don't flush the grad it stays there so when we do the second
forward pass and we do backward again remember that all the backward operations do a plus equals on the grad
and so these gradients just add up and they never get reset to zero
so basically we didn't zero grad so here's how we zero grad before
backward we need to iterate over all the parameters and we need to make sure that p dot grad
is set to zero we need to reset it to zero just like it is in the constructor
so remember all the way here for all these value nodes grad is reset to zero and then all these backward passes do a
plus equals from that grad but we need to make sure that we reset these graphs to zero so that
when we do backward all of them start at zero and the actual backward pass accumulates um
the loss derivatives into the grads so this is zero grad in pytorch
and uh we will slightly get we'll get a slightly different optimization let's reset the neural net
the data is the same this is now i think correct and we get a much more
you know we get a much more slower descent we still end up with pretty good results
and we can continue this a bit more to get down lower and lower
and lower yeah so the only reason that the previous
thing worked it's extremely buggy um the only reason that worked is that
this is a very very simple problem and it's very easy for this neural net to fit this data
and so the grads ended up accumulating and it effectively gave us a massive step size and it made us converge
extremely fast but basically now we have to do more steps to get to very low values of loss
and get wipe red to be really good we can try to step a bit greater
yeah we're gonna get closer and closer to one minus one and one so
working with neural nets is sometimes tricky because uh
you may have lots of bugs in the code and uh your network might actually work just like ours worked
but chances are is that if we had a more complex problem then actually this bug would have made us not optimize the loss
very well and we were only able to get away with it because the problem is very simple

è¿™éƒ¨åˆ†è®²çš„æ˜¯å¦‚ä½•æ‰‹åŠ¨ä½¿ç”¨\*\*æ¢¯åº¦ä¸‹é™ï¼ˆgradient descentï¼‰\*\*ä¼˜åŒ–ç¥ç»ç½‘ç»œçš„å‚æ•°ï¼Œå¹¶è®­ç»ƒç½‘ç»œï¼Œä½¿å…¶é¢„æµ‹è¶Šæ¥è¶Šå‡†ç¡®ã€‚

---

## ğŸ§  ä¸»è¦æ€è·¯

1. **æ¯ä¸ªå‚æ•°éƒ½æœ‰æ¢¯åº¦ä¿¡æ¯ï¼ˆ`grad`ï¼‰**ï¼Œè¡¨ç¤ºå¦‚æœä½ ç¨å¾®è°ƒæ•´å®ƒï¼ŒæŸå¤±å‡½æ•°ï¼ˆlossï¼‰ä¼šæ€ä¹ˆå˜åŒ–ã€‚
2. ä½¿ç”¨è¿™äº›æ¢¯åº¦ï¼Œ**æˆ‘ä»¬å°±èƒ½æ›´æ–°å‚æ•°çš„å€¼**ï¼Œè®©æŸå¤±å˜å¾—æ›´å°ã€‚
3. é‡å¤æ‰§è¡Œâ€œå‰å‘ä¼ æ’­ â†’ åå‘ä¼ æ’­ â†’ å‚æ•°æ›´æ–°â€è¿™ä¸ªå¾ªç¯ï¼Œç¥ç»ç½‘ç»œå°±ä¼š**å­¦ä¼šæ‹Ÿåˆæ•°æ®**ã€‚

---

## ğŸš¶â€â™€ï¸æ¯ä¸€æ­¥è§£é‡Š

### 1. æŸ¥çœ‹æŸä¸ªå‚æ•°çš„ `data` å’Œ `grad`

```python
p.data  # å½“å‰å‚æ•°çš„å€¼
p.grad  # å½“å‰å‚æ•°å¯¹lossçš„æ¢¯åº¦
```

æˆ‘ä»¬å¯ä»¥ä»æ¢¯åº¦ä¸­çŸ¥é“â€œå¾€å“ªä¸ªæ–¹å‘ç§»åŠ¨å‚æ•°ä¼šè®©losså˜å°â€ã€‚

---

### 2. æ¢¯åº¦ä¸‹é™å…¬å¼

```python
p.data += -learning_rate * p.grad
```

* `p.grad` æ˜¯æŒ‡â€œå¢å¤§è¿™ä¸ªå‚æ•°ä¼šè®© loss å¢åŠ å¤šå°‘â€ï¼Œä¹Ÿå°±æ˜¯â€œå¾€ä¸Šçˆ¬çš„æ–¹å‘â€ã€‚
* æ‰€ä»¥æˆ‘ä»¬åŠ ä¸€ä¸ª **è´Ÿå·**ï¼Œæœç€â€œè®©lossä¸‹é™â€çš„æ–¹å‘å»æ›´æ–°ã€‚
* `learning_rate` æ˜¯å­¦ä¹ ç‡ï¼Œæ§åˆ¶â€œèµ°å¤šè¿œâ€ã€‚

---

### 3. ä¸ºä»€ä¹ˆéœ€è¦è´Ÿå·ï¼Ÿ

> æ¢¯åº¦æŒ‡å‘ **æŸå¤±å‡½æ•°å˜å¤§çš„æ–¹å‘**ï¼Œä½†æˆ‘ä»¬æƒ³è¦ **æœ€å°åŒ–æŸå¤±**ï¼Œæ‰€ä»¥è¦å¾€åæ–¹å‘èµ°ã€‚

---

### 4. è®­ç»ƒç»“æœè§‚æµ‹

ä½ å¯ä»¥çœ‹åˆ°ï¼š

* æ¯æ¬¡æ›´æ–°åï¼Œ`loss`ï¼ˆæŸå¤±ï¼‰è¶Šæ¥è¶Šå°
* ç¥ç»ç½‘ç»œçš„é¢„æµ‹ç»“æœ `y_pred` è¶Šæ¥è¶Šæ¥è¿‘çœŸå®å€¼ `y_gt`
* å¦‚æœå­¦ä¹ ç‡åˆé€‚ï¼Œå°±èƒ½é€æ­¥æ”¶æ•›åˆ°ä¸€ä¸ªå¥½æ¨¡å‹
* å¦‚æœå­¦ä¹ ç‡å¤ªå¤§ï¼Œå¯èƒ½ä¼šâ€œè·³è¿‡æœ€ä½³å€¼â€ç”šè‡³å‘æ•£

---

### 5. å®ç°ä¸€ä¸ªå®Œæ•´è®­ç»ƒå¾ªç¯

```python
for step in range(20):  # è®­ç»ƒ20è½®
    # 1. å‰å‘ä¼ æ’­è®¡ç®— loss
    loss = ...

    # 2. æ¸…é›¶æ‰€æœ‰æ¢¯åº¦ï¼ˆé‡è¦ï¼ï¼‰
    for p in n.parameters():
        p.grad = 0.0

    # 3. åå‘ä¼ æ’­
    loss.backward()

    # 4. å‚æ•°æ›´æ–°
    for p in n.parameters():
        p.data += -learning_rate * p.grad
```

---

## ğŸ› ä¸€ä¸ªéå¸¸å¸¸è§çš„ Bugï¼š**å¿˜è®° zero\_grad()**

### å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ

* ä½ è®¡ç®— `loss.backward()`ï¼Œä¼šæŠŠæ¢¯åº¦åŠ åˆ° `p.grad` ä¸Šï¼ˆæ˜¯ +=ï¼‰ã€‚
* å¦‚æœä¸åœ¨æ¯è½®è®­ç»ƒå‰æŠŠ `p.grad` é‡ç½®ä¸º0ï¼Œæ¢¯åº¦ä¼šä¸€ç›´ç´¯åŠ ï¼
* è¿™ä¼šå¯¼è‡´å‚æ•°æ›´æ–°å˜å¾— **ä¸å‡†ç¡®ç”šè‡³çˆ†ç‚¸**ï¼Œè®­ç»ƒä¹Ÿä¼šä¸ç¨³å®šã€‚

### æ­£ç¡®åšæ³•ï¼š

```python
for p in n.parameters():
    p.grad = 0.0
```

è¿™å°±åƒ PyTorch é‡Œçš„ `optimizer.zero_grad()`ã€‚

---

## âœ… æ€»ç»“

| æ­¥éª¤                | å†…å®¹                            |
| ----------------- | ----------------------------- |
| å‰å‘ä¼ æ’­              | è®¡ç®—è¾“å‡ºå’ŒæŸå¤±                       |
| `loss.backward()` | åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¯ä¸ªå‚æ•°çš„ `grad`           |
| æ¸…ç©ºæ—§çš„ `grad`       | æ¯è½®å¼€å§‹æ—¶å¿…é¡»åš                      |
| å‚æ•°æ›´æ–°              | ç”¨ `p.data += -lr * p.grad` æ›´æ–° |

---

## ğŸ“ å°ç»“ä¸€å¥è¯

æˆ‘ä»¬ä½¿ç”¨**æ¢¯åº¦ä¸‹é™**åå¤å¾®è°ƒç½‘ç»œçš„æƒé‡ï¼Œè®©å®ƒå¯¹è®­ç»ƒæ•°æ®çš„é¢„æµ‹è¶Šæ¥è¶Šå‡†ç¡®â€”â€”è€Œè¿™ä¸€åˆ‡éƒ½é  `.grad` ä¸­çš„ä¿¡æ¯å®Œæˆã€‚

å¦‚æœä½ æƒ³çœ‹æˆ‘ç”¨ä¸­æ–‡å®ç°ä¸€ä¸ªå®Œæ•´çš„ç®€æ˜“è®­ç»ƒå¾ªç¯ï¼Œæˆ‘å¯ä»¥é©¬ä¸Šå†™å‡ºæ¥ï¼


# summary of what we learned, how to go towards modern neural nets

so let's now bring everything together and summarize what we learned what are neural nets neural nets are
these mathematical expressions fairly simple mathematical expressions in the case of multi-layer perceptron
that take input as the data and they take input the weights and the parameters of the
neural net mathematical expression for the forward pass followed by a loss function and the loss function tries to
measure the accuracy of the predictions and usually the loss will be low when your predictions are matching your
targets or where the network is basically behaving well so we we manipulate the loss function so that
when the loss is low the network is doing what you want it to do on your problem
and then we backward the loss use backpropagation to get the gradient and then we know how to tune all the
parameters to decrease the loss locally but then we have to iterate that process many times in what's called the gradient
descent so we simply follow the gradient information and that minimizes the loss
and the loss is arranged so that when the loss is minimized the network is doing what you want it to do
and yeah so we just have a blob of neural stuff and we can make it do arbitrary things and that's what gives
neural nets their power um it's you know this is a very tiny network with 41 parameters
but you can build significantly more complicated neural nets with billions at this point almost trillions of
parameters and it's a massive blob of neural tissue simulated neural tissue
roughly speaking and you can make it do extremely complex problems and these neurons then have all
kinds of very fascinating emergent properties in when you try to make them do
significantly hard problems as in the case of gpt for example we have massive amounts of text from the
internet and we're trying to get a neural net to predict to take like a few words and try to predict the next word
in a sequence that's the learning problem and it turns out that when you train this on all of internet the neural net
actually has like really remarkable emergent properties but that neural net would have hundreds of billions of parameters
but it works on fundamentally the exact same principles the neural net of course will be a bit more complex but otherwise the
value in the gradient is there and would be identical and the gradient descent would be there and would be
basically identical but people usually use slightly different updates this is a very simple stochastic gradient descent
update um and the loss function would not be mean squared error they would be using something called the cross-entropy loss
for predicting the next token so there's a few more details but fundamentally the neural network setup and neural network
training is identical and pervasive and now you understand intuitively
how that works under the hood in the beginning of this video i told you that by the end of it you would understand everything in micrograd and then we'd

è¿™ä¸€éƒ¨åˆ†æ˜¯å¯¹æ•´ä¸ªå¾®å‹ç¥ç»ç½‘ç»œé¡¹ç›®çš„**æ€»ç»“ä¸å‡å**ï¼Œç›®çš„æ˜¯è®©ä½ ç†è§£ä»ç®€å•æ¨¡å‹åˆ°ç°ä»£å¤§æ¨¡å‹ï¼ˆæ¯”å¦‚GPTï¼‰èƒŒåçš„æ ¸å¿ƒåŸç†å…¶å®**ä¸€è„‰ç›¸æ‰¿**ã€‚

---

## ğŸ§  æˆ‘ä»¬å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ

### 1. ç¥ç»ç½‘ç»œæ˜¯ä»€ä¹ˆï¼Ÿ

* æœ¬è´¨ä¸Šï¼Œ**ç¥ç»ç½‘ç»œæ˜¯ä¸€ç§æ•°å­¦è¡¨è¾¾å¼**ã€‚
* å®ƒæœ‰ä¸¤ç±»è¾“å…¥ï¼š

  * **è¾“å…¥æ•°æ®**ï¼ˆå¦‚ä¸€ç»„æ•°å­—ï¼‰
  * **å¯è°ƒå‚æ•°**ï¼ˆæƒé‡weightså’Œåç½®biasesï¼‰
* è¾“å…¥è¿™äº›åï¼Œé€šè¿‡ä¸€ç³»åˆ—æ•°å­¦æ“ä½œï¼ˆä¹˜æ³•ã€åŠ æ³•ã€æ¿€æ´»å‡½æ•°ï¼‰ï¼Œä¼šäº§ç”Ÿä¸€ä¸ªè¾“å‡ºï¼Œè¿™å°±æ˜¯æ‰€è°“çš„â€œå‰å‘ä¼ æ’­â€ã€‚

---

### 2. æŸå¤±å‡½æ•°ï¼ˆloss functionï¼‰

* æŸå¤±å‡½æ•°æ˜¯å¦ä¸€ä¸ªæ•°å­¦è¡¨è¾¾å¼ï¼Œç”¨æ¥è¡¡é‡è¾“å‡ºä¸\*\*ç›®æ ‡å€¼ï¼ˆground truthï¼‰\*\*ä¹‹é—´çš„å·®è·ã€‚
* **æŸå¤±è¶Šä½ï¼Œè¯´æ˜é¢„æµ‹è¶Šå‡†**ã€‚
* æ¯”å¦‚æˆ‘ä»¬ç”¨çš„æ˜¯å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ï¼Œé¢„æµ‹å€¼å’Œç›®æ ‡å€¼è¶Šæ¥è¿‘ï¼ŒæŸå¤±è¶Šå°ã€‚

---

### 3. åå‘ä¼ æ’­ä¸æ¢¯åº¦ï¼ˆgradientï¼‰

* ä½¿ç”¨**åå‘ä¼ æ’­ç®—æ³•**ï¼Œæˆ‘ä»¬å¯ä»¥æ±‚å‡ºæ¯ä¸ªå‚æ•°å¯¹æŸå¤±å‡½æ•°çš„å½±å“ï¼Œä¹Ÿå°±æ˜¯æ¢¯åº¦ã€‚
* è¿™äº›æ¢¯åº¦å‘Šè¯‰æˆ‘ä»¬ï¼šâ€œå¦‚æœæˆ‘æ”¹åŠ¨è¿™ä¸ªå‚æ•°ï¼ŒæŸå¤±å‡½æ•°ä¼šä¸Šå‡è¿˜æ˜¯ä¸‹é™ï¼Ÿâ€

---

### 4. æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰

* ç”¨æ¢¯åº¦æ¥æ›´æ–°æ¯ä¸ªå‚æ•°ï¼š

  * **æœç€è®©æŸå¤±å˜å°çš„æ–¹å‘æ›´æ–°**
  * æ›´æ–°çš„å…¬å¼å°±æ˜¯ï¼š
    `å‚æ•° = å‚æ•° - å­¦ä¹ ç‡ Ã— æ¢¯åº¦`
* ä¸æ–­è¿­ä»£è¿™ä¸ªè¿‡ç¨‹ï¼š**å‰å‘ä¼ æ’­ â†’ åå‘ä¼ æ’­ â†’ å‚æ•°æ›´æ–°**
  ç¥ç»ç½‘ç»œå°±ä¼šè¶Šæ¥è¶Šâ€œèªæ˜â€ã€‚

---

### 5. ä»å°æ¨¡å‹åˆ°å¤§æ¨¡å‹

* è™½ç„¶æˆ‘ä»¬ç°åœ¨åªè®­ç»ƒäº†ä¸€ä¸ª**å¾ˆå°çš„ç¥ç»ç½‘ç»œ**ï¼ˆ41ä¸ªå‚æ•°ï¼‰ï¼Œä½†ä½ å·²ç»æŒæ¡äº†è®­ç»ƒGPTç­‰å¤§æ¨¡å‹çš„**åŸºæœ¬åŸç†**ã€‚
* æ¯”å¦‚GPTï¼š

  * æœ‰æ•°åƒäº¿ä¸ªå‚æ•°
  * è¾“å…¥æ˜¯æ–‡æœ¬ï¼Œè¾“å‡ºæ˜¯â€œä¸‹ä¸€ä¸ªè¯â€
  * ä½¿ç”¨çš„ä¸æ˜¯ MSEï¼Œè€Œæ˜¯**äº¤å‰ç†µæŸå¤±ï¼ˆcross-entropy lossï¼‰**
  * æ›´æ–°æ–¹å¼ä¹Ÿæ¯”æ™®é€š SGD æ›´å¤æ‚ï¼Œå¦‚ Adamã€RMSprop ç­‰

ä½†æ ¸å¿ƒæµç¨‹ï¼š**å‰å‘ â†’ æŸå¤± â†’ åå‘ä¼ æ’­ â†’ å‚æ•°æ›´æ–°**ï¼Œæ˜¯ä¸€æ¨¡ä¸€æ ·çš„ã€‚

---

## ğŸ’¬ æ€»ç»“ä¸€å¥è¯ï¼š

> ä¸ç®¡æ˜¯å¾®å‹ç¥ç»å…ƒï¼Œè¿˜æ˜¯åºå¤§çš„GPT4ï¼Œå®ƒä»¬èƒŒåå…¶å®éƒ½æ˜¯â€œå…ˆé¢„æµ‹ â†’ ç®—æŸå¤± â†’ æ‰¾æ¢¯åº¦ â†’ è°ƒå‚æ•°â€è¿™ä¹ˆä¸€ä¸ª**è‡ªåŠ¨è°ƒæ•´çš„æ•°å­¦ç³»ç»Ÿ**ã€‚

ç°åœ¨ï¼Œä½ å·²ç»ç†è§£äº†è¿™ä¸€åˆ‡çš„åº•å±‚æœºåˆ¶ã€‚

å¦‚æœä½ å¸Œæœ›ï¼Œæˆ‘å¯ä»¥ç”¨ä¸­æ–‡é‡æ„æ•´ä¸ª `micrograd` ç¥ç»ç½‘ç»œä»£ç ï¼Œå¸®åŠ©ä½ æ›´å¥½ç†è§£å¹¶åŠ¨æ‰‹å®è·µï¼


# walkthrough of the full code of micrograd on github

slowly build it up let me briefly prove that to you so i'm going to step through all the code that is in micrograd as of today
actually potentially some of the code will change by the time you watch this video because i intend to continue developing micrograd
but let's look at what we have so far at least init.pi is empty when you go to engine.pi that has the value
everything here you should mostly recognize so we have the data.grad attributes we have the backward function
uh we have the previous set of children and the operation that produced this value we have addition multiplication and
raising to a scalar power we have the relu non-linearity which is slightly different type of nonlinearity
than 10h that we used in this video both of them are non-linearities and notably 10h is not actually present in
micrograd as of right now but i intend to add it later with the backward which is identical and
then all of these other operations which are built up on top of operations here so values should be very recognizable
except for the non-linearity used in this video um there's no massive difference between relu and 10h and sigmoid and these other
non-linearities they're all roughly equivalent and can be used in mlps so i use 10h because it's a bit smoother and
because it's a little bit more complicated than relu and therefore it's stressed a little bit more the
local gradients and working with those derivatives which i thought would be useful and then that pi is the neural networks
library as i mentioned so you should recognize identical implementation of neuron layer and mlp
notably or not so much we have a class module here there is a parent class of all these modules i did
that because there's an nn.module class in pytorch and so this exactly matches that api and end.module and pytorch has
also a zero grad which i've refactored out here so that's the end of micrograd really
then there's a test which you'll see basically creates two chunks of code one in micrograd and
one in pi torch and we'll make sure that the forward and the backward pass agree identically for a slightly less complicated
expression a slightly more complicated expression everything agrees so we agree with pytorch on all
of these operations and finally there's a demo.ipymb here and it's a bit more complicated binary
classification demo than the one i covered in this lecture so we only had a tiny data set of four examples um here
we have a bit more complicated example with lots of blue points and lots of red points and we're trying to again build a
binary classifier to distinguish uh two dimensional points as red or blue it's a bit more complicated mlp here
with it's a bigger mlp the loss is a bit more complicated because it supports batches
so because our dataset was so tiny we always did a forward pass on the entire data set of four examples but when your
data set is like a million examples what we usually do in practice is we chair we basically pick out some random subset we
call that a batch and then we only process the batch forward backward and update so we don't have to forward the
entire training set so this supports batching because there's a lot more examples here
we do a forward pass the loss is slightly more different this is a max margin loss that i implement here
the one that we used was the mean squared error loss because it's the simplest one there's also the binary cross entropy
loss all of them can be used for binary classification and don't make too much of a difference in the simple examples
that we looked at so far there's something called l2 regularization used here this has to do
with generalization of the neural net and controls the overfitting in machine learning setting but i did not cover
these concepts and concepts in this video potentially later and the training loop you should recognize so forward backward with zero
grad and update and so on you'll notice that in the update here the learning rate is
scaled as a function of number of iterations and it shrinks and this is something called learning
rate decay so in the beginning you have a high learning rate and as the network sort of stabilizes near the end you
bring down the learning rate to get some of the fine details in the end and in the end we see the decision
surface of the neural net and we see that it learns to separate out the red and the blue area based on the data
points so that's the slightly more complicated example and then we'll demo that hyper ymb that you're free to go over
but yeah as of today that is micrograd i also wanted to show you a little bit of real stuff so that you get to see how

å½“ç„¶å¯ä»¥ï¼Œä»¥ä¸‹æ˜¯ä½ è¿™æ®µè‹±æ–‡å†…å®¹çš„**é€æ­¥ä¸­æ–‡è§£é‡Š**ï¼Œå®ƒä¸»è¦æ˜¯ä½œè€…å¯¹ GitHub ä¸Šå¼€æºé¡¹ç›® **micrograd** çš„ä»£ç ç»“æ„è¿›è¡Œä¸€ä¸ªæ€»è§ˆå¼è®²è§£ã€‚

---

## ğŸ§  micrograd é¡¹ç›®å®Œæ•´ä»£ç ç»“æ„è®²è§£ï¼ˆé€æ­¥è§£é‡Šï¼‰

### ğŸ”¹1. `__init__.py`

* å½“å‰æ˜¯ç©ºçš„ï¼Œè¡¨ç¤ºè¿™ä¸ªæ–‡ä»¶å¤¹æ˜¯ä¸€ä¸ª Python æ¨¡å—ã€‚
* **æ²¡æœ‰å®é™…ä»£ç é€»è¾‘ã€‚**

---

### ğŸ”¹2. `engine.py`ï¼šæ ¸å¿ƒè®¡ç®—å¼•æ“

* **è¿™æ˜¯æœ€å…³é”®çš„æ–‡ä»¶ï¼Œå®šä¹‰äº† `Value` ç±»ã€‚**
* `Value` å¯¹è±¡è´Ÿè´£å­˜å‚¨ï¼š

  * `.data`: å½“å‰å€¼ï¼ˆä¸€ä¸ªæµ®ç‚¹æ•°ï¼‰
  * `.grad`: å½“å‰å€¼å¯¹åº”çš„æ¢¯åº¦
* å®ƒè¿˜å®šä¹‰äº†ï¼š

  * `backward()`ï¼šåå‘ä¼ æ’­å‡½æ•°ï¼ˆå®ç°äº†è‡ªåŠ¨å¾®åˆ†ï¼‰
  * `_prev`: å½“å‰å€¼ç”±å“ªäº›å‰é¢èŠ‚ç‚¹äº§ç”Ÿï¼ˆè®°å½•è®¡ç®—å›¾ç»“æ„ï¼‰
  * `_op`: å½“å‰å€¼æ˜¯é€šè¿‡ä»€ä¹ˆæ“ä½œäº§ç”Ÿçš„ï¼ˆå¦‚åŠ æ³•ã€ä¹˜æ³•ï¼‰
* æ”¯æŒçš„æ“ä½œï¼š

  * `+` åŠ æ³•
  * `*` ä¹˜æ³•
  * `**` å¹‚è¿ç®—ï¼ˆå¦‚å¹³æ–¹ï¼‰
  * `relu()` æ¿€æ´»å‡½æ•°ï¼ˆReLUï¼‰
* æ³¨æ„ï¼šè§†é¢‘ä¸­ç”¨çš„æ˜¯ `tanh()`ï¼Œå®ƒ**ç›®å‰è¿˜æ²¡åœ¨ micrograd æ­£å¼å®ç°**ï¼Œä½œè€…æ‰“ç®—åç»­åŠ ä¸Šã€‚

#### ğŸ’¡ å…³äºéçº¿æ€§æ¿€æ´»å‡½æ•°

* ä¸ç®¡æ˜¯ `tanh`ã€`sigmoid`ã€è¿˜æ˜¯ `ReLU`ï¼Œå®ƒä»¬éƒ½èƒ½ç”¨äºå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ã€‚
* è§†é¢‘ä¸­é€‰ç”¨ `tanh()`ï¼Œå› ä¸ºå®ƒæ›´å¹³æ»‘ï¼Œä¹Ÿæ›´èƒ½ä½“ç°å±€éƒ¨å¯¼æ•°å˜åŒ–çš„ç‰¹æ€§ã€‚

---

### ğŸ”¹3. `nn.py`ï¼šæ„å»ºç¥ç»ç½‘ç»œæ¨¡å—

* å®ç°äº†ä¸‰ä¸ªç±»ï¼š

  * `Neuron`ï¼šå•ä¸ªç¥ç»å…ƒ
  * `Layer`ï¼šç¥ç»å…ƒå±‚
  * `MLP`ï¼šå¤šå±‚ç¥ç»ç½‘ç»œï¼ˆMulti-layer Perceptronï¼‰

#### ğŸ†• æ–°å¢çš„ç±»ï¼š

* `Module`ï¼šçˆ¶ç±»ï¼Œç”¨äºç»Ÿä¸€ç®¡ç†æ‰€æœ‰ç¥ç»ç½‘ç»œæ¨¡å—

  * å’Œ PyTorch ä¸­çš„ `torch.nn.Module` ç±»ä¼¼
  * åŒ…å« `parameters()` æ–¹æ³•ï¼Œç”¨äºæå–æƒé‡å‚æ•°
  * åŒ…å« `zero_grad()` æ–¹æ³•ï¼Œæ¢¯åº¦æ¸…é›¶ï¼ˆé¿å…ç´¯åŠ ï¼‰

---

### ğŸ”¹4. `test.py`ï¼šæµ‹è¯•ä¸ PyTorch çš„ä¸€è‡´æ€§

* è¿™ä¸ªæ–‡ä»¶åšäº†ä¸¤ä»¶äº‹ï¼š

  * æ„é€ ä¸€ä¸ªç¥ç»ç½‘ç»œè¡¨è¾¾å¼åœ¨ micrograd è¿è¡Œ
  * ç”¨ç›¸åŒç»“æ„åœ¨ PyTorch ä¸­è¿è¡Œ
* ç„¶åæ¯”è¾ƒä¸¤è¾¹ï¼š

  * å‰å‘ä¼ æ’­ç»“æœæ˜¯å¦ä¸€æ ·
  * åå‘ä¼ æ’­ï¼ˆæ¢¯åº¦ï¼‰ç»“æœæ˜¯å¦ä¸€è‡´

âœ… ç»“è®ºï¼š**å¾®å°è¡¨è¾¾å¼å’Œç¨å¤æ‚è¡¨è¾¾å¼ä¸Šï¼Œç»“æœä¸€è‡´ï¼**

---

### ğŸ”¹5. `demo.ipynb`ï¼šè¿›é˜¶äºŒåˆ†ç±»æ¡ˆä¾‹

* ä¸€ä¸ªæ›´å¤æ‚çš„ä¾‹å­ï¼Œç”¨æ¥åŒºåˆ†çº¢è‰²ç‚¹å’Œè“è‰²ç‚¹ï¼ˆåœ¨äºŒç»´å¹³é¢ä¸Šï¼‰ã€‚
* ä¸åŒäºä¹‹å‰åªå¤„ç† 4 ä¸ªæ ·æœ¬çš„æ•°æ®ï¼Œè¿™é‡Œæœ‰å¾ˆå¤šæ•°æ®ç‚¹ã€‚
* MLP ç»“æ„æ›´å¤§ï¼Œè®­ç»ƒè¿‡ç¨‹æ›´å¤æ‚ã€‚

#### ğŸ“¦ åŒ…å«çš„æ–°æ¦‚å¿µï¼š

1. **Batchï¼ˆå°æ‰¹é‡ï¼‰**

   * æ•°æ®å¤ªå¤šï¼Œä¸èƒ½æ¯æ¬¡éƒ½ç”¨å…¨éƒ¨æ ·æœ¬
   * ç”¨å°æ‰¹é‡æ ·æœ¬æ¥è®­ç»ƒï¼Œæé«˜æ•ˆç‡

2. **æ–°çš„æŸå¤±å‡½æ•°ï¼šMax Margin Loss**

   * æˆ‘ä»¬ä¹‹å‰ç”¨çš„æ˜¯æœ€ç®€å•çš„ Mean Squared Errorï¼ˆå‡æ–¹è¯¯å·®ï¼‰
   * è¿™é‡Œä½¿ç”¨ margin loss æˆ– Binary Cross Entropyï¼ˆBCEï¼‰æ¥å¤„ç†åˆ†ç±»é—®é¢˜

3. **L2 æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰**

   * é˜²æ­¢ç¥ç»ç½‘ç»œè¿‡æ‹Ÿåˆ
   * å¢å¼ºæ³›åŒ–èƒ½åŠ›
   * è¿™ä¸ªè§†é¢‘æ²¡è¯¦ç»†è®²ï¼Œæœªæ¥å¯èƒ½ä¼šè¡¥å……

4. **å­¦ä¹ ç‡è¡°å‡ï¼ˆLearning Rate Decayï¼‰**

   * ä¸€å¼€å§‹å­¦ä¹ ç‡é«˜ï¼Œæ”¶æ•›å¿«
   * åæœŸé€æ¸å‡å°å­¦ä¹ ç‡ï¼Œç»†åŒ–è°ƒä¼˜
   * å­¦ä¹ ç‡ = åˆå§‹å€¼ Ã— è¡°å‡å› å­

---

### ğŸ¯ æœ€ç»ˆç»“æœå±•ç¤º

* ç½‘ç»œå­¦ä¼šæ ¹æ®åæ ‡ä½ç½®å°†çº¢ç‚¹å’Œè“ç‚¹åˆ†å¼€
* å¯è§†åŒ–å†³ç­–è¾¹ç•Œï¼Œçœ‹åˆ°çº¢è“åŒºåŸŸå·²ç»è¢«å¾ˆå¥½åœ°åŒºåˆ†

---

## âœ… æ€»ç»“

ä½ ç°åœ¨çœ‹åˆ°çš„ micrograd é¡¹ç›®ï¼ŒåŒ…å«ï¼š

* è‡ªåŠ¨å¾®åˆ†å¼•æ“ï¼ˆ`engine.py`ï¼‰
* ç¥ç»ç½‘ç»œæ¨¡å—å®šä¹‰ï¼ˆ`nn.py`ï¼‰
* æµ‹è¯•ï¼ˆä¸ PyTorch å¯¹æ¯”ï¼‰
* ä¸€ä¸ªå®Œæ•´çš„äºŒåˆ†ç±»æ¡ˆä¾‹ï¼ˆ`demo.ipynb`ï¼‰

è™½ç„¶ç»“æ„å°å·§ï¼Œä½†å·²ç»å®ç°äº†ä¸€ä¸ªæç®€ç‰ˆçš„ PyTorchï¼Œå¹¶ä¸”é€šè¿‡å®é™…æ¡ˆä¾‹æ¼”ç¤ºäº†â€œæ­å»º â†’ è®­ç»ƒ â†’ å¯è§†åŒ–â€çš„æ•´ä¸ªæµç¨‹ã€‚

---

å¦‚æœä½ æƒ³æ·±å…¥æŒæ¡è¿™äº›æ¨¡å—ï¼Œæˆ‘ä¹Ÿå¯ä»¥ï¼š

* ç”¨ä¸­æ–‡é€æ­¥è§£è¯»æ¯ä¸ªæ¨¡å—æºä»£ç 
* ç»™å‡ºä½ çš„å¾®è°ƒå»ºè®®
* æˆ–è€…å¸®åŠ©ä½ ç”¨ micrograd è‡ªå·±åŠ¨æ‰‹å†™ä¸ªå°é¡¹ç›®

ä½ æƒ³ä»å“ªéƒ¨åˆ†ä»£ç å¼€å§‹ï¼Ÿ


# real stuff: diving into PyTorch, finding their backward pass for tanh

this is actually implemented in production grade library like by torch uh so in particular i wanted to show i
wanted to find and show you the backward pass for 10h in pytorch so here in
micrograd we see that the backward password 10h is one minus t square where t is the output of the tanh of x
times of that grad which is the chain rule so we're looking for something that looks like this now
i went to pytorch um which has an open source github codebase and uh i looked
through a lot of its code and honestly i i i spent about 15 minutes and i couldn't find 10h
and that's because these libraries unfortunately they grow in size and entropy and if you just search for 10h
you get apparently 2 800 results and 400 and 406 files so i don't know what these
files are doing honestly and why there are so many mentions of
10h but unfortunately these libraries are quite complex they're meant to be used not really inspected um
eventually i did stumble on someone who tries to change the 10 h backward
code for some reason and someone here pointed to the cpu kernel and the kuda kernel for 10 inch
backward so this so basically depends on if you're using pi torch on a cpu device or
on a gpu which these are different devices and i haven't covered this but this is the 10 h backwards kernel
for uh cpu and the reason it's so large is that
number one this is like if you're using a complex type which we haven't even talked about if you're using a specific data type of b-float 16 which we haven't
talked about and then if you're not then this is the kernel and deep here we see something
that resembles our backward pass so they have a times one minus b square uh so this b
b here must be the output of the 10h and this is the health.grad so here we found it
uh deep inside pi torch from this location for some reason inside binaryops kernel when 10h
is not actually a binary op and then this is the gpu kernel
we're not complex we're here and here we go with one line of code
so we did find it but basically unfortunately these codepieces are very large and
micrograd is very very simple but if you actually want to use real stuff uh finding the code for it you'll actually
find that difficult i also wanted to show you a little example here where pytorch is showing
you how can you can register a new type of function that you want to add to pytorch as a lego building block
so here if you want to for example add a gender polynomial 3
here's how you could do it you will register it as a class that subclasses storage.org that function
and then you have to tell pytorch how to forward your new function and how to backward through it
so as long as you can do the forward pass of this little function piece that you want to add and as long as you know the the local derivative the local
gradients which are implemented in the backward pi torch will be able to back propagate through your function and then
you can use this as a lego block in a larger lego castle of all the different lego blocks that pytorch already has
and so that's the only thing you have to tell pytorch and everything would just work and you can register new types of functions
in this way following this example and that is everything that i wanted to cover in this lecture so i hope you enjoyed building out

# conclusion

micrograd with me i hope you find it interesting insightful and
yeah i will post a lot of the links that are related to this video in the video description below i will also
probably post a link to a discussion forum or discussion group where you can ask questions related to this video and then
i can answer or someone else can answer your questions and i may also do a follow-up video that answers some of the
most common questions but for now that's it i hope you enjoyed it if you did then please like and
subscribe so that youtube knows to feature this video to more people and that's it for now i'll see you later

# outtakes :)

now here's the problem we know dl by
wait what is the problem and that's everything i wanted to cover in this lecture
so i hope you enjoyed us building up microcraft micro crab
okay now let's do the exact same thing for multiply because we can't do something like a times two
oops i know what happened there


[Value(data=-0.5262412713163147), Value(data=0.12076317604667741)] Value(data=0.3241930773289454)
Value(data=-0.36599993716365176)
Value(data=-0.35048795545027384)


w1 = -0.5262412713163147
w2 = 0.12076317604667741
b = 0.3241930773289454

x = [2.0, 3.0]
n = Neuron(2)
n(x)

sum(-0.5262412713163147*2.0 + 0.12076317604667741*3.0 + 0.3241930773289454)
-0.36599993716365177

tanh(-0.36599993716365177)
-0.35048795545027391


# __init__.py çš„ä½œç”¨æ˜¯ä»€ä¹ˆ

`__init__.py` æ–‡ä»¶åœ¨ Python ä¸­ç”¨äºæ ‡è¯†ä¸€ä¸ªç›®å½•æ˜¯ä¸€ä¸ªåŒ…ï¼ˆpackageï¼‰ï¼Œå¹¶ä¸”å®ƒå¯ä»¥åœ¨åŒ…å¯¼å…¥æ—¶æ‰§è¡Œä¸€äº›åˆå§‹åŒ–ä»£ç ã€‚

### ä¸»è¦ä½œç”¨ï¼š

1. **æ ‡è¯†åŒ…**ï¼š

   * åœ¨ Python ä¸­ï¼Œç›®å½•æœ¬èº«å¹¶ä¸ä¼šè¢«è¯†åˆ«ä¸ºä¸€ä¸ªåŒ…ï¼Œé™¤éè¯¥ç›®å½•åŒ…å«ä¸€ä¸ª `__init__.py` æ–‡ä»¶ã€‚è¿™ä¸ªæ–‡ä»¶å‘Šè¯‰ Python è¯¥ç›®å½•æ˜¯ä¸€ä¸ªåŒ…ï¼ˆå³ä¸€ä¸ªæ¨¡å—é›†åˆï¼‰ï¼Œå¯ä»¥è¢«å¯¼å…¥ã€‚

2. **åˆå§‹åŒ–åŒ…**ï¼š

   * `__init__.py` æ–‡ä»¶å¯ä»¥åŒ…å«åŒ…çš„åˆå§‹åŒ–ä»£ç ã€‚å³ï¼Œå½“åŒ…è¢«å¯¼å…¥æ—¶ï¼Œ`__init__.py` ä¼šè‡ªåŠ¨æ‰§è¡Œï¼Œå¯ä»¥ç”¨äºåŒ…å†…å˜é‡çš„åˆå§‹åŒ–ã€åŒ…å†…æ¨¡å—çš„å¯¼å…¥ç­‰ã€‚

3. **ç»„ç»‡æ¨¡å—**ï¼š

   * ä½ å¯ä»¥åœ¨ `__init__.py` ä¸­å¯¼å…¥åŒ…å†…çš„æ¨¡å—æˆ–å­åŒ…ï¼Œä½¿å¾—ä»åŒ…å¤–å¯¼å…¥æ—¶æ›´åŠ ç®€æ´ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥é€šè¿‡åœ¨ `__init__.py` ä¸­æ·»åŠ  `from .module import ...` è¯­å¥ï¼Œè®©ç”¨æˆ·åœ¨å¯¼å…¥åŒ…æ—¶èƒ½å¤Ÿç›´æ¥è®¿é—®åŒ…å†…çš„æ¨¡å—æˆ–å‡½æ•°ã€‚

4. **é˜²æ­¢åŒ…è¢«é‡å¤å¯¼å…¥**ï¼š

   * åœ¨ä¸€äº›æƒ…å†µä¸‹ï¼Œä½ å¯èƒ½å¸Œæœ›æŸäº›åŒ…ä»…åœ¨ç¬¬ä¸€æ¬¡å¯¼å…¥æ—¶åˆå§‹åŒ–ä¸€æ¬¡ï¼Œ`__init__.py` ä¹Ÿå¯ä»¥ç”¨æ¥æ§åˆ¶å¯¼å…¥çš„è¡Œä¸ºï¼Œç¡®ä¿åŒ…å†…çš„æŸäº›çŠ¶æ€ä»…è¢«è®¾ç½®ä¸€æ¬¡ã€‚

### ç¤ºä¾‹ï¼š

å‡è®¾æœ‰å¦‚ä¸‹ç›®å½•ç»“æ„ï¼š

```
my_package/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ module_a.py
â””â”€â”€ module_b.py
```

`__init__.py` æ–‡ä»¶çš„å†…å®¹å¯èƒ½æ˜¯ï¼š

```python
# my_package/__init__.py

from .module_a import func_a
from .module_b import func_b

print("my_package has been initialized!")
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå½“ä½ å¯¼å…¥ `my_package` æ—¶ï¼Œ`__init__.py` ä¼šè¢«è‡ªåŠ¨æ‰§è¡Œï¼Œå¹¶ä¸”ä½ å¯ä»¥ç›´æ¥ä½¿ç”¨ `func_a` å’Œ `func_b`ï¼š

```python
import my_package

# ç°åœ¨å¯ä»¥ç›´æ¥è®¿é—® func_a å’Œ func_b
my_package.func_a()
my_package.func_b()
```

### å°ç»“ï¼š

`__init__.py` æ–‡ä»¶çš„ä¸»è¦ä½œç”¨æ˜¯æ ‡è¯†ç›®å½•ä¸ºä¸€ä¸ª Python åŒ…ï¼Œå¹¶å¯ä»¥åŒ…å«åˆå§‹åŒ–ä»£ç å’Œç»„ç»‡æ¨¡å—ã€‚
