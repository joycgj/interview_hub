# Residual blocks — Building blocks of ResNet


理解残差块其实很简单。在传统神经网络中，每一层的输出都会传递到下一层。而在包含残差块的网络中，每一层不仅将输出传递到下一层，还会直接传递给相隔 2–3 层的后续层。就是这样。
但要真正理解为什么最初需要它、它为什么如此重要，以及它与一些其他先进架构的相似之处，这才是我们接下来要关注的重点。关于为什么残差块如此优秀、以及它是如何成为让神经网络在广泛任务中取得最先进性能的关键思想之一，其实有不止一种解释。
在深入细节之前，这里先给出一张残差块的示意图，帮助你直观地了解它的结构。

![](pictures/single_residual_block.webp ""）